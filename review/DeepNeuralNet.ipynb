{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "92e1e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6328fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1bcfbfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4fc60d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diagonal</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0904</td>\n",
       "      <td>1.3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>13.4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>1.2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>12.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2.2770</td>\n",
       "      <td>1.2558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>19.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.8728</td>\n",
       "      <td>2.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>19.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.9322</td>\n",
       "      <td>1.8792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Species  Weight  Length  Diagonal   Height   Width\n",
       "0     Bream   242.0    25.4      30.0  11.5200  4.0200\n",
       "1     Bream   290.0    26.3      31.2  12.4800  4.3056\n",
       "2     Bream   340.0    26.5      31.1  12.3778  4.6961\n",
       "3     Bream   363.0    29.0      33.5  12.7300  4.4555\n",
       "4     Bream   430.0    29.0      34.0  12.4440  5.1340\n",
       "..      ...     ...     ...       ...      ...     ...\n",
       "154   Smelt    12.2    12.2      13.4   2.0904  1.3936\n",
       "155   Smelt    13.4    12.4      13.5   2.4300  1.2690\n",
       "156   Smelt    12.2    13.0      13.8   2.2770  1.2558\n",
       "157   Smelt    19.7    14.3      15.2   2.8728  2.0672\n",
       "158   Smelt    19.9    15.0      16.2   2.9322  1.8792\n",
       "\n",
       "[159 rows x 6 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/fish.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "82dd4555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perch        56\n",
       "Bream        35\n",
       "Roach        20\n",
       "Pike         17\n",
       "Smelt        14\n",
       "Parkki       11\n",
       "Whitefish     6\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b4b56084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diagonal</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>430.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0904</td>\n",
       "      <td>1.3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>13.4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>1.2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>12.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2.2770</td>\n",
       "      <td>1.2558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>19.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.8728</td>\n",
       "      <td>2.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>19.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.9322</td>\n",
       "      <td>1.8792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Weight  Length  Diagonal   Height   Width\n",
       "0     242.0    25.4      30.0  11.5200  4.0200\n",
       "1     290.0    26.3      31.2  12.4800  4.3056\n",
       "2     340.0    26.5      31.1  12.3778  4.6961\n",
       "3     363.0    29.0      33.5  12.7300  4.4555\n",
       "4     430.0    29.0      34.0  12.4440  5.1340\n",
       "..      ...     ...       ...      ...     ...\n",
       "154    12.2    12.2      13.4   2.0904  1.3936\n",
       "155    13.4    12.4      13.5   2.4300  1.2690\n",
       "156    12.2    13.0      13.8   2.2770  1.2558\n",
       "157    19.7    14.3      15.2   2.8728  2.0672\n",
       "158    19.9    15.0      16.2   2.9322  1.8792\n",
       "\n",
       "[159 rows x 5 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.loc[:, 'Weight':]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f6a04a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 5)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d5c0f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "31f3eb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = LabelEncoder()               \n",
    "y_en = e.fit_transform(y)\n",
    "y_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "462087fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oh = tf.keras.utils.to_categorical(y_en)\n",
    "y_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7af7e85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 7)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5509aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 20)                120       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 16)                336       \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 655\n",
      "Trainable params: 655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim = 5, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3b51727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8a538681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 709us/step - loss: 12.0977 - accuracy: 0.2013\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 679us/step - loss: 1.9382 - accuracy: 0.3082\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 687us/step - loss: 1.7624 - accuracy: 0.3522\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 713us/step - loss: 1.6722 - accuracy: 0.3522\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 689us/step - loss: 1.6420 - accuracy: 0.3522\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 731us/step - loss: 1.5957 - accuracy: 0.3899\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 729us/step - loss: 1.5587 - accuracy: 0.4277\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 717us/step - loss: 1.4810 - accuracy: 0.5094\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 719us/step - loss: 1.4698 - accuracy: 0.4843\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 722us/step - loss: 1.4300 - accuracy: 0.5157\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 729us/step - loss: 1.3813 - accuracy: 0.5031\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 692us/step - loss: 1.3622 - accuracy: 0.5094\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 680us/step - loss: 1.3320 - accuracy: 0.5031\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 712us/step - loss: 1.3810 - accuracy: 0.4969\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 708us/step - loss: 1.3293 - accuracy: 0.5031\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 732us/step - loss: 1.2833 - accuracy: 0.5031\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 702us/step - loss: 1.2791 - accuracy: 0.5031\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 668us/step - loss: 1.2545 - accuracy: 0.4969\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 669us/step - loss: 1.2432 - accuracy: 0.4906\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 690us/step - loss: 1.2364 - accuracy: 0.4780\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 695us/step - loss: 1.2427 - accuracy: 0.5157\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 701us/step - loss: 1.2336 - accuracy: 0.5157\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 670us/step - loss: 1.2302 - accuracy: 0.4969\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 681us/step - loss: 1.2108 - accuracy: 0.4906\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 719us/step - loss: 1.2249 - accuracy: 0.4906\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 685us/step - loss: 1.2092 - accuracy: 0.5094\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 711us/step - loss: 1.2080 - accuracy: 0.4969\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 669us/step - loss: 1.2324 - accuracy: 0.4906\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 674us/step - loss: 1.2196 - accuracy: 0.5094\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 678us/step - loss: 1.2375 - accuracy: 0.4843\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 697us/step - loss: 1.2225 - accuracy: 0.4780\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 699us/step - loss: 1.2018 - accuracy: 0.4969\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 677us/step - loss: 1.2025 - accuracy: 0.5157\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 690us/step - loss: 1.2088 - accuracy: 0.4654\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 801us/step - loss: 1.2318 - accuracy: 0.5031\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 757us/step - loss: 1.1866 - accuracy: 0.5157\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 726us/step - loss: 1.1947 - accuracy: 0.4780\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 698us/step - loss: 1.2150 - accuracy: 0.4906\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 685us/step - loss: 1.2022 - accuracy: 0.4969\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 675us/step - loss: 1.2120 - accuracy: 0.4906\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 676us/step - loss: 1.2054 - accuracy: 0.5094\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 675us/step - loss: 1.1956 - accuracy: 0.4906\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 683us/step - loss: 1.2090 - accuracy: 0.5157\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 685us/step - loss: 1.2005 - accuracy: 0.5220\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 698us/step - loss: 1.2104 - accuracy: 0.5031\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 741us/step - loss: 1.1871 - accuracy: 0.4969\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 720us/step - loss: 1.2104 - accuracy: 0.5094\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 706us/step - loss: 1.1824 - accuracy: 0.5094\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 717us/step - loss: 1.1993 - accuracy: 0.5031\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 692us/step - loss: 1.1759 - accuracy: 0.5094\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 708us/step - loss: 1.1957 - accuracy: 0.5220\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 675us/step - loss: 1.1905 - accuracy: 0.5094\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 687us/step - loss: 1.1675 - accuracy: 0.4969\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 713us/step - loss: 1.1976 - accuracy: 0.5283\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 704us/step - loss: 1.1783 - accuracy: 0.5031\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 672us/step - loss: 1.2094 - accuracy: 0.5094\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 711us/step - loss: 1.1696 - accuracy: 0.5031\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 679us/step - loss: 1.1586 - accuracy: 0.5157\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 716us/step - loss: 1.1811 - accuracy: 0.4906\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 711us/step - loss: 1.1677 - accuracy: 0.4969\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 678us/step - loss: 1.1625 - accuracy: 0.4969\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 722us/step - loss: 1.1807 - accuracy: 0.5031\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 743us/step - loss: 1.1548 - accuracy: 0.5157\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 691us/step - loss: 1.2115 - accuracy: 0.5346\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 649us/step - loss: 1.1798 - accuracy: 0.4843\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 699us/step - loss: 1.1582 - accuracy: 0.4969\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 704us/step - loss: 1.1518 - accuracy: 0.5031\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 717us/step - loss: 1.1285 - accuracy: 0.5031\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 808us/step - loss: 1.1473 - accuracy: 0.5157\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 783us/step - loss: 1.1806 - accuracy: 0.5094\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 607us/step - loss: 1.1406 - accuracy: 0.5157\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 675us/step - loss: 1.1426 - accuracy: 0.5031\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 671us/step - loss: 1.1746 - accuracy: 0.5157\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 656us/step - loss: 1.1589 - accuracy: 0.4843\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 659us/step - loss: 1.1435 - accuracy: 0.4969\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 644us/step - loss: 1.1111 - accuracy: 0.5157\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 693us/step - loss: 1.0983 - accuracy: 0.5094\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 671us/step - loss: 1.1280 - accuracy: 0.5409\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 644us/step - loss: 1.0876 - accuracy: 0.5220\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 685us/step - loss: 1.0915 - accuracy: 0.5220\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 658us/step - loss: 1.1014 - accuracy: 0.5409\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 655us/step - loss: 1.1182 - accuracy: 0.5346\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 643us/step - loss: 1.0697 - accuracy: 0.5472\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 678us/step - loss: 1.0710 - accuracy: 0.5660\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 680us/step - loss: 1.0502 - accuracy: 0.5535\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 641us/step - loss: 1.0326 - accuracy: 0.5723\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 640us/step - loss: 1.0392 - accuracy: 0.5597\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 664us/step - loss: 0.9963 - accuracy: 0.5912\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 652us/step - loss: 1.0573 - accuracy: 0.5597\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 648us/step - loss: 1.0671 - accuracy: 0.5660\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.9895 - accuracy: 0.5849\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 642us/step - loss: 0.9198 - accuracy: 0.5975\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 708us/step - loss: 0.8417 - accuracy: 0.6730\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 657us/step - loss: 0.8587 - accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 647us/step - loss: 0.7362 - accuracy: 0.7044\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 656us/step - loss: 0.7809 - accuracy: 0.6918\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 660us/step - loss: 1.0237 - accuracy: 0.6164\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 656us/step - loss: 0.7220 - accuracy: 0.7421\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 669us/step - loss: 0.7120 - accuracy: 0.7170\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 667us/step - loss: 0.6767 - accuracy: 0.7358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d35ea8490>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y_oh, epochs = 100, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0beeb8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 998us/step - loss: 0.6227 - accuracy: 0.7736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6227254271507263, 0.7735849022865295]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x, y_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ec138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c78d5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c693a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0c165fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_oh, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "28b30677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 20)                120       \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 16)                336       \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 655\n",
      "Trainable params: 655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim = 5, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fffe4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "53d3c9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 0s 730us/step - loss: 26.8427 - accuracy: 0.0672\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 707us/step - loss: 3.0386 - accuracy: 0.3277\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 746us/step - loss: 2.3666 - accuracy: 0.3277\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 674us/step - loss: 2.0566 - accuracy: 0.3950\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 711us/step - loss: 1.9464 - accuracy: 0.4706\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 680us/step - loss: 1.6278 - accuracy: 0.4790\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 697us/step - loss: 1.8280 - accuracy: 0.4622\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 723us/step - loss: 1.6066 - accuracy: 0.4790\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 662us/step - loss: 1.4554 - accuracy: 0.4874\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 718us/step - loss: 1.8275 - accuracy: 0.4874\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 712us/step - loss: 1.3562 - accuracy: 0.5378\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 669us/step - loss: 1.5261 - accuracy: 0.5042\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 701us/step - loss: 1.1473 - accuracy: 0.5882\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 702us/step - loss: 1.3723 - accuracy: 0.5126\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 703us/step - loss: 1.2006 - accuracy: 0.5210\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 681us/step - loss: 1.1927 - accuracy: 0.5546\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 682us/step - loss: 1.0904 - accuracy: 0.5882\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 750us/step - loss: 1.0973 - accuracy: 0.5294\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 722us/step - loss: 1.6838 - accuracy: 0.4874\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 717us/step - loss: 2.2175 - accuracy: 0.4370\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 712us/step - loss: 2.1988 - accuracy: 0.4370\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 745us/step - loss: 1.7160 - accuracy: 0.4874\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 687us/step - loss: 1.4951 - accuracy: 0.5042\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 678us/step - loss: 1.2721 - accuracy: 0.5798\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 710us/step - loss: 1.4559 - accuracy: 0.4706\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 710us/step - loss: 1.1261 - accuracy: 0.5546\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 672us/step - loss: 1.0286 - accuracy: 0.5798\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 692us/step - loss: 0.9419 - accuracy: 0.6134\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 667us/step - loss: 1.1263 - accuracy: 0.5546\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 734us/step - loss: 1.0962 - accuracy: 0.5546\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 677us/step - loss: 1.6622 - accuracy: 0.5210\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 667us/step - loss: 1.4048 - accuracy: 0.5546\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 708us/step - loss: 1.2306 - accuracy: 0.5210\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 699us/step - loss: 0.9236 - accuracy: 0.6050\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 680us/step - loss: 0.9804 - accuracy: 0.6303\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 699us/step - loss: 1.0143 - accuracy: 0.6387\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 668us/step - loss: 1.2393 - accuracy: 0.5798\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 722us/step - loss: 1.1309 - accuracy: 0.5294\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 730us/step - loss: 1.3904 - accuracy: 0.5042\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 730us/step - loss: 1.1407 - accuracy: 0.5630\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 700us/step - loss: 0.9872 - accuracy: 0.6218\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 680us/step - loss: 1.0965 - accuracy: 0.6471\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.9521 - accuracy: 0.6218\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 756us/step - loss: 0.9235 - accuracy: 0.6723\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 744us/step - loss: 1.3274 - accuracy: 0.5546\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 664us/step - loss: 1.2572 - accuracy: 0.5462\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 629us/step - loss: 1.1908 - accuracy: 0.5462\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 671us/step - loss: 0.9670 - accuracy: 0.5966\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 684us/step - loss: 0.9395 - accuracy: 0.6050\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 662us/step - loss: 0.9994 - accuracy: 0.5798\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 658us/step - loss: 0.9717 - accuracy: 0.6050\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 666us/step - loss: 0.9473 - accuracy: 0.6218\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 673us/step - loss: 0.9339 - accuracy: 0.6134\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 694us/step - loss: 0.9749 - accuracy: 0.6303\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 673us/step - loss: 1.0938 - accuracy: 0.5714\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 650us/step - loss: 1.5310 - accuracy: 0.4874\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 664us/step - loss: 1.1466 - accuracy: 0.6471\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 675us/step - loss: 0.9682 - accuracy: 0.6303\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 681us/step - loss: 1.0201 - accuracy: 0.6303\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 670us/step - loss: 1.0062 - accuracy: 0.6134\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 714us/step - loss: 1.0521 - accuracy: 0.6471\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 654us/step - loss: 1.5264 - accuracy: 0.5210\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 669us/step - loss: 1.4657 - accuracy: 0.5714\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 677us/step - loss: 1.0204 - accuracy: 0.5966\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 679us/step - loss: 1.0377 - accuracy: 0.6050\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.9878 - accuracy: 0.5798\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 678us/step - loss: 0.9077 - accuracy: 0.6471\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 663us/step - loss: 0.9349 - accuracy: 0.6975\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 680us/step - loss: 0.9766 - accuracy: 0.6639\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 643us/step - loss: 0.8526 - accuracy: 0.6891\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 680us/step - loss: 0.8358 - accuracy: 0.6975\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 711us/step - loss: 0.8692 - accuracy: 0.6471\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.8521 - accuracy: 0.6975\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 682us/step - loss: 0.9319 - accuracy: 0.6639\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 674us/step - loss: 0.8546 - accuracy: 0.7059\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 673us/step - loss: 0.8448 - accuracy: 0.6723\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 689us/step - loss: 1.0768 - accuracy: 0.5798\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 670us/step - loss: 0.9910 - accuracy: 0.6134\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 651us/step - loss: 0.9086 - accuracy: 0.6471\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.8733 - accuracy: 0.6723\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 644us/step - loss: 0.8317 - accuracy: 0.6807\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 691us/step - loss: 0.7803 - accuracy: 0.7143\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.9726 - accuracy: 0.6555\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 658us/step - loss: 0.8422 - accuracy: 0.7227\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 658us/step - loss: 0.7934 - accuracy: 0.6555\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 658us/step - loss: 0.9965 - accuracy: 0.6387\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 663us/step - loss: 0.7481 - accuracy: 0.7143\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.8249 - accuracy: 0.6639\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 707us/step - loss: 0.9984 - accuracy: 0.6639\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.8297 - accuracy: 0.6975\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.7651 - accuracy: 0.7059\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 697us/step - loss: 0.8211 - accuracy: 0.7059\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 687us/step - loss: 1.0339 - accuracy: 0.6387\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 658us/step - loss: 0.8117 - accuracy: 0.6639\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 666us/step - loss: 0.8138 - accuracy: 0.6807\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 677us/step - loss: 0.7875 - accuracy: 0.6975\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 674us/step - loss: 0.7536 - accuracy: 0.7059\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 687us/step - loss: 0.8972 - accuracy: 0.6639\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 673us/step - loss: 1.9281 - accuracy: 0.5294\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 662us/step - loss: 0.9026 - accuracy: 0.6387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d36fb9fd0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7f139d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7668 - accuracy: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7667639255523682, 0.7749999761581421]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45dcf81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be153c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "24f8d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train_sc = scaler.fit_transform(x_train)\n",
    "x_test_sc = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1ef6a672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (None, 128)               768       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 68)                8772      \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 36)                2484      \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 7)                 259       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,283\n",
      "Trainable params: 12,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim = 5, activation = 'relu'))\n",
    "model.add(Dense(68, activation = 'relu'))\n",
    "model.add(Dense(36, activation = 'relu'))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c9224da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fd140ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8354 - accuracy: 0.2421 - val_loss: 1.5913 - val_accuracy: 0.7083\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6526 - accuracy: 0.3684 - val_loss: 1.4397 - val_accuracy: 0.7083\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.5103 - accuracy: 0.5158 - val_loss: 1.3072 - val_accuracy: 0.7083\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3605 - accuracy: 0.6000 - val_loss: 1.1245 - val_accuracy: 0.7083\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.1953 - accuracy: 0.6842 - val_loss: 0.9951 - val_accuracy: 0.7083\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.0413 - accuracy: 0.6947 - val_loss: 0.8672 - val_accuracy: 0.7083\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.8947 - accuracy: 0.7263 - val_loss: 0.7267 - val_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.7978 - accuracy: 0.7474 - val_loss: 0.6828 - val_accuracy: 0.7917\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.7474 - val_loss: 0.6005 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.7789 - val_loss: 0.5728 - val_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.8211 - val_loss: 0.5075 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5396 - accuracy: 0.7895 - val_loss: 0.4967 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7789 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8000 - val_loss: 0.4306 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7895 - val_loss: 0.4097 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.8000 - val_loss: 0.4357 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.8211 - val_loss: 0.3892 - val_accuracy: 0.9167\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8105 - val_loss: 0.3821 - val_accuracy: 0.8750\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4133 - accuracy: 0.8105 - val_loss: 0.4400 - val_accuracy: 0.9167\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7895 - val_loss: 0.3612 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3816 - accuracy: 0.8421 - val_loss: 0.3735 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8211 - val_loss: 0.3560 - val_accuracy: 0.8750\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8211 - val_loss: 0.3516 - val_accuracy: 0.8750\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3931 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8632 - val_loss: 0.3230 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8211 - val_loss: 0.3438 - val_accuracy: 0.9167\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8526 - val_loss: 0.3767 - val_accuracy: 0.8750\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8316 - val_loss: 0.3549 - val_accuracy: 0.9167\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8526 - val_loss: 0.3864 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.8316 - val_loss: 0.3270 - val_accuracy: 0.9167\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8632 - val_loss: 0.3373 - val_accuracy: 0.9167\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8526 - val_loss: 0.3471 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8632 - val_loss: 0.3440 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8632 - val_loss: 0.3557 - val_accuracy: 0.7917\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8632 - val_loss: 0.3631 - val_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8421 - val_loss: 0.3855 - val_accuracy: 0.7917\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.8632 - val_loss: 0.3630 - val_accuracy: 0.8750\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8316 - val_loss: 0.3445 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8632 - val_loss: 0.3413 - val_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8632 - val_loss: 0.3539 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8632 - val_loss: 0.3594 - val_accuracy: 0.8750\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8632 - val_loss: 0.3434 - val_accuracy: 0.8750\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8632 - val_loss: 0.3828 - val_accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8526 - val_loss: 0.3418 - val_accuracy: 0.7917\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.8526 - val_loss: 0.3382 - val_accuracy: 0.9167\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8632 - val_loss: 0.3983 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8526 - val_loss: 0.3300 - val_accuracy: 0.9167\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8737 - val_loss: 0.3323 - val_accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.8737 - val_loss: 0.3326 - val_accuracy: 0.9167\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.8526 - val_loss: 0.3253 - val_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3116 - accuracy: 0.8632 - val_loss: 0.3348 - val_accuracy: 0.9583\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8421 - val_loss: 0.3898 - val_accuracy: 0.8750\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8105 - val_loss: 0.3622 - val_accuracy: 0.8750\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3178 - accuracy: 0.8211 - val_loss: 0.3960 - val_accuracy: 0.7917\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.8632 - val_loss: 0.3354 - val_accuracy: 0.9167\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2687 - accuracy: 0.8842 - val_loss: 0.3809 - val_accuracy: 0.8750\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8632 - val_loss: 0.3519 - val_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.8632 - val_loss: 0.3507 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.8842 - val_loss: 0.3144 - val_accuracy: 0.9167\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.8737 - val_loss: 0.3467 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.8737 - val_loss: 0.3268 - val_accuracy: 0.9167\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2938 - accuracy: 0.8526 - val_loss: 0.3496 - val_accuracy: 0.8750\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8316 - val_loss: 0.3769 - val_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2703 - accuracy: 0.8842 - val_loss: 0.3700 - val_accuracy: 0.7917\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2827 - accuracy: 0.8842 - val_loss: 0.4155 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2727 - accuracy: 0.8526 - val_loss: 0.4397 - val_accuracy: 0.7083\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8632 - val_loss: 0.4522 - val_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.8737 - val_loss: 0.3817 - val_accuracy: 0.9583\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8632 - val_loss: 0.3301 - val_accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.8737 - val_loss: 0.4039 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8526 - val_loss: 0.4258 - val_accuracy: 0.7083\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2770 - accuracy: 0.8737 - val_loss: 0.4150 - val_accuracy: 0.7917\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2799 - accuracy: 0.8526 - val_loss: 0.3691 - val_accuracy: 0.9167\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.8632 - val_loss: 0.3126 - val_accuracy: 0.9167\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2819 - accuracy: 0.8737 - val_loss: 0.3416 - val_accuracy: 0.9167\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2749 - accuracy: 0.8632 - val_loss: 0.3355 - val_accuracy: 0.9167\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.8842 - val_loss: 0.3565 - val_accuracy: 0.9167\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.8842 - val_loss: 0.3314 - val_accuracy: 0.9167\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.8632 - val_loss: 0.3794 - val_accuracy: 0.8750\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2926 - accuracy: 0.8526 - val_loss: 0.3735 - val_accuracy: 0.8750\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.8842 - val_loss: 0.3358 - val_accuracy: 0.8750\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2925 - accuracy: 0.8737 - val_loss: 0.3445 - val_accuracy: 0.9167\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8737 - val_loss: 0.3417 - val_accuracy: 0.9583\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.8632 - val_loss: 0.3486 - val_accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.8632 - val_loss: 0.3141 - val_accuracy: 0.9167\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.8737 - val_loss: 0.3251 - val_accuracy: 0.9167\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2341 - accuracy: 0.8737 - val_loss: 0.3775 - val_accuracy: 0.7917\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8947 - val_loss: 0.3024 - val_accuracy: 0.9167\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.8842 - val_loss: 0.3171 - val_accuracy: 0.9583\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.8842 - val_loss: 0.3133 - val_accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.8947 - val_loss: 0.3056 - val_accuracy: 0.9167\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.8842 - val_loss: 0.3382 - val_accuracy: 0.9167\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.9053 - val_loss: 0.2903 - val_accuracy: 0.9167\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2424 - accuracy: 0.9053 - val_loss: 0.5321 - val_accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8737 - val_loss: 0.3719 - val_accuracy: 0.7917\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2553 - accuracy: 0.8632 - val_loss: 0.3555 - val_accuracy: 0.9167\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2854 - accuracy: 0.8947 - val_loss: 0.3407 - val_accuracy: 0.7917\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.8737 - val_loss: 0.3308 - val_accuracy: 0.8750\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.8842 - val_loss: 0.3060 - val_accuracy: 0.9167\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.8947 - val_loss: 0.3975 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_sc, y_train, epochs = 100, batch_size = 2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f0336c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 3.4654 - accuracy: 0.2750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.465449094772339, 0.2750000059604645]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "aeff395d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26d3a42f7f0>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], c = 'r')\n",
    "plt.plot(hist.history['val_loss'], c = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724bc1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
