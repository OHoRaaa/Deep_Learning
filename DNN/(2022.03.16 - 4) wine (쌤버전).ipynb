{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cf913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a36635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba2e247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4     5     6       7     8     9    10  11  12\n",
       "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
       "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
       "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1\n",
       "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   6   1\n",
       "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/wine.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845c7a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b73ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "6492    0\n",
       "6493    0\n",
       "6494    0\n",
       "6495    0\n",
       "6496    0\n",
       "Name: 12, Length: 6497, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be5933e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48bb932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classification, muliti classification 두 가지 방식으로 nural network model을 만들고 \n",
    "# train data로 학습시킨 후 test data로 accuracy를 평가하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15ea5140",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, 12].values\n",
    "x = df.iloc[:, :12].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38c8797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee6a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oh = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d32499d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f24320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62a70b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c98cbeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c9764a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d13070cf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 36)                468       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 18)                666       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 9)                 171       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,315\n",
      "Trainable params: 1,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(36, activation='relu', input_dim=12))\n",
    "model.add(Dense(18, activation='relu'))\n",
    "model.add(Dense(9, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2e2fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3674f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4872, 12)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d69eca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4872,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bbd1474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfef521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "244/244 [==============================] - 1s 847us/step - loss: 0.2216 - accuracy: 0.9208\n",
      "Epoch 2/50\n",
      "244/244 [==============================] - 0s 823us/step - loss: 0.1876 - accuracy: 0.9349\n",
      "Epoch 3/50\n",
      "244/244 [==============================] - 0s 816us/step - loss: 0.1734 - accuracy: 0.9419\n",
      "Epoch 4/50\n",
      "244/244 [==============================] - 0s 855us/step - loss: 0.1520 - accuracy: 0.9493\n",
      "Epoch 5/50\n",
      "244/244 [==============================] - 0s 846us/step - loss: 0.1369 - accuracy: 0.9530\n",
      "Epoch 6/50\n",
      "244/244 [==============================] - 0s 810us/step - loss: 0.1210 - accuracy: 0.9602\n",
      "Epoch 7/50\n",
      "244/244 [==============================] - 0s 840us/step - loss: 0.1244 - accuracy: 0.9589\n",
      "Epoch 8/50\n",
      "244/244 [==============================] - 0s 851us/step - loss: 0.1172 - accuracy: 0.9587\n",
      "Epoch 9/50\n",
      "244/244 [==============================] - 0s 823us/step - loss: 0.1074 - accuracy: 0.9665\n",
      "Epoch 10/50\n",
      "244/244 [==============================] - 0s 814us/step - loss: 0.0996 - accuracy: 0.9665\n",
      "Epoch 11/50\n",
      "244/244 [==============================] - 0s 899us/step - loss: 0.0908 - accuracy: 0.9719\n",
      "Epoch 12/50\n",
      "244/244 [==============================] - 0s 944us/step - loss: 0.0852 - accuracy: 0.9729\n",
      "Epoch 13/50\n",
      "244/244 [==============================] - 0s 836us/step - loss: 0.0844 - accuracy: 0.9743\n",
      "Epoch 14/50\n",
      "244/244 [==============================] - 0s 902us/step - loss: 0.0889 - accuracy: 0.9739\n",
      "Epoch 15/50\n",
      "244/244 [==============================] - 0s 903us/step - loss: 0.0888 - accuracy: 0.9737\n",
      "Epoch 16/50\n",
      "244/244 [==============================] - 0s 936us/step - loss: 0.0852 - accuracy: 0.9752\n",
      "Epoch 17/50\n",
      "244/244 [==============================] - 0s 838us/step - loss: 0.0777 - accuracy: 0.9780\n",
      "Epoch 18/50\n",
      "244/244 [==============================] - 0s 822us/step - loss: 0.0816 - accuracy: 0.9752\n",
      "Epoch 19/50\n",
      "244/244 [==============================] - 0s 822us/step - loss: 0.0699 - accuracy: 0.9793\n",
      "Epoch 20/50\n",
      "244/244 [==============================] - 0s 946us/step - loss: 0.0777 - accuracy: 0.9750\n",
      "Epoch 21/50\n",
      "244/244 [==============================] - 0s 805us/step - loss: 0.0789 - accuracy: 0.9780\n",
      "Epoch 22/50\n",
      "244/244 [==============================] - 0s 904us/step - loss: 0.0711 - accuracy: 0.9774\n",
      "Epoch 23/50\n",
      "244/244 [==============================] - 0s 921us/step - loss: 0.0745 - accuracy: 0.9776\n",
      "Epoch 24/50\n",
      "244/244 [==============================] - 0s 910us/step - loss: 0.0670 - accuracy: 0.9799\n",
      "Epoch 25/50\n",
      "244/244 [==============================] - 0s 866us/step - loss: 0.0722 - accuracy: 0.9780\n",
      "Epoch 26/50\n",
      "244/244 [==============================] - 0s 917us/step - loss: 0.0748 - accuracy: 0.9758\n",
      "Epoch 27/50\n",
      "244/244 [==============================] - 0s 828us/step - loss: 0.0659 - accuracy: 0.9803\n",
      "Epoch 28/50\n",
      "244/244 [==============================] - 0s 825us/step - loss: 0.0696 - accuracy: 0.9807\n",
      "Epoch 29/50\n",
      "244/244 [==============================] - 0s 809us/step - loss: 0.0688 - accuracy: 0.9780\n",
      "Epoch 30/50\n",
      "244/244 [==============================] - 0s 799us/step - loss: 0.0704 - accuracy: 0.9795\n",
      "Epoch 31/50\n",
      "244/244 [==============================] - 0s 851us/step - loss: 0.0634 - accuracy: 0.9809\n",
      "Epoch 32/50\n",
      "244/244 [==============================] - 0s 883us/step - loss: 0.0639 - accuracy: 0.9813\n",
      "Epoch 33/50\n",
      "244/244 [==============================] - 0s 924us/step - loss: 0.0663 - accuracy: 0.9805\n",
      "Epoch 34/50\n",
      "244/244 [==============================] - 0s 916us/step - loss: 0.0638 - accuracy: 0.9809\n",
      "Epoch 35/50\n",
      "244/244 [==============================] - 0s 903us/step - loss: 0.0609 - accuracy: 0.9826\n",
      "Epoch 36/50\n",
      "244/244 [==============================] - 0s 833us/step - loss: 0.0793 - accuracy: 0.9750\n",
      "Epoch 37/50\n",
      "244/244 [==============================] - 0s 794us/step - loss: 0.0674 - accuracy: 0.9799\n",
      "Epoch 38/50\n",
      "244/244 [==============================] - 0s 881us/step - loss: 0.0618 - accuracy: 0.9811\n",
      "Epoch 39/50\n",
      "244/244 [==============================] - 0s 884us/step - loss: 0.0597 - accuracy: 0.9828\n",
      "Epoch 40/50\n",
      "244/244 [==============================] - 0s 915us/step - loss: 0.0615 - accuracy: 0.9811\n",
      "Epoch 41/50\n",
      "244/244 [==============================] - 0s 964us/step - loss: 0.0639 - accuracy: 0.9801\n",
      "Epoch 42/50\n",
      "244/244 [==============================] - 0s 964us/step - loss: 0.0647 - accuracy: 0.9811\n",
      "Epoch 43/50\n",
      "244/244 [==============================] - 0s 935us/step - loss: 0.0630 - accuracy: 0.9787\n",
      "Epoch 44/50\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9787\n",
      "Epoch 45/50\n",
      "244/244 [==============================] - 0s 872us/step - loss: 0.0602 - accuracy: 0.9830\n",
      "Epoch 46/50\n",
      "244/244 [==============================] - 0s 946us/step - loss: 0.0631 - accuracy: 0.9815\n",
      "Epoch 47/50\n",
      "244/244 [==============================] - 0s 821us/step - loss: 0.0614 - accuracy: 0.9807\n",
      "Epoch 48/50\n",
      "244/244 [==============================] - 0s 850us/step - loss: 0.0545 - accuracy: 0.9838\n",
      "Epoch 49/50\n",
      "244/244 [==============================] - 0s 858us/step - loss: 0.0597 - accuracy: 0.9803\n",
      "Epoch 50/50\n",
      "244/244 [==============================] - 0s 863us/step - loss: 0.0631 - accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x270476a1a60>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.astype(float), y_train, epochs=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b959b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 698us/step - loss: 0.0595 - accuracy: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.059461187571287155, 0.9821538329124451]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d114d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ef595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d43c8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b405f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 36)                468       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 18)                666       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 171       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,325\n",
      "Trainable params: 1,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(36, activation='relu', input_dim=12))\n",
    "model.add(Dense(18, activation='relu'))\n",
    "model.add(Dense(9, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71640536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6504d6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "244/244 [==============================] - 0s 743us/step - loss: 0.1968 - accuracy: 0.9358\n",
      "Epoch 2/50\n",
      "244/244 [==============================] - 0s 729us/step - loss: 0.1654 - accuracy: 0.9423\n",
      "Epoch 3/50\n",
      "244/244 [==============================] - 0s 749us/step - loss: 0.1517 - accuracy: 0.9468\n",
      "Epoch 4/50\n",
      "244/244 [==============================] - 0s 748us/step - loss: 0.1386 - accuracy: 0.9530\n",
      "Epoch 5/50\n",
      "244/244 [==============================] - 0s 730us/step - loss: 0.1284 - accuracy: 0.9563\n",
      "Epoch 6/50\n",
      "244/244 [==============================] - 0s 725us/step - loss: 0.1132 - accuracy: 0.9612\n",
      "Epoch 7/50\n",
      "244/244 [==============================] - 0s 730us/step - loss: 0.1082 - accuracy: 0.9649\n",
      "Epoch 8/50\n",
      "244/244 [==============================] - 0s 721us/step - loss: 0.0924 - accuracy: 0.9692\n",
      "Epoch 9/50\n",
      "244/244 [==============================] - 0s 720us/step - loss: 0.0928 - accuracy: 0.9692\n",
      "Epoch 10/50\n",
      "244/244 [==============================] - 0s 723us/step - loss: 0.0754 - accuracy: 0.9760\n",
      "Epoch 11/50\n",
      "244/244 [==============================] - 0s 715us/step - loss: 0.0783 - accuracy: 0.9756\n",
      "Epoch 12/50\n",
      "244/244 [==============================] - 0s 725us/step - loss: 0.0816 - accuracy: 0.9745\n",
      "Epoch 13/50\n",
      "244/244 [==============================] - 0s 734us/step - loss: 0.0656 - accuracy: 0.9803\n",
      "Epoch 14/50\n",
      "244/244 [==============================] - 0s 726us/step - loss: 0.0760 - accuracy: 0.9764\n",
      "Epoch 15/50\n",
      "244/244 [==============================] - 0s 719us/step - loss: 0.0723 - accuracy: 0.9762\n",
      "Epoch 16/50\n",
      "244/244 [==============================] - 0s 754us/step - loss: 0.0722 - accuracy: 0.9768\n",
      "Epoch 17/50\n",
      "244/244 [==============================] - 0s 719us/step - loss: 0.0643 - accuracy: 0.9813\n",
      "Epoch 18/50\n",
      "244/244 [==============================] - 0s 717us/step - loss: 0.0592 - accuracy: 0.9828\n",
      "Epoch 19/50\n",
      "244/244 [==============================] - 0s 729us/step - loss: 0.0612 - accuracy: 0.9809\n",
      "Epoch 20/50\n",
      "244/244 [==============================] - 0s 729us/step - loss: 0.0674 - accuracy: 0.9791\n",
      "Epoch 21/50\n",
      "244/244 [==============================] - 0s 722us/step - loss: 0.0572 - accuracy: 0.9821\n",
      "Epoch 22/50\n",
      "244/244 [==============================] - 0s 729us/step - loss: 0.0606 - accuracy: 0.9826\n",
      "Epoch 23/50\n",
      "244/244 [==============================] - 0s 715us/step - loss: 0.0591 - accuracy: 0.9834\n",
      "Epoch 24/50\n",
      "244/244 [==============================] - 0s 708us/step - loss: 0.0611 - accuracy: 0.9809\n",
      "Epoch 25/50\n",
      "244/244 [==============================] - 0s 723us/step - loss: 0.0563 - accuracy: 0.9830\n",
      "Epoch 26/50\n",
      "244/244 [==============================] - 0s 825us/step - loss: 0.0612 - accuracy: 0.9793\n",
      "Epoch 27/50\n",
      "244/244 [==============================] - 0s 684us/step - loss: 0.0596 - accuracy: 0.9821\n",
      "Epoch 28/50\n",
      "244/244 [==============================] - 0s 720us/step - loss: 0.0564 - accuracy: 0.9838\n",
      "Epoch 29/50\n",
      "244/244 [==============================] - 0s 722us/step - loss: 0.0531 - accuracy: 0.9846\n",
      "Epoch 30/50\n",
      "244/244 [==============================] - 0s 723us/step - loss: 0.0523 - accuracy: 0.9840\n",
      "Epoch 31/50\n",
      "244/244 [==============================] - 0s 733us/step - loss: 0.0607 - accuracy: 0.9801\n",
      "Epoch 32/50\n",
      "244/244 [==============================] - 0s 741us/step - loss: 0.0527 - accuracy: 0.9834\n",
      "Epoch 33/50\n",
      "244/244 [==============================] - 0s 728us/step - loss: 0.0492 - accuracy: 0.9860\n",
      "Epoch 34/50\n",
      "244/244 [==============================] - 0s 723us/step - loss: 0.0583 - accuracy: 0.9821\n",
      "Epoch 35/50\n",
      "244/244 [==============================] - 0s 729us/step - loss: 0.0487 - accuracy: 0.9865\n",
      "Epoch 36/50\n",
      "244/244 [==============================] - 0s 723us/step - loss: 0.0586 - accuracy: 0.9813\n",
      "Epoch 37/50\n",
      "244/244 [==============================] - 0s 717us/step - loss: 0.0515 - accuracy: 0.9848\n",
      "Epoch 38/50\n",
      "244/244 [==============================] - 0s 717us/step - loss: 0.0477 - accuracy: 0.9862\n",
      "Epoch 39/50\n",
      "244/244 [==============================] - 0s 713us/step - loss: 0.0549 - accuracy: 0.9828\n",
      "Epoch 40/50\n",
      "244/244 [==============================] - 0s 712us/step - loss: 0.0484 - accuracy: 0.9852\n",
      "Epoch 41/50\n",
      "244/244 [==============================] - 0s 754us/step - loss: 0.0536 - accuracy: 0.9823\n",
      "Epoch 42/50\n",
      "244/244 [==============================] - 0s 712us/step - loss: 0.0478 - accuracy: 0.9860\n",
      "Epoch 43/50\n",
      "244/244 [==============================] - 0s 728us/step - loss: 0.0454 - accuracy: 0.9871\n",
      "Epoch 44/50\n",
      "244/244 [==============================] - 0s 728us/step - loss: 0.0476 - accuracy: 0.9871\n",
      "Epoch 45/50\n",
      "244/244 [==============================] - 0s 717us/step - loss: 0.0442 - accuracy: 0.9877\n",
      "Epoch 46/50\n",
      "244/244 [==============================] - 0s 705us/step - loss: 0.0465 - accuracy: 0.9854\n",
      "Epoch 47/50\n",
      "244/244 [==============================] - 0s 722us/step - loss: 0.0496 - accuracy: 0.9858\n",
      "Epoch 48/50\n",
      "244/244 [==============================] - 0s 725us/step - loss: 0.0471 - accuracy: 0.9848\n",
      "Epoch 49/50\n",
      "244/244 [==============================] - 0s 736us/step - loss: 0.0490 - accuracy: 0.9856\n",
      "Epoch 50/50\n",
      "244/244 [==============================] - 0s 720us/step - loss: 0.0405 - accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x188ff8faeb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.astype(float), y_train, epochs=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d7abb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 627us/step - loss: 0.0574 - accuracy: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.057422250509262085, 0.9852307438850403]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70d27b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./deep_model/wine_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd04ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6299d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0f617c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_oh)\n",
    "model = Sequential()\n",
    "model.add(Dense(36, activation='relu', input_dim=12))\n",
    "model.add(Dense(18, activation='relu'))\n",
    "model.add(Dense(9, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# model.summary()\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "251dff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a4ae78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './deep_model/model_check'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fa0dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62d48a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = './deep_model/model_check/{epoch:02d}-{val_loss:4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor='val_loss', verbose=1, \\\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2124e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 1.5522 - accuracy: 0.7321  \n",
      "Epoch 1: val_loss improved from inf to 0.19177, saving model to ./deep_model/model_check\\01-0.191766.hdf5\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 1.3800 - accuracy: 0.7572 - val_loss: 0.1918 - val_accuracy: 0.9374\n",
      "Epoch 2/100\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.2154 - accuracy: 0.9255\n",
      "Epoch 2: val_loss improved from 0.19177 to 0.18848, saving model to ./deep_model/model_check\\02-0.188477.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.9258 - val_loss: 0.1885 - val_accuracy: 0.9385\n",
      "Epoch 3/100\n",
      "55/78 [====================>.........] - ETA: 0s - loss: 0.2039 - accuracy: 0.9291\n",
      "Epoch 3: val_loss improved from 0.18848 to 0.18585, saving model to ./deep_model/model_check\\03-0.185848.hdf5\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9284 - val_loss: 0.1858 - val_accuracy: 0.9395\n",
      "Epoch 4/100\n",
      "61/78 [======================>.......] - ETA: 0s - loss: 0.2012 - accuracy: 0.9321\n",
      "Epoch 4: val_loss did not improve from 0.18585\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.9299 - val_loss: 0.1882 - val_accuracy: 0.9415\n",
      "Epoch 5/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.2020 - accuracy: 0.9309\n",
      "Epoch 5: val_loss improved from 0.18585 to 0.17885, saving model to ./deep_model/model_check\\05-0.178853.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.9320 - val_loss: 0.1789 - val_accuracy: 0.9405\n",
      "Epoch 6/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.1959 - accuracy: 0.9321\n",
      "Epoch 6: val_loss improved from 0.17885 to 0.17868, saving model to ./deep_model/model_check\\06-0.178679.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.9312 - val_loss: 0.1787 - val_accuracy: 0.9426\n",
      "Epoch 7/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.2004 - accuracy: 0.9312\n",
      "Epoch 7: val_loss improved from 0.17868 to 0.17716, saving model to ./deep_model/model_check\\07-0.177156.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9325 - val_loss: 0.1772 - val_accuracy: 0.9405\n",
      "Epoch 8/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.1982 - accuracy: 0.9303\n",
      "Epoch 8: val_loss improved from 0.17716 to 0.17270, saving model to ./deep_model/model_check\\08-0.172698.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.9315 - val_loss: 0.1727 - val_accuracy: 0.9426\n",
      "Epoch 9/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.1947 - accuracy: 0.9297\n",
      "Epoch 9: val_loss improved from 0.17270 to 0.16958, saving model to ./deep_model/model_check\\09-0.169578.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9330 - val_loss: 0.1696 - val_accuracy: 0.9426\n",
      "Epoch 10/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.1840 - accuracy: 0.9338\n",
      "Epoch 10: val_loss improved from 0.16958 to 0.16841, saving model to ./deep_model/model_check\\10-0.168408.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9341 - val_loss: 0.1684 - val_accuracy: 0.9436\n",
      "Epoch 11/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.1778 - accuracy: 0.9379\n",
      "Epoch 11: val_loss improved from 0.16841 to 0.16270, saving model to ./deep_model/model_check\\11-0.162698.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.9369 - val_loss: 0.1627 - val_accuracy: 0.9528\n",
      "Epoch 12/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.1723 - accuracy: 0.9418\n",
      "Epoch 12: val_loss improved from 0.16270 to 0.14634, saving model to ./deep_model/model_check\\12-0.146338.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9428 - val_loss: 0.1463 - val_accuracy: 0.9528\n",
      "Epoch 13/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.1578 - accuracy: 0.9421\n",
      "Epoch 13: val_loss improved from 0.14634 to 0.12501, saving model to ./deep_model/model_check\\13-0.125010.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9435 - val_loss: 0.1250 - val_accuracy: 0.9621\n",
      "Epoch 14/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.1449 - accuracy: 0.9471\n",
      "Epoch 14: val_loss improved from 0.12501 to 0.10975, saving model to ./deep_model/model_check\\14-0.109746.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9479 - val_loss: 0.1097 - val_accuracy: 0.9579\n",
      "Epoch 15/100\n",
      "71/78 [==========================>...] - ETA: 0s - loss: 0.1196 - accuracy: 0.9561\n",
      "Epoch 15: val_loss improved from 0.10975 to 0.09896, saving model to ./deep_model/model_check\\15-0.098960.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9551 - val_loss: 0.0990 - val_accuracy: 0.9692\n",
      "Epoch 16/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.1084 - accuracy: 0.9600\n",
      "Epoch 16: val_loss improved from 0.09896 to 0.09681, saving model to ./deep_model/model_check\\16-0.096811.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9589 - val_loss: 0.0968 - val_accuracy: 0.9723\n",
      "Epoch 17/100\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.1140 - accuracy: 0.9628\n",
      "Epoch 17: val_loss did not improve from 0.09681\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9641 - val_loss: 0.0976 - val_accuracy: 0.9621\n",
      "Epoch 18/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.1027 - accuracy: 0.9645\n",
      "Epoch 18: val_loss improved from 0.09681 to 0.07633, saving model to ./deep_model/model_check\\18-0.076328.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9646 - val_loss: 0.0763 - val_accuracy: 0.9723\n",
      "Epoch 19/100\n",
      "64/78 [=======================>......] - ETA: 0s - loss: 0.0985 - accuracy: 0.9684\n",
      "Epoch 19: val_loss did not improve from 0.07633\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9705 - val_loss: 0.0873 - val_accuracy: 0.9641\n",
      "Epoch 20/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0968 - accuracy: 0.9694\n",
      "Epoch 20: val_loss improved from 0.07633 to 0.06985, saving model to ./deep_model/model_check\\20-0.069848.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9697 - val_loss: 0.0698 - val_accuracy: 0.9713\n",
      "Epoch 21/100\n",
      "63/78 [=======================>......] - ETA: 0s - loss: 0.0885 - accuracy: 0.9724\n",
      "Epoch 21: val_loss improved from 0.06985 to 0.06748, saving model to ./deep_model/model_check\\21-0.067483.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9725 - val_loss: 0.0675 - val_accuracy: 0.9795\n",
      "Epoch 22/100\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0919 - accuracy: 0.9692\n",
      "Epoch 22: val_loss improved from 0.06748 to 0.06193, saving model to ./deep_model/model_check\\22-0.061927.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9723 - val_loss: 0.0619 - val_accuracy: 0.9795\n",
      "Epoch 23/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0841 - accuracy: 0.9745\n",
      "Epoch 23: val_loss did not improve from 0.06193\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9728 - val_loss: 0.0672 - val_accuracy: 0.9805\n",
      "Epoch 24/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0816 - accuracy: 0.9746\n",
      "Epoch 24: val_loss improved from 0.06193 to 0.05383, saving model to ./deep_model/model_check\\24-0.053829.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9751 - val_loss: 0.0538 - val_accuracy: 0.9826\n",
      "Epoch 25/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.0791 - accuracy: 0.9753\n",
      "Epoch 25: val_loss did not improve from 0.05383\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.9764 - val_loss: 0.0563 - val_accuracy: 0.9846\n",
      "Epoch 26/100\n",
      "64/78 [=======================>......] - ETA: 0s - loss: 0.0680 - accuracy: 0.9794\n",
      "Epoch 26: val_loss did not improve from 0.05383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9784 - val_loss: 0.0540 - val_accuracy: 0.9836\n",
      "Epoch 27/100\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0796 - accuracy: 0.9766\n",
      "Epoch 27: val_loss improved from 0.05383 to 0.05076, saving model to ./deep_model/model_check\\27-0.050764.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 0.9774 - val_loss: 0.0508 - val_accuracy: 0.9856\n",
      "Epoch 28/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0730 - accuracy: 0.9794\n",
      "Epoch 28: val_loss did not improve from 0.05076\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9805 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
      "Epoch 29/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0705 - accuracy: 0.9779\n",
      "Epoch 29: val_loss improved from 0.05076 to 0.04976, saving model to ./deep_model/model_check\\29-0.049762.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9800 - val_loss: 0.0498 - val_accuracy: 0.9867\n",
      "Epoch 30/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0633 - accuracy: 0.9845\n",
      "Epoch 30: val_loss did not improve from 0.04976\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9820 - val_loss: 0.0516 - val_accuracy: 0.9846\n",
      "Epoch 31/100\n",
      "72/78 [==========================>...] - ETA: 0s - loss: 0.0688 - accuracy: 0.9803\n",
      "Epoch 31: val_loss did not improve from 0.04976\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9808 - val_loss: 0.0545 - val_accuracy: 0.9877\n",
      "Epoch 32/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0649 - accuracy: 0.9806\n",
      "Epoch 32: val_loss improved from 0.04976 to 0.04809, saving model to ./deep_model/model_check\\32-0.048094.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9802 - val_loss: 0.0481 - val_accuracy: 0.9887\n",
      "Epoch 33/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.0731 - accuracy: 0.9776\n",
      "Epoch 33: val_loss did not improve from 0.04809\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9790 - val_loss: 0.0487 - val_accuracy: 0.9856\n",
      "Epoch 34/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0661 - accuracy: 0.9809\n",
      "Epoch 34: val_loss improved from 0.04809 to 0.04465, saving model to ./deep_model/model_check\\34-0.044647.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9808 - val_loss: 0.0446 - val_accuracy: 0.9867\n",
      "Epoch 35/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.0707 - accuracy: 0.9794\n",
      "Epoch 35: val_loss did not improve from 0.04465\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9787 - val_loss: 0.0474 - val_accuracy: 0.9908\n",
      "Epoch 36/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0592 - accuracy: 0.9830\n",
      "Epoch 36: val_loss did not improve from 0.04465\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9833 - val_loss: 0.0448 - val_accuracy: 0.9856\n",
      "Epoch 37/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0586 - accuracy: 0.9817\n",
      "Epoch 37: val_loss improved from 0.04465 to 0.04064, saving model to ./deep_model/model_check\\37-0.040636.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9820 - val_loss: 0.0406 - val_accuracy: 0.9877\n",
      "Epoch 38/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0590 - accuracy: 0.9849\n",
      "Epoch 38: val_loss did not improve from 0.04064\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0590 - accuracy: 0.9849 - val_loss: 0.0441 - val_accuracy: 0.9867\n",
      "Epoch 39/100\n",
      "72/78 [==========================>...] - ETA: 0s - loss: 0.0558 - accuracy: 0.9833\n",
      "Epoch 39: val_loss did not improve from 0.04064\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 0.9828 - val_loss: 0.0426 - val_accuracy: 0.9856\n",
      "Epoch 40/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0722 - accuracy: 0.9768\n",
      "Epoch 40: val_loss did not improve from 0.04064\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9790 - val_loss: 0.0420 - val_accuracy: 0.9887\n",
      "Epoch 41/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.0592 - accuracy: 0.9809\n",
      "Epoch 41: val_loss did not improve from 0.04064\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 0.9818 - val_loss: 0.0430 - val_accuracy: 0.9887\n",
      "Epoch 42/100\n",
      "73/78 [===========================>..] - ETA: 0s - loss: 0.0608 - accuracy: 0.9816\n",
      "Epoch 42: val_loss did not improve from 0.04064\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9813 - val_loss: 0.0511 - val_accuracy: 0.9846\n",
      "Epoch 43/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0524 - accuracy: 0.9845\n",
      "Epoch 43: val_loss did not improve from 0.04064\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0542 - accuracy: 0.9849 - val_loss: 0.0432 - val_accuracy: 0.9877\n",
      "Epoch 44/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0521 - accuracy: 0.9827\n",
      "Epoch 44: val_loss did not improve from 0.04064\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9828 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
      "Epoch 45/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0537 - accuracy: 0.9833\n",
      "Epoch 45: val_loss did not improve from 0.04064\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9831 - val_loss: 0.0422 - val_accuracy: 0.9877\n",
      "Epoch 46/100\n",
      "72/78 [==========================>...] - ETA: 0s - loss: 0.0613 - accuracy: 0.9825\n",
      "Epoch 46: val_loss improved from 0.04064 to 0.04018, saving model to ./deep_model/model_check\\46-0.040176.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0590 - accuracy: 0.9831 - val_loss: 0.0402 - val_accuracy: 0.9877\n",
      "Epoch 47/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0587 - accuracy: 0.9836\n",
      "Epoch 47: val_loss did not improve from 0.04018\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0540 - accuracy: 0.9849 - val_loss: 0.0493 - val_accuracy: 0.9887\n",
      "Epoch 48/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0643 - accuracy: 0.9806\n",
      "Epoch 48: val_loss improved from 0.04018 to 0.03859, saving model to ./deep_model/model_check\\48-0.038594.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9823 - val_loss: 0.0386 - val_accuracy: 0.9887\n",
      "Epoch 49/100\n",
      "64/78 [=======================>......] - ETA: 0s - loss: 0.0492 - accuracy: 0.9856\n",
      "Epoch 49: val_loss improved from 0.03859 to 0.03786, saving model to ./deep_model/model_check\\49-0.037859.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9846 - val_loss: 0.0379 - val_accuracy: 0.9877\n",
      "Epoch 50/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0564 - accuracy: 0.9836\n",
      "Epoch 50: val_loss did not improve from 0.03786\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9838 - val_loss: 0.0421 - val_accuracy: 0.9897\n",
      "Epoch 51/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0500 - accuracy: 0.9842\n",
      "Epoch 51: val_loss improved from 0.03786 to 0.03683, saving model to ./deep_model/model_check\\51-0.036828.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.0368 - val_accuracy: 0.9887\n",
      "Epoch 52/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0548 - accuracy: 0.9858\n",
      "Epoch 52: val_loss did not improve from 0.03683\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9859 - val_loss: 0.0454 - val_accuracy: 0.9908\n",
      "Epoch 53/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.0568 - accuracy: 0.9838\n",
      "Epoch 53: val_loss did not improve from 0.03683\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9823 - val_loss: 0.0944 - val_accuracy: 0.9651\n",
      "Epoch 54/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.0498 - accuracy: 0.9862\n",
      "Epoch 54: val_loss did not improve from 0.03683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9861 - val_loss: 0.0415 - val_accuracy: 0.9867\n",
      "Epoch 55/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0546 - accuracy: 0.9846\n",
      "Epoch 55: val_loss did not improve from 0.03683\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9859 - val_loss: 0.0401 - val_accuracy: 0.9887\n",
      "Epoch 56/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0522 - accuracy: 0.9858\n",
      "Epoch 56: val_loss did not improve from 0.03683\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9864 - val_loss: 0.0485 - val_accuracy: 0.9846\n",
      "Epoch 57/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0521 - accuracy: 0.9854\n",
      "Epoch 57: val_loss did not improve from 0.03683\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9856 - val_loss: 0.0406 - val_accuracy: 0.9867\n",
      "Epoch 58/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0507 - accuracy: 0.9876\n",
      "Epoch 58: val_loss did not improve from 0.03683\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9882 - val_loss: 0.0408 - val_accuracy: 0.9877\n",
      "Epoch 59/100\n",
      "62/78 [======================>.......] - ETA: 0s - loss: 0.0611 - accuracy: 0.9832\n",
      "Epoch 59: val_loss did not improve from 0.03683\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9843 - val_loss: 0.0440 - val_accuracy: 0.9887\n",
      "Epoch 60/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0455 - accuracy: 0.9886\n",
      "Epoch 60: val_loss did not improve from 0.03683\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9882 - val_loss: 0.0384 - val_accuracy: 0.9867\n",
      "Epoch 61/100\n",
      "73/78 [===========================>..] - ETA: 0s - loss: 0.0524 - accuracy: 0.9847\n",
      "Epoch 61: val_loss did not improve from 0.03683\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9854 - val_loss: 0.0588 - val_accuracy: 0.9836\n",
      "Epoch 62/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0512 - accuracy: 0.9855\n",
      "Epoch 62: val_loss did not improve from 0.03683\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9849 - val_loss: 0.0460 - val_accuracy: 0.9897\n",
      "Epoch 63/100\n",
      "72/78 [==========================>...] - ETA: 0s - loss: 0.0520 - accuracy: 0.9839\n",
      "Epoch 63: val_loss improved from 0.03683 to 0.03526, saving model to ./deep_model/model_check\\63-0.035262.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9849 - val_loss: 0.0353 - val_accuracy: 0.9897\n",
      "Epoch 64/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0435 - accuracy: 0.9891\n",
      "Epoch 64: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9887 - val_loss: 0.0354 - val_accuracy: 0.9908\n",
      "Epoch 65/100\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0542 - accuracy: 0.9852\n",
      "Epoch 65: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.9856 - val_loss: 0.0410 - val_accuracy: 0.9867\n",
      "Epoch 66/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0433 - accuracy: 0.9886\n",
      "Epoch 66: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9882 - val_loss: 0.0428 - val_accuracy: 0.9877\n",
      "Epoch 67/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0530 - accuracy: 0.9872\n",
      "Epoch 67: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9877 - val_loss: 0.0574 - val_accuracy: 0.9887\n",
      "Epoch 68/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.0454 - accuracy: 0.9882\n",
      "Epoch 68: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9879 - val_loss: 0.0460 - val_accuracy: 0.9897\n",
      "Epoch 69/100\n",
      "72/78 [==========================>...] - ETA: 0s - loss: 0.0494 - accuracy: 0.9856\n",
      "Epoch 69: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9859 - val_loss: 0.0569 - val_accuracy: 0.9846\n",
      "Epoch 70/100\n",
      "71/78 [==========================>...] - ETA: 0s - loss: 0.0495 - accuracy: 0.9870\n",
      "Epoch 70: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9874 - val_loss: 0.0427 - val_accuracy: 0.9856\n",
      "Epoch 71/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0484 - accuracy: 0.9874\n",
      "Epoch 71: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9877 - val_loss: 0.0447 - val_accuracy: 0.9918\n",
      "Epoch 72/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0424 - accuracy: 0.9870\n",
      "Epoch 72: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9879 - val_loss: 0.0408 - val_accuracy: 0.9867\n",
      "Epoch 73/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0410 - accuracy: 0.9901\n",
      "Epoch 73: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9895 - val_loss: 0.0688 - val_accuracy: 0.9795\n",
      "Epoch 74/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0547 - accuracy: 0.9855\n",
      "Epoch 74: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9861 - val_loss: 0.0431 - val_accuracy: 0.9856\n",
      "Epoch 75/100\n",
      "71/78 [==========================>...] - ETA: 0s - loss: 0.0491 - accuracy: 0.9851\n",
      "Epoch 75: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.0483 - val_accuracy: 0.9887\n",
      "Epoch 76/100\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0422 - accuracy: 0.9894\n",
      "Epoch 76: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0439 - accuracy: 0.9882 - val_loss: 0.0465 - val_accuracy: 0.9908\n",
      "Epoch 77/100\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0443 - accuracy: 0.9865\n",
      "Epoch 77: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.0490 - val_accuracy: 0.9887\n",
      "Epoch 78/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0435 - accuracy: 0.9884\n",
      "Epoch 78: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0453 - accuracy: 0.9879 - val_loss: 0.0516 - val_accuracy: 0.9887\n",
      "Epoch 79/100\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0426 - accuracy: 0.9874\n",
      "Epoch 79: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9879 - val_loss: 0.0416 - val_accuracy: 0.9887\n",
      "Epoch 80/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0460 - accuracy: 0.9869\n",
      "Epoch 80: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9872 - val_loss: 0.0577 - val_accuracy: 0.9826\n",
      "Epoch 81/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0596 - accuracy: 0.9785\n",
      "Epoch 81: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0610 - accuracy: 0.9784 - val_loss: 0.0460 - val_accuracy: 0.9887\n",
      "Epoch 82/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0524 - accuracy: 0.9861\n",
      "Epoch 82: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9856 - val_loss: 0.0453 - val_accuracy: 0.9887\n",
      "Epoch 83/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0425 - accuracy: 0.9887\n",
      "Epoch 83: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9897 - val_loss: 0.0492 - val_accuracy: 0.9887\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/78 [=========================>....] - ETA: 0s - loss: 0.0452 - accuracy: 0.9888\n",
      "Epoch 84: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9892 - val_loss: 0.0417 - val_accuracy: 0.9887\n",
      "Epoch 85/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0411 - accuracy: 0.9881\n",
      "Epoch 85: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9879 - val_loss: 0.0436 - val_accuracy: 0.9887\n",
      "Epoch 86/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0426 - accuracy: 0.9881\n",
      "Epoch 86: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9879 - val_loss: 0.0520 - val_accuracy: 0.9887\n",
      "Epoch 87/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0429 - accuracy: 0.9896\n",
      "Epoch 87: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9908 - val_loss: 0.0395 - val_accuracy: 0.9897\n",
      "Epoch 88/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0411 - accuracy: 0.9899\n",
      "Epoch 88: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9897 - val_loss: 0.0443 - val_accuracy: 0.9867\n",
      "Epoch 89/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0385 - accuracy: 0.9891\n",
      "Epoch 89: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9879 - val_loss: 0.0449 - val_accuracy: 0.9887\n",
      "Epoch 90/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0449 - accuracy: 0.9871\n",
      "Epoch 90: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9877 - val_loss: 0.0413 - val_accuracy: 0.9908\n",
      "Epoch 91/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0422 - accuracy: 0.9894\n",
      "Epoch 91: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9897 - val_loss: 0.0463 - val_accuracy: 0.9867\n",
      "Epoch 92/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0380 - accuracy: 0.9896\n",
      "Epoch 92: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0438 - val_accuracy: 0.9877\n",
      "Epoch 93/100\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0397 - accuracy: 0.9896\n",
      "Epoch 93: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9895 - val_loss: 0.0463 - val_accuracy: 0.9897\n",
      "Epoch 94/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0410 - accuracy: 0.9894\n",
      "Epoch 94: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9900 - val_loss: 0.0459 - val_accuracy: 0.9887\n",
      "Epoch 95/100\n",
      "71/78 [==========================>...] - ETA: 0s - loss: 0.0411 - accuracy: 0.9879\n",
      "Epoch 95: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9877 - val_loss: 0.0590 - val_accuracy: 0.9826\n",
      "Epoch 96/100\n",
      "70/78 [=========================>....] - ETA: 0s - loss: 0.0366 - accuracy: 0.9911\n",
      "Epoch 96: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9905 - val_loss: 0.0435 - val_accuracy: 0.9877\n",
      "Epoch 97/100\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0444 - accuracy: 0.9864\n",
      "Epoch 97: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9849 - val_loss: 0.0529 - val_accuracy: 0.9908\n",
      "Epoch 98/100\n",
      "71/78 [==========================>...] - ETA: 0s - loss: 0.0571 - accuracy: 0.9831\n",
      "Epoch 98: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9836 - val_loss: 0.0444 - val_accuracy: 0.9897\n",
      "Epoch 99/100\n",
      "62/78 [======================>.......] - ETA: 0s - loss: 0.0369 - accuracy: 0.9903\n",
      "Epoch 99: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9905 - val_loss: 0.0426 - val_accuracy: 0.9877\n",
      "Epoch 100/100\n",
      "68/78 [=========================>....] - ETA: 0s - loss: 0.0455 - accuracy: 0.9865\n",
      "Epoch 100: val_loss did not improve from 0.03526\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9867 - val_loss: 0.0447 - val_accuracy: 0.9897\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.2, batch_size=50, epochs=100, \\\n",
    "                    callbacks=[checkpointer])\n",
    "\n",
    "# val_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faedf089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3800119161605835,\n",
       "  0.2151135951280594,\n",
       "  0.20730750262737274,\n",
       "  0.20454105734825134,\n",
       "  0.2014961838722229,\n",
       "  0.19945697486400604,\n",
       "  0.1963517963886261,\n",
       "  0.19633381068706512,\n",
       "  0.1904430091381073,\n",
       "  0.18693332374095917,\n",
       "  0.17864049971103668,\n",
       "  0.16896826028823853,\n",
       "  0.15689192712306976,\n",
       "  0.1418611705303192,\n",
       "  0.12228233367204666,\n",
       "  0.11086142063140869,\n",
       "  0.10871531814336777,\n",
       "  0.10257390886545181,\n",
       "  0.09346264600753784,\n",
       "  0.0958344116806984,\n",
       "  0.08833812922239304,\n",
       "  0.0860423594713211,\n",
       "  0.08778327703475952,\n",
       "  0.0817047730088234,\n",
       "  0.0756705105304718,\n",
       "  0.0726509764790535,\n",
       "  0.07686429470777512,\n",
       "  0.0701838880777359,\n",
       "  0.06769350171089172,\n",
       "  0.06551969796419144,\n",
       "  0.06755256652832031,\n",
       "  0.06532614678144455,\n",
       "  0.06827995181083679,\n",
       "  0.06406676769256592,\n",
       "  0.06975152343511581,\n",
       "  0.05874815955758095,\n",
       "  0.060868918895721436,\n",
       "  0.05904177948832512,\n",
       "  0.05756531283259392,\n",
       "  0.06784600019454956,\n",
       "  0.057642851024866104,\n",
       "  0.06134672835469246,\n",
       "  0.054174311459064484,\n",
       "  0.052632227540016174,\n",
       "  0.05531005933880806,\n",
       "  0.05895666405558586,\n",
       "  0.05399380996823311,\n",
       "  0.05999545380473137,\n",
       "  0.05442364886403084,\n",
       "  0.05439763888716698,\n",
       "  0.050614163279533386,\n",
       "  0.05324142053723335,\n",
       "  0.058090418577194214,\n",
       "  0.05070427805185318,\n",
       "  0.051952432841062546,\n",
       "  0.049670252948999405,\n",
       "  0.05078016221523285,\n",
       "  0.04729944467544556,\n",
       "  0.05598444864153862,\n",
       "  0.047835372388362885,\n",
       "  0.05000375211238861,\n",
       "  0.05077264457941055,\n",
       "  0.04920729622244835,\n",
       "  0.04646584391593933,\n",
       "  0.05194946005940437,\n",
       "  0.04592088237404823,\n",
       "  0.05007065460085869,\n",
       "  0.04459172487258911,\n",
       "  0.047458063811063766,\n",
       "  0.04835652559995651,\n",
       "  0.047282785177230835,\n",
       "  0.04331553727388382,\n",
       "  0.04291222244501114,\n",
       "  0.05174006521701813,\n",
       "  0.047610070556402206,\n",
       "  0.04392138123512268,\n",
       "  0.04372389614582062,\n",
       "  0.04530223831534386,\n",
       "  0.04415089637041092,\n",
       "  0.0457993820309639,\n",
       "  0.06101882457733154,\n",
       "  0.05098334327340126,\n",
       "  0.04107929766178131,\n",
       "  0.04224398359656334,\n",
       "  0.04158724844455719,\n",
       "  0.04331899434328079,\n",
       "  0.03874657303094864,\n",
       "  0.04161236062645912,\n",
       "  0.04167259484529495,\n",
       "  0.044159192591905594,\n",
       "  0.03990266099572182,\n",
       "  0.03859395906329155,\n",
       "  0.04137067496776581,\n",
       "  0.0402032844722271,\n",
       "  0.04209892079234123,\n",
       "  0.03807072341442108,\n",
       "  0.049833618104457855,\n",
       "  0.05715101957321167,\n",
       "  0.03740636259317398,\n",
       "  0.04301408678293228],\n",
       " 'accuracy': [0.7572491765022278,\n",
       "  0.9258403778076172,\n",
       "  0.9284064769744873,\n",
       "  0.9299461245536804,\n",
       "  0.9319989681243896,\n",
       "  0.9312291741371155,\n",
       "  0.9325121641159058,\n",
       "  0.9314857721328735,\n",
       "  0.9330254197120667,\n",
       "  0.9340518116950989,\n",
       "  0.936874508857727,\n",
       "  0.9427765011787415,\n",
       "  0.9435462951660156,\n",
       "  0.9479086399078369,\n",
       "  0.9550936818122864,\n",
       "  0.9589427709579468,\n",
       "  0.9640749096870422,\n",
       "  0.9645881652832031,\n",
       "  0.9704900979995728,\n",
       "  0.9697203040122986,\n",
       "  0.9725430011749268,\n",
       "  0.9722864031791687,\n",
       "  0.9727995991706848,\n",
       "  0.9751090407371521,\n",
       "  0.9763920903205872,\n",
       "  0.9784449338912964,\n",
       "  0.9774185419082642,\n",
       "  0.9804978370666504,\n",
       "  0.9799845814704895,\n",
       "  0.9820374846458435,\n",
       "  0.9807544350624084,\n",
       "  0.9802412390708923,\n",
       "  0.9789581894874573,\n",
       "  0.9807544350624084,\n",
       "  0.9787015914916992,\n",
       "  0.9833204746246338,\n",
       "  0.9820374846458435,\n",
       "  0.9848601222038269,\n",
       "  0.9828072786331177,\n",
       "  0.9789581894874573,\n",
       "  0.9817808866500854,\n",
       "  0.9812676310539246,\n",
       "  0.9848601222038269,\n",
       "  0.9828072786331177,\n",
       "  0.9830638766288757,\n",
       "  0.9830638766288757,\n",
       "  0.9848601222038269,\n",
       "  0.9822940826416016,\n",
       "  0.9846035242080688,\n",
       "  0.9838337302207947,\n",
       "  0.9846035242080688,\n",
       "  0.9858865737915039,\n",
       "  0.9822940826416016,\n",
       "  0.986143171787262,\n",
       "  0.9858865737915039,\n",
       "  0.98639976978302,\n",
       "  0.9856299757957458,\n",
       "  0.988196074962616,\n",
       "  0.9843469262123108,\n",
       "  0.988196074962616,\n",
       "  0.9853733777999878,\n",
       "  0.9848601222038269,\n",
       "  0.9848601222038269,\n",
       "  0.9887092709541321,\n",
       "  0.9856299757957458,\n",
       "  0.988196074962616,\n",
       "  0.9876828193664551,\n",
       "  0.9879394173622131,\n",
       "  0.9858865737915039,\n",
       "  0.987426221370697,\n",
       "  0.9876828193664551,\n",
       "  0.9879394173622131,\n",
       "  0.9894790649414062,\n",
       "  0.986143171787262,\n",
       "  0.9851167798042297,\n",
       "  0.988196074962616,\n",
       "  0.9866564273834229,\n",
       "  0.9879394173622131,\n",
       "  0.9879394173622131,\n",
       "  0.987169623374939,\n",
       "  0.9784449338912964,\n",
       "  0.9856299757957458,\n",
       "  0.9897357225418091,\n",
       "  0.9892224669456482,\n",
       "  0.9879394173622131,\n",
       "  0.9879394173622131,\n",
       "  0.9907621145248413,\n",
       "  0.9897357225418091,\n",
       "  0.9879394173622131,\n",
       "  0.9876828193664551,\n",
       "  0.9897357225418091,\n",
       "  0.9894790649414062,\n",
       "  0.9894790649414062,\n",
       "  0.9899923205375671,\n",
       "  0.9876828193664551,\n",
       "  0.9905055165290833,\n",
       "  0.9848601222038269,\n",
       "  0.9835771322250366,\n",
       "  0.9905055165290833,\n",
       "  0.9866564273834229],\n",
       " 'val_loss': [0.1917659193277359,\n",
       "  0.18847665190696716,\n",
       "  0.18584796786308289,\n",
       "  0.18819618225097656,\n",
       "  0.178853377699852,\n",
       "  0.17867936193943024,\n",
       "  0.1771564483642578,\n",
       "  0.1726977676153183,\n",
       "  0.169578418135643,\n",
       "  0.1684075891971588,\n",
       "  0.1626981943845749,\n",
       "  0.14633840322494507,\n",
       "  0.1250096708536148,\n",
       "  0.10974586009979248,\n",
       "  0.09895990043878555,\n",
       "  0.09681050479412079,\n",
       "  0.09756424278020859,\n",
       "  0.0763276144862175,\n",
       "  0.08730264753103256,\n",
       "  0.06984821707010269,\n",
       "  0.06748318672180176,\n",
       "  0.061927005648612976,\n",
       "  0.06724231690168381,\n",
       "  0.05382924526929855,\n",
       "  0.056277576833963394,\n",
       "  0.053975626826286316,\n",
       "  0.050763994455337524,\n",
       "  0.05247001349925995,\n",
       "  0.04976203292608261,\n",
       "  0.05163465440273285,\n",
       "  0.05451573058962822,\n",
       "  0.04809439182281494,\n",
       "  0.048666518181562424,\n",
       "  0.04464687779545784,\n",
       "  0.047350428998470306,\n",
       "  0.044831838458776474,\n",
       "  0.0406360886991024,\n",
       "  0.04410574212670326,\n",
       "  0.042589686810970306,\n",
       "  0.04199817404150963,\n",
       "  0.04297570139169693,\n",
       "  0.05106133222579956,\n",
       "  0.043197840452194214,\n",
       "  0.055243413895368576,\n",
       "  0.04219350591301918,\n",
       "  0.040175821632146835,\n",
       "  0.0493292398750782,\n",
       "  0.03859354183077812,\n",
       "  0.037859246134757996,\n",
       "  0.04208192229270935,\n",
       "  0.03682776913046837,\n",
       "  0.04535430297255516,\n",
       "  0.09443415701389313,\n",
       "  0.041525162756443024,\n",
       "  0.04007219523191452,\n",
       "  0.04848162457346916,\n",
       "  0.04058292880654335,\n",
       "  0.04080899432301521,\n",
       "  0.04395061731338501,\n",
       "  0.038417644798755646,\n",
       "  0.058776549994945526,\n",
       "  0.045964665710926056,\n",
       "  0.035261575132608414,\n",
       "  0.0353730283677578,\n",
       "  0.04101266711950302,\n",
       "  0.04281381890177727,\n",
       "  0.057408567517995834,\n",
       "  0.04599260911345482,\n",
       "  0.05685120448470116,\n",
       "  0.04265028238296509,\n",
       "  0.044677846133708954,\n",
       "  0.04080701991915703,\n",
       "  0.068837471306324,\n",
       "  0.0430779866874218,\n",
       "  0.04833729937672615,\n",
       "  0.04652165248990059,\n",
       "  0.04902604967355728,\n",
       "  0.05161326006054878,\n",
       "  0.04159665107727051,\n",
       "  0.05772054195404053,\n",
       "  0.045972276479005814,\n",
       "  0.04526150971651077,\n",
       "  0.049170125275850296,\n",
       "  0.041747283190488815,\n",
       "  0.04358132556080818,\n",
       "  0.05203455314040184,\n",
       "  0.039460767060518265,\n",
       "  0.04432195797562599,\n",
       "  0.04487575218081474,\n",
       "  0.04131084680557251,\n",
       "  0.046277984976768494,\n",
       "  0.04381995648145676,\n",
       "  0.046289071440696716,\n",
       "  0.04593212530016899,\n",
       "  0.05897243320941925,\n",
       "  0.0434781089425087,\n",
       "  0.052858661860227585,\n",
       "  0.044351447373628616,\n",
       "  0.04259217903017998,\n",
       "  0.04472111538052559],\n",
       " 'val_accuracy': [0.9374359250068665,\n",
       "  0.9384615421295166,\n",
       "  0.9394871592521667,\n",
       "  0.9415384531021118,\n",
       "  0.9405128359794617,\n",
       "  0.9425641298294067,\n",
       "  0.9405128359794617,\n",
       "  0.9425641298294067,\n",
       "  0.9425641298294067,\n",
       "  0.9435897469520569,\n",
       "  0.9528205394744873,\n",
       "  0.9528205394744873,\n",
       "  0.962051272392273,\n",
       "  0.9579487442970276,\n",
       "  0.9692307710647583,\n",
       "  0.9723076820373535,\n",
       "  0.962051272392273,\n",
       "  0.9723076820373535,\n",
       "  0.964102566242218,\n",
       "  0.9712820649147034,\n",
       "  0.9794871807098389,\n",
       "  0.9794871807098389,\n",
       "  0.980512797832489,\n",
       "  0.9825640916824341,\n",
       "  0.9846153855323792,\n",
       "  0.983589768409729,\n",
       "  0.9856410026550293,\n",
       "  0.9876922965049744,\n",
       "  0.9866666793823242,\n",
       "  0.9846153855323792,\n",
       "  0.9876922965049744,\n",
       "  0.9887179732322693,\n",
       "  0.9856410026550293,\n",
       "  0.9866666793823242,\n",
       "  0.9907692074775696,\n",
       "  0.9856410026550293,\n",
       "  0.9876922965049744,\n",
       "  0.9866666793823242,\n",
       "  0.9856410026550293,\n",
       "  0.9887179732322693,\n",
       "  0.9887179732322693,\n",
       "  0.9846153855323792,\n",
       "  0.9876922965049744,\n",
       "  0.9846153855323792,\n",
       "  0.9876922965049744,\n",
       "  0.9876922965049744,\n",
       "  0.9887179732322693,\n",
       "  0.9887179732322693,\n",
       "  0.9876922965049744,\n",
       "  0.9897435903549194,\n",
       "  0.9887179732322693,\n",
       "  0.9907692074775696,\n",
       "  0.9651281833648682,\n",
       "  0.9866666793823242,\n",
       "  0.9887179732322693,\n",
       "  0.9846153855323792,\n",
       "  0.9866666793823242,\n",
       "  0.9876922965049744,\n",
       "  0.9887179732322693,\n",
       "  0.9866666793823242,\n",
       "  0.983589768409729,\n",
       "  0.9897435903549194,\n",
       "  0.9897435903549194,\n",
       "  0.9907692074775696,\n",
       "  0.9866666793823242,\n",
       "  0.9876922965049744,\n",
       "  0.9887179732322693,\n",
       "  0.9897435903549194,\n",
       "  0.9846153855323792,\n",
       "  0.9856410026550293,\n",
       "  0.9917948842048645,\n",
       "  0.9866666793823242,\n",
       "  0.9794871807098389,\n",
       "  0.9856410026550293,\n",
       "  0.9887179732322693,\n",
       "  0.9907692074775696,\n",
       "  0.9887179732322693,\n",
       "  0.9887179732322693,\n",
       "  0.9887179732322693,\n",
       "  0.9825640916824341,\n",
       "  0.9887179732322693,\n",
       "  0.9887179732322693,\n",
       "  0.9887179732322693,\n",
       "  0.9887179732322693,\n",
       "  0.9887179732322693,\n",
       "  0.9887179732322693,\n",
       "  0.9897435903549194,\n",
       "  0.9866666793823242,\n",
       "  0.9887179732322693,\n",
       "  0.9907692074775696,\n",
       "  0.9866666793823242,\n",
       "  0.9876922965049744,\n",
       "  0.9897435903549194,\n",
       "  0.9887179732322693,\n",
       "  0.9825640916824341,\n",
       "  0.9876922965049744,\n",
       "  0.9907692074775696,\n",
       "  0.9897435903549194,\n",
       "  0.9876922965049744,\n",
       "  0.9897435903549194]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7095ead5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18889643430>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkhUlEQVR4nO3deXxc1X338c9v7oz23ZJtWbIt23gF7ADCLMVgIAkGkpCFUpxQliQ4aZOUtHnaJM3TJ23zPHmSpnmapFl4UUJpSAJNwAmUEqAJawBTDNhgGy+yjS1ZtrVZ+zYzOs8fdySPFkuDPUZc+ft+vfSS5t6rO+do+c6Zc84915xziIhI8IUmuwAiIpIeCnQRkSlCgS4iMkUo0EVEpggFuojIFBGerCcuLS11VVVVk/X0IiKB9PLLLzc558rG2jdpgV5VVcXGjRsn6+lFRALJzPYda5+6XEREpggFuojIFDFhoJvZXWbWYGZbJjjuXDOLm9m16SueiIikKpUW+t3AmvEOMDMP+CbwWBrKJCIix2HCQHfOPQO0THDY54AHgIZ0FEpERN66E+5DN7MK4EPA7Skcu87MNprZxsbGxhN9ahERSZKOQdHvAF90zsUnOtA5d4dzrto5V11WNuY0ShEROU7pmIdeDdxnZgClwFVmFnPO/ToN5x5lx6EOHn6tnpsurKI0L/NkPIWISCCdcAvdOTfPOVflnKsC7gf+9GSFOcDuxk7++Ykamjv7T9ZTiIgE0oQtdDO7F1gNlJpZHfBVIALgnJuw3zzdvJABEI0PvN1PLSLyjjZhoDvn1qZ6MufczSdUmhREPD/QYwO605KISLLAXSkaDvlFjg+ohS4ikiyAgT7Y5aIWuohIsuAFujfYQlegi4gkC1yga1BURGRsgQv0oUFRdbmIiAwTuEAfHBTVLBcRkeGCF+hD0xbV5SIikix4gZ7oQ9egqIjIcAEMdL/ImrYoIjJc8AJ9aFBUXS4iIsmCF+ghXfovIjKW4AV64sIitdBFRIYLYKCrhS4iMpbgBbq6XERExhTAQFeXi4jIWAIY6Gqhi4iMJXCBHgoZIdNaLiIiIwUu0MGf6aIWuojIcMEM9JCpD11EZITgBrpa6CIiwwQz0L2QVlsUERlhwkA3s7vMrMHMthxj/8fM7LXEx/NmtiL9xRzO73JRC11EJFkqLfS7gTXj7N8LXOKcWw58DbgjDeUaV0SDoiIio4QnOsA594yZVY2z//mkhxuAyjSUa1yeBkVFREZJdx/6J4DfHGunma0zs41mtrGxsfG4nyTsGVG10EVEhklboJvZpfiB/sVjHeOcu8M5V+2cqy4rKzvu5wqHjLj60EVEhpmwyyUVZrYcuBO40jnXnI5zjicc0iwXEZGRTriFbmZzgPXAHzvndp54kSYW8TQPXURkpAlb6GZ2L7AaKDWzOuCrQATAOXc78L+AacAPzQwg5pyrPlkFhsFBUQW6iEiyVGa5rJ1g/yeBT6atRCkIeyGimuUiIjJMMK8UDRlxdbmIiAwTzED3Qpq2KCIyQiADPRIy4prlIiIyTCADXYOiIiKjBTLQIxoUFREZJZCB7mlQVERklEAGetgzoupyEREZJpiBrha6iMgowQx03bFIRGSUQAZ6RPcUFREZJZCB7oVCmrYoIjJCIAM94pmmLYqIjBDIQNe0RRGR0QIZ6OHETaKdU6iLiAwKZKBHQgagVrqISJJABrrn+YGumS4iIkcFMtAjIb/YGhgVETkqkIHuqctFRGSUQAZ6JNHlovVcRESOCmSghz2/2Gqhi4gcNWGgm9ldZtZgZluOsd/M7HtmVmNmr5nZ2ekv5nCDXS7qQxcROSqVFvrdwJpx9l8JLEx8rAN+dOLFGl9Es1xEREaZMNCdc88ALeMccg3wE+fbABSZWXm6CjgWLzTY5aIWuojIoHT0oVcAtUmP6xLbRjGzdWa20cw2NjY2HvcTRkIaFBURGSkdgW5jbBszaZ1zdzjnqp1z1WVlZcf9hBoUFREZLR2BXgfMTnpcCdSn4bzHFNagqIjIKOkI9IeAGxOzXc4H2pxzB9Nw3mMKa1BURGSU8EQHmNm9wGqg1MzqgK8CEQDn3O3AI8BVQA3QDdxysgo7aHDaom5yISJy1ISB7pxbO8F+B3wmbSVKQSTRh677ioqIHBXMK0VD6nIRERkpoIGeaKGry0VEZEgwA31wUFSzXEREhgQz0NXlIiIySjADXYOiIiKjBDPQNW1RRGSUYAa6LiwSERklmIE+NMtFXS4iIoMCGuhqoYuIjBTMQPfUhy4iMlIwA32wy0UtdBGRIcEMdF1YJCIySjADfXA9dLXQRUSGBDLQzQwvZLqnqIhIkkAGOvitdA2KiogcFexAV5eLiMiQ4Aa6F9KgqIhIksAGesQzDYqKiCQJbKB7ISOuPnQRkSGBDfRwKERUs1xERIakFOhmtsbMdphZjZl9aYz9hWb2H2a22cy2mtkt6S/qcGHPiKvLRURkyISBbmYe8APgSmAZsNbMlo047DPANufcCmA18G0zy0hzWYfRtEURkeFSaaGvBGqcc3ucc/3AfcA1I45xQL6ZGZAHtACxtJZ0hIgXIqpZLiIiQ1IJ9AqgNulxXWJbsu8DS4F64HXgNufcSU1b/0pRtdBFRAalEug2xraRSXoFsAmYBbwL+L6ZFYw6kdk6M9toZhsbGxvfYlGHC3shTVsUEUmSSqDXAbOTHlfit8ST3QKsd74aYC+wZOSJnHN3OOeqnXPVZWVlx1tmwO9D11ouIiJHpRLoLwELzWxeYqDzeuChEcfsBy4HMLMZwGJgTzoLOlI4ZEQ1KCoiMiQ80QHOuZiZfRZ4DPCAu5xzW83s04n9twNfA+42s9fxu2i+6JxrOonlJuKF6InGT+ZTiIgEyoSBDuCcewR4ZMS225O+rgfem96ijc8LmdZyERFJEtgrRSOeulxERJIFNtA1bVFEZLjABro/bVFdLiIigwIb6BG10EVEhglsoHuhkNZyERFJEthA9wdF1eUiIjIosIGuQVERkeECG+habVFEZLjABnpYLXQRkWECG+iebhItIjJMYAM9Egrp0n8RkSSBDXQvZAw4GFArXUQECHCgRzz/vhsxBbqICBDgQPdCftE1MCoi4gtsoA+20LWei4iIL7CBHg4lulx0+b+ICBDgQPc8v+gxtdBFRIAAB3pELXQRkWECG+heItA1KCoi4gtsoEcSXS5az0VExBfYQA9rHrqIyDApBbqZrTGzHWZWY2ZfOsYxq81sk5ltNbOn01vM0TTLRURkuPBEB5iZB/wAeA9QB7xkZg8557YlHVME/BBY45zbb2bTT1J5h4RDmuUiIpIslRb6SqDGObfHOdcP3AdcM+KYjwLrnXP7AZxzDekt5mieulxERIZJJdArgNqkx3WJbckWAcVm9pSZvWxmN451IjNbZ2YbzWxjY2Pj8ZU4ITLYQleXi4gIkFqg2xjbRqZoGDgHuBq4AvgbM1s06pucu8M5V+2cqy4rK3vLhR32hIMtdM1yEREBUuhDx2+Rz056XAnUj3FMk3OuC+gys2eAFcDOtJRyDEODoupyEREBUmuhvwQsNLN5ZpYBXA88NOKYB4FVZhY2sxzgPOCN9BZ1uLAu/RcRGWbCFrpzLmZmnwUeAzzgLufcVjP7dGL/7c65N8zsUeA1YAC40zm35aQWXNMWRUSGSaXLBefcI8AjI7bdPuLxt4Bvpa9o49OFRSIiwwX3StGQLv0XEUkW4EDX4lwiIsmCG+ie+tBFRJIFN9CHLv1XoIuIQJADfWhQVH3oIiIQ4ECPDA2KqoUuIgIBDvTBxbniaqGLiAABDvTBWS5qoYuI+AIf6Jq2KCLiC2ygeyGttigikiywgW5mRDzTtEURkYTABjr4rXQFuoiIL9CBHgmFtJaLiEhCoAPd80yDoiIiCYEO9HAopGmLIiIJAQ9004VFIiIJwQ50z7TaoohIQqADPeKFiKoPXUQECHige+pyEREZEuhAD4dMg6IiIgkpBbqZrTGzHWZWY2ZfGue4c80sbmbXpq+IxxbWtEURkSETBrqZecAPgCuBZcBaM1t2jOO+CTyW7kIeS1gXFomIDEmlhb4SqHHO7XHO9QP3AdeMcdzngAeAhjSWb1wRzXIRERmSSqBXALVJj+sS24aYWQXwIeD28U5kZuvMbKOZbWxsbHyrZR3FHxRVoIuIQGqBbmNsG5mi3wG+6JyLj3ci59wdzrlq51x1WVlZikU8Nn/aorpcREQAwikcUwfMTnpcCdSPOKYauM/MAEqBq8ws5pz7dToKeSxqoYuIHJVKoL8ELDSzecAB4Hrgo8kHOOfmDX5tZncDD5/sMAet5SIikmzCQHfOxczss/izVzzgLufcVjP7dGL/uP3mJ5M/KKouFxERSK2FjnPuEeCREdvGDHLn3M0nXqzUqMtFROSoQF8pqkFREZGjAh3oXsiIqw9dRAQIeKBHPNNqiyIiCYEO9HAopEFREZGEQAe6FzJiaqGLiAABD3St5SIiclSgA90LhTRtUUQkIdCB7g+Kqg9dRAQCHujhUAjnUCtdRISgB7rnLwQZUytdRCTggR5KBLoGRkVEgh3o3mCgq8tFRCTYgR7x/OLr4iIRkYAHulroIiJHBTrQI54CXURkUKADPRxSl4uIyKBgB7pa6CIiQ4Id6EMtdAW6iEigA31wUDSqLhcRkWAH+uCgqC79FxEJeKCHE/PQ1UIXEUkx0M1sjZntMLMaM/vSGPs/ZmavJT6eN7MV6S/qaAVZYQA++ZONfPXBLWyubaU/pnAXkVOTOTd+d4WZecBO4D1AHfASsNY5ty3pmAuBN5xzR8zsSuBvnXPnjXfe6upqt3HjxhMtP8/uauQXG+t4bOsh+mMDhAzKC7OZXZJN1bRc5pXmUlWaS3lhFtPzsyjNyxhq2YuIBI2Zveycqx5rXziF718J1Djn9iROdh9wDTAU6M6555OO3wBUHn9x35pVC8tYtbCMtp4oT25vYE9TF7Ut3exr7uLxbYdp6eofdrwZzCrMZn6ZH/aF2ZGhfbOLc7h4URkzC7PeruKLiKRNKoFeAdQmPa4Dxmt9fwL4zVg7zGwdsA5gzpw5KRZxhN1Pwm++CKULoXSR/1FcRWHRHD64Yib0HIH2HujqgcqVtLkc3mzq4nB7Lw0dfTS097K/pZs9TV386pUDdPXHAHDA4JuVJTPzWTmvhIUz8lk0PY/TKwrJy0zlRyUiMnlSSSkbY9uY/TRmdil+oF801n7n3B3AHeB3uaRYxuEi2X6YN+2EnY/CQOzYx2bkUXj2jaw471Mwu2rc0zrn2HG4g6d3NPL0zkbWv3KAzj7/3FmREFefOYu1K2dzztxizMb6kYiITK5UAr0OmJ30uBKoH3mQmS0H7gSudM41p6d4Y5hzvv8BEI/CkX3Qug9a90PHQcgugYJZkJkHm+6F/74DNvwIMgv8/paQBxl5kF0MOSVQsgAqq7GKapZMn8+SmQV86pIFOOc42NbLjsMd/HbbYR7cVM8Dr9SxZGY+t66az/tXzCIjrL54EXnnSGVQNIw/KHo5cAB/UPSjzrmtScfMAZ4AbhzRn35M6RoUnVDbAdj0c+huBheHgTj0d0J3i7+taaf/GCCS4wf8tAVQUAGZ+ZBVAEVz6Jp1IQ/v7OJfn3uT7Yc6KC/M4tZV87nh/LkKdhF524w3KDphoCdOcBXwHcAD7nLO/R8z+zSAc+52M7sT+AiwL/EtsWM94aC3LdAnMhCHxh1wYCM0bIfmGmjeBZ0NR4MewEJQcQ7u9A/xVNGHuf2ZN3lxbwvzSnP5ylVLuXzpdHXFiMhJd8KBfjK8YwJ9PANx6Gv3g373E1DzW6h/BU57N3z4X3iyNsbXHt7GnsYuLllUxjc+ciblhdmTXWoRmcIU6OniHLx8N/zmryB/Jlx3D9EZy/nJC/v49uM7yAiH+MaHl7PmjJmTXVIRmaLGC3R1/r4VZlB9C9zyqN96v2sNkdrn+cRF83j4cxcxuziHT//0Zf76V6/rilURedsp0I9H5Tmw7ikomgM/uw72b2B+WR4P/MmFfOri+fz8xf3c+pON9PTHJ7ukInIKUaAfr7zpcNNDUFAOP70Wal8iIxziy1ct5RsfPpNndjXyxz9+kbae6GSXVEROEQr0E5E/E276D8gthXs+BFseAOD6lXP4/tqz2VzXyto7NrD9UPskF1RETgUK9BNVMAtu/k+YvhTu/zg8+Fno7+Lq5eX8y43V1B3p5srvPstf/nIzB9t6Jru0IjKFaZZLusSj8OTX4ff/BNNOg/f8PSy+ktaeKD98ajd3P/cmDkdlcQ7T8zOZWZjFuVUlXLZkOrOKNNVRRFKjaYtvpz1PwcN/Di17oOIcuPivYNa7qO3L5WcvHaDuSDcN7X3sb+nmUHsv4C8Gdu05lVx37mwKsiLjn19ETmkK9LdbPAab74WnvwltiYUqzYOcaf5iYrFeHEbjBf+TX3lX8NjWQ7yyv5XcDI9rz6mkLD+T+rZeDrX1sqAslw+eVcGy8gJdifpO0Fbnr/h51g3+NFaRt5kCfbLE+vx//rZa6DgEXY3gRSCcBQc3w5vPwvu+A9W3sOVAG/c8u53Qlvt5Ib6Y9py5TM/PZHdjJ9G4Y9GMPM6fP43ywmzKC7Mwg5auflq6+snPCrN68XQWTs9T6J9s93/cH/y+9UmoOHuySyOnoBO9wYUcr3AmLF4z9r5YH/z7DfDw5wHHGRjfPPAPEK7H5RZgf3g3nHYxR7r6+c/XD/LQpnp+/eoB2nuHLxccMhhw8PVHtlNRlM2lS8q4dPF0LlgwjZwM/XrTqv0gbHvQ//rluxXo8o6jFvpkivbCfR+F3b/zH1euhAs+A0//AzRuhzXfgJW3Dntr39UX42BbL+CYlptJYXaEwx29PLWjkSe2N/BcTRPd/XEywiHOml3E/LI85pXmkJsZZmt9O1sOtNHQ3sdFC0tZc/pMLlpYSlbEm5z6B82TX/d/N1UXQf2r8IUd/jLNIm8jdbm8k0V74Jlv+WG+6Ao/vPs6YP062PEIlMyHwkooqISZZ8D81TB9mf+9jdvhzd/767qf/mEwoy8WZ+ObR3hiewOv7D/Cm01dHOn2L27KzwqzvLKQopwMntnZSEdvjIxwiMqibGYVZVNRlM2MwixmFGRSmpdJW0+Uxo4+mjv7KcgOM7Mgi+kFmbR0RdnX3MX+lm5KcjM4s6KQMyoKOdzey7O7mnh+dxMzC7L4/LsXcUZFYco/Cucc/7XtMJvrWvnI2ZXML3sHhWWsH/7pdJh1Fqz6Atz1Xnj/9+Ccmya7ZCdfrB9+85ew8ApYctVkl+aUp0APooEBePF2qH0R2usT/fAH/X250wHn98kPqloF7/+uv5b7CG3dUdp7o1QWZw/1sffHBtiwp5nnapqoO9JDXWsP9a09NHX2MfJPIjfDozsaH7bdCxnlhVk0d/bTEz26xEHEM86aU8yOQx209US5enk57102g8aOPho6+uiPDVCal8G0vExKcjMoyo5QnJtBTUMn//xEDW8c9C/CChm8b/ksPnbeHBo7+9hxqIODbb38wWnTePfSGeSPMxvIOceh9l5qGjqZUZDFaWV5hEJ+vQ+39/LMzkayIh4XLpjGtLzM1H4fr/0C1t9K7x/9kuaZF1Hx88sgIwdufSK1738rWvZARj7klZ34uaK9EDnBe+Q++tew4Qf+2M/HH/Vf1NLBOX8106xCthxo4/Fth3nf8nIWzchPz/lPlmiP/w5tzgXjDozHBxxeKP1jWgr0qaK1FvY+DXue9v+Qqlb5b//3PgOP/w3EemHp+/wbd7TVQX+3vzRBwSwonO2Hfeki/+YdPa3Q3eSv+Z4/C4rnQt5Moj1tHGk8QGdTPYW9ByjsqSXcWU9s+hk0VlzOwdBMSnIyqCjOJuKFiMUH2N3Yxdb6NopzMjhvfgk5GWHaeqLc+ewefvz7vXQn1rTJDIeIeKGhW/uNNL80l89edhoXLijlX5/fyz0v7Bv63pA5qrK62dOTQ2bY4+JFZcwtyeH06Gu86/Cv2JZ/Ib/1Lmb/kR52He4YNtZQlBPhnDnF1Lf1Dr1gDFpWXsCC6XlD91ksyomwZGYBS8rzKcqOcKC1h7ojPax66nrobWV17z8QGzC+XPwkn+r5F/Zd9zg9JUtp74nRF4tTlp9JeUE2BdlhBhx09sXoi8aZlpc59M/d1hPlgZfreHBzPfNLc/mjc2dz3rwS/8W25re4+z4GoTC9q75M+5k3E4lkUJgdGTMcnHPsb+mmtTvKGRWFR4/paoaHb4Odj8G5t8LF/8N/J9dW578j3PmY35134W3gjTPWsv0RuG8trFgLe58FHPuufYSBHP/nH5oosPq7/L/bSLb/NzaoqxnW34rb+zTbZl3LzXsvozHuvyO74vQZfObS01heWTT+uQcNDMCh16BkHmSl/o7wuOx+Ah7+CziyFxZfBdf8wP+5AnS30LvjtzzdM59/3+n4/a4mPnXJfP7iPYvSOllBgX4q6DgEj34J9m/wA7uwEjJy/VZ9e71/i75o9wQnMUbdLtY8f2mDzsP+47IlkFvmD+rG+/3nKl8B5cv9FlfrPv+2gBaCotl0ZZfTmDmH4splFORmYmb0RuMcaT1Ce0sjzQO5tPR7ZGf4M3WSQ+tIVz+vbNvJsqZHmLH7l4SadtJdvJhnct7LA01zubb3l1xhL9LrImRZlJdCK7hn2m3kz1rEkpn5LCjL42DzEQY2/4LTDz/IkchM9p/5OVacdR798QGeq2ni97uahq4HAGjq6KNjxAvO2baT9Zl/y90Ff0rzGTdTkBXhqc07uavpBu6NX8rfxm4eOraATj7iPcsl3uu8EF/K+vhFNFJMZjjEgrI8yguzeH53Mz3RGCtnhNjRZrT1DlA1LYcrIpv4Quv/psZV0jBQyGpvM1sGqvhq9CZeYTEFWRFmFGQyuziH2SU5dPfHeK6mmQOt/hXIRTkRVi0s493hTaze/ndkxzt4zi3nEttE1MuhrXI102ofA+eozVpMVc9WajKW8v3CL9CeNYtZXjvTw50UlS9gwdw5nJHTRsFPLsOK5xK9+TE2vPg8K59Yy2sDc/lq9GZWZezi0uxdTMuIEy4oI6e4nLyww+s8gNdeR6i9Fq+nBQCHcWTuFbSe82d4NsDMR9cR6WnklcyVnNX9PL1eLn3nfIr/PpLL72ra6e2P8e7SZlblH6K4/yBWtQqWXweV5/qNGZd4h7r5Xn+AumWP/3f5nq/BiuuPtpw7DkNXg99tFO+D7GJcyQKaex2RUIjCeDPsfwG6mvxGT2Gl/+LTfsB/8etuhlDY/9i/Abbc79/VbNk18ML3/edc83+J7n4GXv0pkYFe4s54zqtmQ/EHuP9ACe8//wy+8oEVhBiAzgYG2g8SzSwis2x+qv/dw/8lFejCwAB01EPTLj/8s4v9oI7kJAL/TX97VqHfpZM33W9RFc72p1q27IEdj0LNf/lvOb0Mf/uRff5dnpJfCCK54AYg1jN8W/ly/7Z+jdv9F5hBXqZ/q79wln/ekOe/u+jv9N+SuwF/jOG0y2HX43Dg5cQ5c4he+HmOrPgk03Y9gPfE1/wXmpln+uvsZBX6NxLvbvZfiFpr/TKdeR0s+4D/fJFsv971r8LBTTg3QPv089iV8y56e7pZdvABimt/B1kF2G2v+eVM6Pz5zWTtfpSmGRdBdhGReC9F+x/HG+ijLaOcwv6DDJjHwZLzaKaQzp5++vp7WRBpoSJ+AK+/HZdVRH3xuWzsKuXq9l9Qn3Ua9y/7Hpl501hy5Eku2Pktcvoa2Ft0AY/N+ASvROdRe6SH2pZuMi3KR2cd5L2Z25jevYv+tgYivc3MpIndNof7Zv8NvSXLaNj9Kn/Y+mNWhzZzf/xivh//EPH8St7vvcDnem8n13X7YZOk3pXgMAro5pro19nPTGIDjhvzX+bvo98eOq4hVEZDPJ9i2iiljTgeB1zpsI86V8bCUB03eY9TYN3EXIhDlPAn/Z9nh3ca/3hJhPcf/hFW89thZYgRYtdABV0ZZSyPbSGDfhpsGnE8il0bWfQB8ApLWR89n+sznuMMt5NDhe+iI7uCaS2vUtI/6vbH9DuPva6cTKJUhQ6n/C8UswiPFa3lZxkfobXf49LCA6w7/DUKe+qIEubB+IXUzfkA15XsoXzPL7GkLtGeUC6ZAz1DP+eXZ9/EOZ/4XsrPnUyBLidXXycc3uq3Yorn+hdQgR+krfv9AK/f5IdmtBvKFh9t6fe2+vd37Ws/2ooaiPvvLjJyIacUTv+g/z2DGrb7c/iXXO13Jw1qPwjPfvvoLQS7GqGiGi74U797qrvZX5rhpTv97qlkXgbMON1/8Tj0uv8Z/Oc/6wao/vjwLgOAQ1v8d0XdzdBzxF/+YdkH4Jxb/Bevpl2w6WfwxsN+vSzk/4wKKqB0IRTNhaYdsPspaK/zX7RuuH94t0F/l3+j8+e+6z9HyQKwEA4H7fVYtNs/5/RlkD8Tl1NKf8kiMi/8k2F9540dfew81M7Momwqi7PJDCdmNnUc8s/vZUL+DMguputQDV37NxNq3skLFbewo3g10YEBzp1bwqVLpuNtW++/qFetguK5xAcctS3dbD/YTktXPwP4XUERL0RRTgYluRlEPKO3o5Vpb/wbWZ21HDr3y+SX+MteFGYnxkO6El2A0V5wA/QWzOWXm5v49asHyKObi+Mvclbvi0QtQqsV02KF1BReQF/JYgqzI+xr7KT8zfWsi94DwGZbyps5Z9KZPYuYRYhZhOmhDhaHapkd3UfMwSZbwm/a5/Naey7l1sIsayKbfg4xjWheBV5eKT3RGL29fXTEPLLziyjNyyAr4rHzUAftbS1cFnqVjhnn8ZlrVlFdleh+ifXD3qdxrfvZ8PpOtu/ZSwfZ9GSWUTqriuVnnc+5Z497l85jUqCLJOtu8buGor1+iz27xA/EcIa/v6fVfxsej/ozj8IpDpweL+f8rrG8Gf67k7H0tvvBe+h1/4XBzH9BnL/aH0fJfIcPJL6NGtp7yPBCFOWm/nuLxQfo7IvR3hNjwDlmFWWndPP3lq5+Drb1sHRmwbjjCZtq/SvBT0vDxX8KdBGRKeKEb0FnZmvMbIeZ1ZjZl8bYb2b2vcT+18xMl9CJiLzNJgx0M/OAHwBXAsuAtWa2bMRhVwILEx/rgB+luZwiIjKBVFroK4Ea59we51w/cB9wzYhjrgF+4nwbgCIzK09zWUVEZBypBHoFUJv0uC6x7a0eg5mtM7ONZraxsbFx5G4RETkBqQT6WEOyI0dSUzkG59wdzrlq51x1WVkaLmsWEZEhqQR6HTA76XElMHK2firHiIjISZRKoL8ELDSzeWaWAVwPPDTimIeAGxOzXc4H2pxzB9NcVhERGceEd0BwzsXM7LPAY4AH3OWc22pmn07svx14BLgKqAG6gVtOXpFFRGQsk3ZhkZk1AvuO89tLgaY0FicoTsV6n4p1hlOz3qdineGt13uuc27MQchJC/QTYWYbj3Wl1FR2Ktb7VKwznJr1PhXrDOmtd0pXioqIyDufAl1EZIoIaqDfMdkFmCSnYr1PxTrDqVnvU7HOkMZ6B7IPXURERgtqC11EREZQoIuITBGBC/SJ1mafCsxstpk9aWZvmNlWM7stsb3EzP7LzHYlPhdPdlnTzcw8M3vVzB5OPD4V6lxkZveb2fbE7/yCU6Tef574+95iZveaWdZUq7eZ3WVmDWa2JWnbMetoZl9OZNsOM7virT5foAI9xbXZp4IY8AXn3FLgfOAziXp+Cfidc24h8LvE46nmNuCNpMenQp2/CzzqnFsCrMCv/5Sut5lVAH8GVDvnzsC/Cv16pl697wbWjNg2Zh0T/+PXA6cnvueHicxLWaACndTWZg8859xB59wria878P/BK/Dr+m+Jw/4N+OCkFPAkMbNK4GrgzqTNU73OBcDFwI8BnHP9zrlWpni9E8JAtpmFgRz8Bf2mVL2dc88ALSM2H6uO1wD3Oef6nHN78ZdSWflWni9ogZ7SuutTiZlVAWcBLwIzBhc9S3yePolFOxm+A/wVMJC0barXeT7QCPxroqvpTjPLZYrX2zl3APhHYD9wEH9Bv8eZ4vVOOFYdTzjfghboKa27PlWYWR7wAPB551z7ZJfnZDKz9wENzrmXJ7ssb7MwcDbwI+fcWUAXwe9mmFCi3/gaYB4wC8g1sxsmt1ST7oTzLWiBfsqsu25mEfww/5lzbn1i8+HBW/slPjdMVvlOgj8APmBmb+J3pV1mZj9latcZ/L/pOufci4nH9+MH/FSv97uBvc65RudcFFgPXMjUrzccu44nnG9BC/RU1mYPPDMz/D7VN5xz/y9p10PATYmvbwIefLvLdrI4577snKt0zlXh/16fcM7dwBSuM4Bz7hBQa2aLE5suB7YxxeuN39VyvpnlJP7eL8cfK5rq9YZj1/Eh4HozyzSzecBC4L/f0pmdc4H6wF93fSewG/jKZJfnJNXxIvy3Wq8BmxIfVwHT8EfFdyU+l0x2WU9S/VcDDye+nvJ1Bt4FbEz8vn8NFJ8i9f47YDuwBbgHyJxq9QbuxR8jiOK3wD8xXh2BrySybQdw5Vt9Pl36LyIyRQSty0VERI5BgS4iMkUo0EVEpggFuojIFKFAFxGZIhToIiJThAJdRGSK+P+4VHXJeKS7owAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "# val_loss가 더 크면 과적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94070359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18889561d60>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c4b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5207311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39a421fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_oh)\n",
    "model = Sequential()\n",
    "model.add(Dense(36, activation='relu', input_dim=12))\n",
    "model.add(Dense(18, activation='relu'))\n",
    "model.add(Dense(9, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# model.summary()\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea998c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "430af56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a6d91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = './deep_model/model_check/{epoch:02d}-{val_loss:4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor='val_loss', verbose=1, \\\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "573443c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.3494 - accuracy: 0.8701 \n",
      "Epoch 1: val_loss improved from inf to 0.22379, saving model to ./deep_model/model_check\\01-0.223793.hdf5\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8761 - val_loss: 0.2238 - val_accuracy: 0.9374\n",
      "Epoch 2/200\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.2213 - accuracy: 0.9333\n",
      "Epoch 2: val_loss improved from 0.22379 to 0.17235, saving model to ./deep_model/model_check\\02-0.172350.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9307 - val_loss: 0.1724 - val_accuracy: 0.9477\n",
      "Epoch 3/200\n",
      "63/78 [=======================>......] - ETA: 0s - loss: 0.1910 - accuracy: 0.9340\n",
      "Epoch 3: val_loss improved from 0.17235 to 0.15804, saving model to ./deep_model/model_check\\03-0.158035.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9323 - val_loss: 0.1580 - val_accuracy: 0.9477\n",
      "Epoch 4/200\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.1871 - accuracy: 0.9338\n",
      "Epoch 4: val_loss did not improve from 0.15804\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9338 - val_loss: 0.1605 - val_accuracy: 0.9467\n",
      "Epoch 5/200\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.1816 - accuracy: 0.9370\n",
      "Epoch 5: val_loss did not improve from 0.15804\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9361 - val_loss: 0.1729 - val_accuracy: 0.9467\n",
      "Epoch 6/200\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.1770 - accuracy: 0.9370\n",
      "Epoch 6: val_loss improved from 0.15804 to 0.13980, saving model to ./deep_model/model_check\\06-0.139803.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.9374 - val_loss: 0.1398 - val_accuracy: 0.9518\n",
      "Epoch 7/200\n",
      "64/78 [=======================>......] - ETA: 0s - loss: 0.1644 - accuracy: 0.9400\n",
      "Epoch 7: val_loss improved from 0.13980 to 0.13389, saving model to ./deep_model/model_check\\07-0.133892.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9400 - val_loss: 0.1339 - val_accuracy: 0.9549\n",
      "Epoch 8/200\n",
      "64/78 [=======================>......] - ETA: 0s - loss: 0.1503 - accuracy: 0.9441\n",
      "Epoch 8: val_loss improved from 0.13389 to 0.12915, saving model to ./deep_model/model_check\\08-0.129146.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9438 - val_loss: 0.1291 - val_accuracy: 0.9569\n",
      "Epoch 9/200\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.1520 - accuracy: 0.9446\n",
      "Epoch 9: val_loss improved from 0.12915 to 0.12723, saving model to ./deep_model/model_check\\09-0.127233.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9451 - val_loss: 0.1272 - val_accuracy: 0.9559\n",
      "Epoch 10/200\n",
      "63/78 [=======================>......] - ETA: 0s - loss: 0.1362 - accuracy: 0.9502\n",
      "Epoch 10: val_loss did not improve from 0.12723\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9487 - val_loss: 0.1436 - val_accuracy: 0.9549\n",
      "Epoch 11/200\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.1328 - accuracy: 0.9533\n",
      "Epoch 11: val_loss improved from 0.12723 to 0.11577, saving model to ./deep_model/model_check\\11-0.115767.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9502 - val_loss: 0.1158 - val_accuracy: 0.9579\n",
      "Epoch 12/200\n",
      "62/78 [======================>.......] - ETA: 0s - loss: 0.1307 - accuracy: 0.9545\n",
      "Epoch 12: val_loss improved from 0.11577 to 0.10859, saving model to ./deep_model/model_check\\12-0.108594.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9556 - val_loss: 0.1086 - val_accuracy: 0.9600\n",
      "Epoch 13/200\n",
      "63/78 [=======================>......] - ETA: 0s - loss: 0.1394 - accuracy: 0.9508\n",
      "Epoch 13: val_loss improved from 0.10859 to 0.10375, saving model to ./deep_model/model_check\\13-0.103754.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9518 - val_loss: 0.1038 - val_accuracy: 0.9651\n",
      "Epoch 14/200\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.1163 - accuracy: 0.9603\n",
      "Epoch 14: val_loss improved from 0.10375 to 0.09923, saving model to ./deep_model/model_check\\14-0.099229.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9607 - val_loss: 0.0992 - val_accuracy: 0.9682\n",
      "Epoch 15/200\n",
      "64/78 [=======================>......] - ETA: 0s - loss: 0.1130 - accuracy: 0.9600\n",
      "Epoch 15: val_loss improved from 0.09923 to 0.08925, saving model to ./deep_model/model_check\\15-0.089245.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9597 - val_loss: 0.0892 - val_accuracy: 0.9662\n",
      "Epoch 16/200\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.1064 - accuracy: 0.9603\n",
      "Epoch 16: val_loss improved from 0.08925 to 0.08545, saving model to ./deep_model/model_check\\16-0.085446.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9625 - val_loss: 0.0854 - val_accuracy: 0.9682\n",
      "Epoch 17/200\n",
      "59/78 [=====================>........] - ETA: 0s - loss: 0.0960 - accuracy: 0.9637\n",
      "Epoch 17: val_loss improved from 0.08545 to 0.08150, saving model to ./deep_model/model_check\\17-0.081498.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9659 - val_loss: 0.0815 - val_accuracy: 0.9682\n",
      "Epoch 18/200\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0974 - accuracy: 0.9686\n",
      "Epoch 18: val_loss improved from 0.08150 to 0.07846, saving model to ./deep_model/model_check\\18-0.078463.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9687 - val_loss: 0.0785 - val_accuracy: 0.9713\n",
      "Epoch 19/200\n",
      "64/78 [=======================>......] - ETA: 0s - loss: 0.1039 - accuracy: 0.9656\n",
      "Epoch 19: val_loss did not improve from 0.07846\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9648 - val_loss: 0.1445 - val_accuracy: 0.9549\n",
      "Epoch 20/200\n",
      "63/78 [=======================>......] - ETA: 0s - loss: 0.0973 - accuracy: 0.9670\n",
      "Epoch 20: val_loss did not improve from 0.07846\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9692 - val_loss: 0.0960 - val_accuracy: 0.9723\n",
      "Epoch 21/200\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0810 - accuracy: 0.9707\n",
      "Epoch 21: val_loss improved from 0.07846 to 0.07122, saving model to ./deep_model/model_check\\21-0.071224.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9705 - val_loss: 0.0712 - val_accuracy: 0.9723\n",
      "Epoch 22/200\n",
      "60/78 [======================>.......] - ETA: 0s - loss: 0.0816 - accuracy: 0.9733\n",
      "Epoch 22: val_loss did not improve from 0.07122\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9713 - val_loss: 0.0994 - val_accuracy: 0.9641\n",
      "Epoch 23/200\n",
      "63/78 [=======================>......] - ETA: 0s - loss: 0.0858 - accuracy: 0.9714\n",
      "Epoch 23: val_loss improved from 0.07122 to 0.06671, saving model to ./deep_model/model_check\\23-0.066714.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9736 - val_loss: 0.0667 - val_accuracy: 0.9733\n",
      "Epoch 24/200\n",
      "63/78 [=======================>......] - ETA: 0s - loss: 0.0789 - accuracy: 0.9759\n",
      "Epoch 24: val_loss did not improve from 0.06671\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9756 - val_loss: 0.0720 - val_accuracy: 0.9744\n",
      "Epoch 25/200\n",
      "62/78 [======================>.......] - ETA: 0s - loss: 0.0831 - accuracy: 0.9726\n",
      "Epoch 25: val_loss improved from 0.06671 to 0.06570, saving model to ./deep_model/model_check\\25-0.065699.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9749 - val_loss: 0.0657 - val_accuracy: 0.9744\n",
      "Epoch 26/200\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0740 - accuracy: 0.9761\n",
      "Epoch 26: val_loss did not improve from 0.06570\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9761 - val_loss: 0.0672 - val_accuracy: 0.9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0825 - accuracy: 0.9729\n",
      "Epoch 27: val_loss improved from 0.06570 to 0.06453, saving model to ./deep_model/model_check\\27-0.064533.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9741 - val_loss: 0.0645 - val_accuracy: 0.9754\n",
      "Epoch 28/200\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0780 - accuracy: 0.9748\n",
      "Epoch 28: val_loss did not improve from 0.06453\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 0.9756 - val_loss: 0.1454 - val_accuracy: 0.9538\n",
      "Epoch 29/200\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0707 - accuracy: 0.9794\n",
      "Epoch 29: val_loss did not improve from 0.06453\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9792 - val_loss: 0.0717 - val_accuracy: 0.9764\n",
      "Epoch 30/200\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0696 - accuracy: 0.9769\n",
      "Epoch 30: val_loss improved from 0.06453 to 0.05735, saving model to ./deep_model/model_check\\30-0.057353.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9779 - val_loss: 0.0574 - val_accuracy: 0.9795\n",
      "Epoch 31/200\n",
      "64/78 [=======================>......] - ETA: 0s - loss: 0.0754 - accuracy: 0.9741\n",
      "Epoch 31: val_loss did not improve from 0.05735\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9754 - val_loss: 0.0722 - val_accuracy: 0.9764\n",
      "Epoch 32/200\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0644 - accuracy: 0.9806\n",
      "Epoch 32: val_loss did not improve from 0.05735\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.0683 - val_accuracy: 0.9774\n",
      "Epoch 33/200\n",
      "63/78 [=======================>......] - ETA: 0s - loss: 0.0662 - accuracy: 0.9800\n",
      "Epoch 33: val_loss did not improve from 0.05735\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9797 - val_loss: 0.1156 - val_accuracy: 0.9621\n",
      "Epoch 34/200\n",
      "64/78 [=======================>......] - ETA: 0s - loss: 0.0729 - accuracy: 0.9766\n",
      "Epoch 34: val_loss improved from 0.05735 to 0.05632, saving model to ./deep_model/model_check\\34-0.056315.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9784 - val_loss: 0.0563 - val_accuracy: 0.9856\n",
      "Epoch 35/200\n",
      "64/78 [=======================>......] - ETA: 0s - loss: 0.0612 - accuracy: 0.9831\n",
      "Epoch 35: val_loss improved from 0.05632 to 0.05469, saving model to ./deep_model/model_check\\35-0.054688.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9820 - val_loss: 0.0547 - val_accuracy: 0.9785\n",
      "Epoch 36/200\n",
      "62/78 [======================>.......] - ETA: 0s - loss: 0.0755 - accuracy: 0.9784\n",
      "Epoch 36: val_loss did not improve from 0.05469\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9802 - val_loss: 0.0587 - val_accuracy: 0.9774\n",
      "Epoch 37/200\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.0827 - accuracy: 0.9716\n",
      "Epoch 37: val_loss improved from 0.05469 to 0.05352, saving model to ./deep_model/model_check\\37-0.053523.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9728 - val_loss: 0.0535 - val_accuracy: 0.9815\n",
      "Epoch 38/200\n",
      "61/78 [======================>.......] - ETA: 0s - loss: 0.0548 - accuracy: 0.9833\n",
      "Epoch 38: val_loss did not improve from 0.05352\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9823 - val_loss: 0.0550 - val_accuracy: 0.9795\n",
      "Epoch 39/200\n",
      "63/78 [=======================>......] - ETA: 0s - loss: 0.0594 - accuracy: 0.9813\n",
      "Epoch 39: val_loss did not improve from 0.05352\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9826 - val_loss: 0.0681 - val_accuracy: 0.9805\n",
      "Epoch 40/200\n",
      "57/78 [====================>.........] - ETA: 0s - loss: 0.0589 - accuracy: 0.9821\n",
      "Epoch 40: val_loss improved from 0.05352 to 0.05158, saving model to ./deep_model/model_check\\40-0.051585.hdf5\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9808 - val_loss: 0.0516 - val_accuracy: 0.9815\n",
      "Epoch 41/200\n",
      "58/78 [=====================>........] - ETA: 0s - loss: 0.0540 - accuracy: 0.9852\n",
      "Epoch 41: val_loss did not improve from 0.05158\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9838 - val_loss: 0.0540 - val_accuracy: 0.9785\n",
      "Epoch 42/200\n",
      "69/78 [=========================>....] - ETA: 0s - loss: 0.0640 - accuracy: 0.9812\n",
      "Epoch 42: val_loss did not improve from 0.05158\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9818 - val_loss: 0.0694 - val_accuracy: 0.9723\n",
      "Epoch 43/200\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0502 - accuracy: 0.9825\n",
      "Epoch 43: val_loss did not improve from 0.05158\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9820 - val_loss: 0.1007 - val_accuracy: 0.9651\n",
      "Epoch 44/200\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0608 - accuracy: 0.9821\n",
      "Epoch 44: val_loss did not improve from 0.05158\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9815 - val_loss: 0.0572 - val_accuracy: 0.9826\n",
      "Epoch 45/200\n",
      "65/78 [========================>.....] - ETA: 0s - loss: 0.0489 - accuracy: 0.9862\n",
      "Epoch 45: val_loss did not improve from 0.05158\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9828 - val_loss: 0.0614 - val_accuracy: 0.9744\n",
      "Epoch 46/200\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0581 - accuracy: 0.9821\n",
      "Epoch 46: val_loss did not improve from 0.05158\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9820 - val_loss: 0.0601 - val_accuracy: 0.9826\n",
      "Epoch 47/200\n",
      "66/78 [========================>.....] - ETA: 0s - loss: 0.0524 - accuracy: 0.9858\n",
      "Epoch 47: val_loss did not improve from 0.05158\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9843 - val_loss: 0.0518 - val_accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.2, batch_size=50, epochs=200, \\\n",
    "                    callbacks=[checkpointer, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3639bb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1888981bc40>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdf16a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1888a837bb0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b7b853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 616us/step - loss: 0.0885 - accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08850596100091934, 0.9753845930099487]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f4c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
