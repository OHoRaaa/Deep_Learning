{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad7a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822972f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56977609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "\n",
       "       11    12    13  \n",
       "0  396.90  4.98  24.0  \n",
       "1  396.90  9.14  21.6  \n",
       "2  392.83  4.03  34.7  \n",
       "3  394.63  2.94  33.4  \n",
       "4  396.90  5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/housing.csv', header = None, delim_whitespace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8f44e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       506 non-null    float64\n",
      " 1   1       506 non-null    float64\n",
      " 2   2       506 non-null    float64\n",
      " 3   3       506 non-null    int64  \n",
      " 4   4       506 non-null    float64\n",
      " 5   5       506 non-null    float64\n",
      " 6   6       506 non-null    float64\n",
      " 7   7       506 non-null    float64\n",
      " 8   8       506 non-null    int64  \n",
      " 9   9       506 non-null    float64\n",
      " 10  10      506 non-null    float64\n",
      " 11  11      506 non-null    float64\n",
      " 12  12      506 non-null    float64\n",
      " 13  13      506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48bdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "629b19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.values[:, 13]\n",
    "x = df.values[:, :13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e9ecb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y     # continous data => regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b33674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c1bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e2fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "553b50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 13, activation = 'relu'))\n",
    "model.add(Dense(20, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1))                         # regression에서는 output layer에 activation function을 사용하지 않는다\n",
    "\n",
    "# binary cls activation : sigmoid()\n",
    "# multi cls activation : softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb434f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91747225",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')     # regression 에서는 loss 로 'mean_squared_error' 를 쓴다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f104e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ed30912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1870.8367 - val_loss: 418.9166\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 453.8241 - val_loss: 216.6223\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 168.5307 - val_loss: 146.4696\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 102.3742 - val_loss: 92.8906\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 77.5701 - val_loss: 83.3459\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 66.5905 - val_loss: 69.5687\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 61.0828 - val_loss: 67.9150\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 57.7126 - val_loss: 63.3072\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 55.9888 - val_loss: 61.6543\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 54.5473 - val_loss: 59.2994\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 52.6259 - val_loss: 59.2607\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 51.9351 - val_loss: 57.3034\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 51.4142 - val_loss: 57.6048\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 50.7358 - val_loss: 55.6057\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 50.1035 - val_loss: 58.2105\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 50.2524 - val_loss: 55.8178\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 50.7976 - val_loss: 53.7149\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.4749 - val_loss: 53.2398\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 52.5122 - val_loss: 58.2382\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 51.2869 - val_loss: 58.7593\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.9924 - val_loss: 52.3009\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.9252 - val_loss: 55.9794\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.3972 - val_loss: 51.4328\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 46.8508 - val_loss: 53.1079\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 46.3570 - val_loss: 51.7820\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.2020 - val_loss: 50.7229\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 45.5737 - val_loss: 53.5491\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 45.7263 - val_loss: 53.0615\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 46.9481 - val_loss: 56.5234\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.0204 - val_loss: 52.4914\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 46.2837 - val_loss: 50.7567\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 46.3794 - val_loss: 48.6500\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 44.4174 - val_loss: 50.1911\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 44.3717 - val_loss: 50.1636\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 46.7985 - val_loss: 48.6634\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 43.3032 - val_loss: 48.1332\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 44.4328 - val_loss: 48.1250\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42.8749 - val_loss: 52.3703\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 45.1482 - val_loss: 47.6674\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 44.1003 - val_loss: 48.9650\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 43.1894 - val_loss: 48.3080\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41.5684 - val_loss: 53.7575\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41.2192 - val_loss: 53.0046\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 46.1987 - val_loss: 55.0333\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42.8101 - val_loss: 43.9250\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 40.4393 - val_loss: 43.6445\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41.2433 - val_loss: 43.6332\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 39.5715 - val_loss: 44.0989\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 39.2102 - val_loss: 51.6193\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 38.3545 - val_loss: 42.2583\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 38.1596 - val_loss: 48.8030\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 39.6429 - val_loss: 41.3616\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 38.5881 - val_loss: 44.2849\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 37.3088 - val_loss: 42.6837\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 37.2645 - val_loss: 48.1360\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 38.5118 - val_loss: 40.2238\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36.0614 - val_loss: 39.9964\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36.0729 - val_loss: 39.4240\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34.7592 - val_loss: 40.1711\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35.4025 - val_loss: 38.4943\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35.0236 - val_loss: 38.7863\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35.7593 - val_loss: 41.5659\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35.4968 - val_loss: 43.7237\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36.0320 - val_loss: 41.1793\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33.5880 - val_loss: 37.6762\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33.7246 - val_loss: 36.6401\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33.7953 - val_loss: 36.3083\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33.9430 - val_loss: 36.5087\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33.7782 - val_loss: 36.4286\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 38.8068 - val_loss: 41.0824\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 44.7283 - val_loss: 47.1661\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35.9230 - val_loss: 37.6532\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35.8381 - val_loss: 44.9204\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41.9908 - val_loss: 42.4100\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.1178 - val_loss: 39.9665\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.8601 - val_loss: 36.8431\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.9744 - val_loss: 44.4404\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33.2392 - val_loss: 36.5575\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.4623 - val_loss: 34.8319\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.9496 - val_loss: 35.5016\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36.2270 - val_loss: 35.5115\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 40.0522 - val_loss: 51.9697\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 44.3860 - val_loss: 43.7439\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 37.6842 - val_loss: 38.0219\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.0602 - val_loss: 34.1283\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.5442 - val_loss: 35.2712\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.0736 - val_loss: 34.4151\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34.2551 - val_loss: 39.5733\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35.7577 - val_loss: 32.9616\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.2332 - val_loss: 50.0397\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35.4730 - val_loss: 43.8348\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.9331 - val_loss: 36.3351\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.6438 - val_loss: 38.0043\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.1529 - val_loss: 36.3911\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.5943 - val_loss: 33.4691\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.2085 - val_loss: 35.7626\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 37.2292 - val_loss: 33.8996\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35.6335 - val_loss: 41.0776\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.7472 - val_loss: 35.5742\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.1856 - val_loss: 32.0766\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, validation_split=0.2, epochs = 100, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a3393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8283e0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14554554cd0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeb69106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 909us/step - loss: 39.1853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39.185325622558594"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9691f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77b508a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "293aea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a36699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 13, activation = 'relu'))\n",
    "model.add(Dense(20, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1))             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7bd1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96dc50c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 538.5395 - val_loss: 571.5735\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 509.9920 - val_loss: 534.6187\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 468.7024 - val_loss: 479.3927\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 407.6618 - val_loss: 400.3580\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 325.7673 - val_loss: 299.8138\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 230.5895 - val_loss: 200.6907\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 156.0376 - val_loss: 142.4006\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 124.7413 - val_loss: 125.2109\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 115.9326 - val_loss: 116.3511\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 106.6483 - val_loss: 109.8132\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 98.3076 - val_loss: 101.5104\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 90.5505 - val_loss: 93.9771\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 83.6528 - val_loss: 89.5369\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 76.1650 - val_loss: 81.1117\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 69.7336 - val_loss: 77.3879\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 64.6560 - val_loss: 71.6553\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 60.8333 - val_loss: 67.9157\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 57.0870 - val_loss: 66.9810\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 54.6079 - val_loss: 63.9196\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 52.2958 - val_loss: 62.7384\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 50.4953 - val_loss: 60.5400\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.0012 - val_loss: 59.7850\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.8894 - val_loss: 58.7625\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 46.9920 - val_loss: 57.6046\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 45.8324 - val_loss: 56.3990\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 44.7327 - val_loss: 55.3993\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 43.6176 - val_loss: 54.7649\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42.8914 - val_loss: 54.5755\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41.6504 - val_loss: 52.6085\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41.7194 - val_loss: 51.4534\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 39.7408 - val_loss: 51.7510\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 38.7376 - val_loss: 50.2189\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 38.2201 - val_loss: 48.9579\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36.9982 - val_loss: 49.3232\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36.2145 - val_loss: 48.7389\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35.6162 - val_loss: 46.9789\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34.8047 - val_loss: 46.5348\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33.6413 - val_loss: 45.3743\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.9295 - val_loss: 44.7808\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.1308 - val_loss: 44.0250\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.6924 - val_loss: 43.8656\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.9289 - val_loss: 42.4215\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 29.9356 - val_loss: 42.0487\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 29.3054 - val_loss: 41.1396\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 28.5300 - val_loss: 40.2621\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 27.6312 - val_loss: 39.9355\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 27.1940 - val_loss: 38.9661\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 26.5172 - val_loss: 38.3087\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 25.7730 - val_loss: 37.8888\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 25.4612 - val_loss: 37.1591\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 24.7921 - val_loss: 36.6810\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 24.5625 - val_loss: 36.1419\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 23.5213 - val_loss: 35.4339\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 23.0079 - val_loss: 35.0618\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 22.7057 - val_loss: 34.3409\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 22.3680 - val_loss: 34.0791\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 21.9648 - val_loss: 33.6412\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 22.0320 - val_loss: 33.4513\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 21.5514 - val_loss: 32.9079\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20.9773 - val_loss: 32.6308\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20.5774 - val_loss: 32.4164\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20.4410 - val_loss: 32.1904\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20.2667 - val_loss: 32.0273\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19.7615 - val_loss: 31.8568\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19.8030 - val_loss: 31.5554\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19.4764 - val_loss: 31.7563\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 21.7579 - val_loss: 31.8075\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19.8992 - val_loss: 31.7089\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19.0935 - val_loss: 31.2928\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.7954 - val_loss: 31.0091\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.7981 - val_loss: 31.0403\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.6445 - val_loss: 30.9121\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.4094 - val_loss: 30.7746\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.3531 - val_loss: 30.7916\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.4067 - val_loss: 30.6632\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19.0089 - val_loss: 30.4952\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.2344 - val_loss: 30.5323\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.8702 - val_loss: 30.4086\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.1289 - val_loss: 30.5912\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.9429 - val_loss: 30.5793\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.5942 - val_loss: 30.3111\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.8054 - val_loss: 30.1941\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.4651 - val_loss: 30.1130\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.4669 - val_loss: 29.9145\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.3107 - val_loss: 30.0074\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.1105 - val_loss: 29.8422\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.2429 - val_loss: 29.8214\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.9069 - val_loss: 30.0716\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.1720 - val_loss: 29.9085\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.0455 - val_loss: 30.2387\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.8851 - val_loss: 29.8060\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.9303 - val_loss: 29.6066\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.7969 - val_loss: 29.6668\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.7830 - val_loss: 29.7163\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.4532 - val_loss: 29.6254\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.5948 - val_loss: 29.6676\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.3599 - val_loss: 29.7957\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.3733 - val_loss: 29.6481\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.3659 - val_loss: 29.6254\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.0402 - val_loss: 29.4048\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_sc, y_train, validation_split=0.2, epochs = 100, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0eac42c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 665us/step - loss: 17.7260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.72597885131836"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b395cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93695441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e03d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ad5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0c55ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a80c54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7828660554544689"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "### r2score\n",
    "\n",
    "# 회귀 모델이 얼마나 '설명력'이 있느냐를 의미\n",
    "# 예측 모델과 실제 모델이 얼마나 강한 상관관계를 가지는가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17f6c8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 - 27\n",
      "30 - 29\n",
      "31 - 30\n",
      "20 - 19\n",
      "48 - 43\n",
      "22 - 27\n",
      "35 - 36\n",
      "16 - 17\n",
      "23 - 22\n",
      "10 - 14\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    pred_price = preds[i]\n",
    "    real_price = y_test[i]\n",
    "    print('{} - {}'.format(round(real_price), round(pred_price[0])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8cc5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
