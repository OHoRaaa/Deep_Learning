{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e54d8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4e879782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfe638f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 , ...,   0.  ,  62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88, ...,   0.  ,  60.  ,   0.  ],\n",
       "       [  8.  ,   2.  ,   3.19, ...,   0.  ,  66.  ,   1.  ],\n",
       "       ...,\n",
       "       [406.  ,   6.  ,   5.36, ...,   0.  ,  62.  ,   0.  ],\n",
       "       [ 25.  ,   8.  ,   4.32, ...,   0.  ,  58.  ,   1.  ],\n",
       "       [447.  ,   8.  ,   5.2 , ...,   0.  ,  49.  ,   0.  ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = np.loadtxt('../Data/ThoraricSurgery.csv', delimiter = ',')\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f8422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_set[:, 0 : 17]\n",
    "y = data_set[:, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ab157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dec7610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 3)                 54        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 16        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75\n",
      "Trainable params: 75\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim = 17, activation = 'relu'))\n",
    "model.add(Dense(4, input_dim = 17, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e6359dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a3429e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.0556 - accuracy: 0.7723\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.5127 - accuracy: 0.7681\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0345 - accuracy: 0.7681\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5949 - accuracy: 0.7681\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2577 - accuracy: 0.7681\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9389 - accuracy: 0.7681\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7143 - accuracy: 0.7702\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.7745\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7787\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a886732df0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5febff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb671b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c559e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685db94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5c6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66027c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afdb0b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>piasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insuline</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  piasma  pressure  thickness  insuline   bmi  pedigree  age  class\n",
       "0           6     148        72         35         0  33.6     0.627   50      1\n",
       "1           1      85        66         29         0  26.6     0.351   31      0\n",
       "2           8     183        64          0         0  23.3     0.672   32      1\n",
       "3           1      89        66         23        94  28.1     0.167   21      0\n",
       "4           0     137        40         35       168  43.1     2.288   33      1\n",
       "..        ...     ...       ...        ...       ...   ...       ...  ...    ...\n",
       "763        10     101        76         48       180  32.9     0.171   63      0\n",
       "764         2     122        70         27         0  36.8     0.340   27      0\n",
       "765         5     121        72         23       112  26.2     0.245   30      0\n",
       "766         1     126        60          0         0  30.1     0.349   47      1\n",
       "767         1      93        70         31         0  30.4     0.315   23      0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['pregnant','piasma', 'pressure','thickness','insuline','bmi','pedigree','age','class']\n",
    "df = pd.read_csv('../Data/pima-indians-diabetes.csv', header = None, names = cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c8160c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pregnant   768 non-null    int64  \n",
      " 1   piasma     768 non-null    int64  \n",
      " 2   pressure   768 non-null    int64  \n",
      " 3   thickness  768 non-null    int64  \n",
      " 4   insuline   768 non-null    int64  \n",
      " 5   bmi        768 non-null    float64\n",
      " 6   pedigree   768 non-null    float64\n",
      " 7   age        768 non-null    int64  \n",
      " 8   class      768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbd6c251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11127931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.loadtxt('../Data/pima-indians-diabetes.csv', delimiter=',')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79f7b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[:, 8]\n",
    "x = dataset[:, 0 : 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "490b2dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77e25d79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccbe0794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 12)                108       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8914c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39736c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.9646 - accuracy: 0.5169\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.2760 - accuracy: 0.5794\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.8817 - accuracy: 0.5846\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.5798 - accuracy: 0.6029\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.6016\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.2590 - accuracy: 0.6172\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.1809 - accuracy: 0.6029\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.1172 - accuracy: 0.6107\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.0648 - accuracy: 0.6302\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.0318 - accuracy: 0.6159\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9877 - accuracy: 0.6224\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9525 - accuracy: 0.6328\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9168 - accuracy: 0.6354\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9374 - accuracy: 0.6198\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9013 - accuracy: 0.6185\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.8634 - accuracy: 0.6328\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9516 - accuracy: 0.6419\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9783 - accuracy: 0.6224\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.8346 - accuracy: 0.6302\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7918 - accuracy: 0.6523\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7677 - accuracy: 0.6536\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.6471\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.6758\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.6628\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7172 - accuracy: 0.6432\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7139 - accuracy: 0.6719\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.6771\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7112 - accuracy: 0.6732\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.6654\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.6888\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.6901\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.6836\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.6862\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.6914\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.7174\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6862\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6966\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.6562\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6992\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6979\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.7070\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.7031\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6849\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.7083\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.7096\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6849\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.7174\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.7148\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.7122\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.7044\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6025 - accuracy: 0.7122\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.7018\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6810\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.7174\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.7266\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7044\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.7214\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.7083\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.7044\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7070\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7083\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.7044\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7005\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.7096\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7201\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7227\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7122\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7174\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7018\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7331\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7201\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7266\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7279\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7135\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7240\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7227\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7161\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7331\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7201\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7044\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7279\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.7188\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7357\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.7161\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7331\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7370\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7331\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7266\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7305\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7279\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7383\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7018\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7109\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7305\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7240\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7305\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7344\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7188\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7396\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa6ffbc100>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs = 100, batch_size = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6157b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(df.iloc[:, :8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3dbfacbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.6055\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6810\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.7031\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7344\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7448\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7552\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7630\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7669\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7747\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7839\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7865\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7891\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7865\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7878\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7904\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7891\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7891\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7904\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7917\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7917\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7943\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7956\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7956\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7969\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7943\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7969\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7995\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7969\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7982\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7943\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7995\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7956\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8008\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7995\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8060\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7995\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7995\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7995\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8008\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8021\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8008\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.8047\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7995\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8034\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8008\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8034\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8047\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8060\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8086\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8021\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8099\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8060\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8047\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8060\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8086\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8073\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8060\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8099\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8151\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8073\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8099\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8073\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8099\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8086\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8086\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8086\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8099\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8086\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8099\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8099\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8060\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8099\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8060\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8073\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8086\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8125\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8151\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8073\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8151\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8112\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8138\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8099\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8151\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8138\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8099\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8112\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8164\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8125\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8099\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8073\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8099\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8099\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8112\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8125\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8099\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8151\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8125\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8164\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8138\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa71c8ad00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_scaled, y, epochs = 100, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b005917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39837726950645447, 0.8177083134651184]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ec6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafd6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e317491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b179c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a13a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7601e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08933260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sl   sw   pl   pw         species\n",
       "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/iris.csv', names = ['sl', 'sw', 'pl', 'pw', 'species'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d0c7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.values[:,4]\n",
    "x = df.values[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574f76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3f57f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e =LabelEncoder()\n",
    "y_en = e.fit_transform(y)\n",
    "y_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fca7761b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38375eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oh = tf.keras.utils.to_categorical(y_en)\n",
    "y_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "038a2d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ab6549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243\n",
      "Trainable params: 243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim = 4, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfd72e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07549354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1571 - accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0409 - accuracy: 0.3533\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9676 - accuracy: 0.5733\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9085 - accuracy: 0.6800\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8481 - accuracy: 0.8933\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7949 - accuracy: 0.8933\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7471 - accuracy: 0.7867\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.7600\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.7800\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7600\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7667\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8133\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8533\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8933\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.9267\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.9133\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.9400\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.9400\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.9333\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.9533\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.9533\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.9667\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.9667\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.9467\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.9667\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.9800\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.9733\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.9667\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9667\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.9733\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.9667\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.9733\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9467\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9667\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9667\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9733\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9800\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9800\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9733\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9800\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9733\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9733\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9800\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9800\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9800\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9800\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.9800\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9800\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9800\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9800\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9733\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9800\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9800\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9667\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9733\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.9733\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.9800\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9867\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9800\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.9800\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9800\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9800\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.9800\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9800\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9800\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9800\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9800\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.9800\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9800\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.9800\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9800\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9867\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9800\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9867\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9800\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9800\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9800\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9800\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.9800\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9800\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9800\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9800\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9667\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9800\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9800\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9867\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9800\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9800\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9867\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9800\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9800\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0864 - accuracy: 0.9800\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9800\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9800\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9867\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9867\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa72280970>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x.astype(float), y_oh, epochs = 100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1af68186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08165434747934341, 0.9800000190734863]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x.astype(float), y_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f55a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d620b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e165475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44d643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e5b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be675c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6e77afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.2238</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.2999</td>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.4797</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.4328</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.6415</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.5121</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.8537</td>\n",
       "      <td>0.8507</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.6097</td>\n",
       "      <td>0.4943</td>\n",
       "      <td>0.2744</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.2834</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.8024</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.3914</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3271</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.4423</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.3788</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.5320</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6759</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>0.4293</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.8512</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>0.6756</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.2261</td>\n",
       "      <td>0.1729</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>0.3973</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.3559</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.7340</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.3012</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.6121</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.2655</td>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.4152</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.6193</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.4292</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.5399</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7262</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.5103</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.2881</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.4181</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2034</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>0.6879</td>\n",
       "      <td>0.8120</td>\n",
       "      <td>0.8453</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8104</td>\n",
       "      <td>0.6199</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>0.5547</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>0.3085</td>\n",
       "      <td>0.3425</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.2429</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>0.5949</td>\n",
       "      <td>0.8302</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.7412</td>\n",
       "      <td>0.7691</td>\n",
       "      <td>0.7117</td>\n",
       "      <td>0.5304</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.2716</td>\n",
       "      <td>0.2374</td>\n",
       "      <td>0.1878</td>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.1503</td>\n",
       "      <td>0.1723</td>\n",
       "      <td>0.2339</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>0.3164</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.8473</td>\n",
       "      <td>0.9424</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>0.7305</td>\n",
       "      <td>0.5197</td>\n",
       "      <td>0.1786</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1446</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>0.2898</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.0673</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.2645</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.4293</td>\n",
       "      <td>0.5685</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>0.7246</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.8297</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>0.7141</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>0.4961</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1552</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.3714</td>\n",
       "      <td>0.4552</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.7123</td>\n",
       "      <td>0.8358</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.4567</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.1549</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>0.2655</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.2076</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.1439</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6   ...      54      55      56      57      58      59  60\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  ...  0.0072  0.0167  0.0180  0.0084  0.0090  0.0032   R\n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  ...  0.0094  0.0191  0.0140  0.0049  0.0052  0.0044   R\n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  ...  0.0180  0.0244  0.0316  0.0164  0.0095  0.0078   R\n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  ...  0.0085  0.0073  0.0050  0.0044  0.0040  0.0117   R\n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  ...  0.0110  0.0015  0.0072  0.0048  0.0107  0.0094   R\n",
       "..      ...     ...     ...     ...     ...     ...     ...  ...     ...     ...     ...     ...     ...     ...  ..\n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  ...  0.0033  0.0101  0.0065  0.0115  0.0193  0.0157   M\n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  ...  0.0063  0.0063  0.0034  0.0032  0.0062  0.0067   M\n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  ...  0.0062  0.0089  0.0140  0.0138  0.0077  0.0031   M\n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  ...  0.0036  0.0035  0.0034  0.0079  0.0036  0.0048   M\n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  ...  0.0039  0.0061  0.0040  0.0036  0.0061  0.0115   M\n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/sonar.csv', header = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a9faf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "24be7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.values[:,:60]\n",
    "y = df.values[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81371a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee22c47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "y_enc = enc.fit_transform(y)\n",
    "y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ae953e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 24)                1464      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 12)                300       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,849\n",
      "Trainable params: 1,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim = 60, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1771ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss ='binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5c127877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.7981\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7596\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7788\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7404\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7788\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8029\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.8077\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.8125\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.8221\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7885\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8173\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8077\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8317\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8317\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8077\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8221\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.7981\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.7981\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8317\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8269\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8365\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8510\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8269\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8462\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8269\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8365\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8606\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8654\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8413\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.8510\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8798\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8558\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8558\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8654\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8846\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8654\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8702\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2820 - accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8942\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.8990\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8990\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2587 - accuracy: 0.9087\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.8990\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.8990\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2551 - accuracy: 0.8846\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2544 - accuracy: 0.9087\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.8990\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.9087\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2314 - accuracy: 0.9231\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2314 - accuracy: 0.9087\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9279\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9279\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2216 - accuracy: 0.9279\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9183\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9183\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9231\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9231\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9375\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9231\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.9279\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9183\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1868 - accuracy: 0.9375\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9327\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9231\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9375\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9231\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9471\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.9279\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9327\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9327\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9519\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9519\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1613 - accuracy: 0.9471\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9471\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9519\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9567\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9471\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9663\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9663\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9519\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9615\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9519\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9615\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1203 - accuracy: 0.9567\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9663\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1145 - accuracy: 0.9760\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9567\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1176 - accuracy: 0.9712\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9712\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9663\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9760\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 0.9712\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9808\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9808\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0921 - accuracy: 0.9760\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9760\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9712\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9760\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa763fdee0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x.astype(float), y_enc, epochs = 100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c30de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "67e87317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oh = tf.keras.utils.to_categorical(y_enc)\n",
    "y_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dba1a994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8e42db7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_37 (Dense)            (None, 24)                1464      \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 12)                300       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 2)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,856\n",
      "Trainable params: 1,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim = 60, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8442b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6405a2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.6346\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.6538\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.6490\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.6587\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.6683\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.6827\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.6731\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.6923\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.6731\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.6875\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.7115\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.6971\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.7163\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.7308\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.7356\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.7404\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.7452\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.7596\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.7692\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7740\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.7596\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7356\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7740\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7837\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7837\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7885\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7885\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7885\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7885\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7981\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7981\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7981\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8173\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8173\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8317\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8221\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8077\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8125\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8269\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8173\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8558\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8269\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8125\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8510\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.8462\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8077\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8317\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8510\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8558\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8462\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8413\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8269\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8510\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3590 - accuracy: 0.8654\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8702\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8558\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8510\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8702\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8413\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8413\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8846\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8750\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8654\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.8413\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8606\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8654\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8702\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8654\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8654\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8606\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8510\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8798\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8606\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8702\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8606\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8654\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8894\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3130 - accuracy: 0.8942\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8894\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.8798\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8894\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8702\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8894\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8798\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8942\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8846\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8942\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.8990\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8942\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8894\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.8942\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8894\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.8990\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.9135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa76825eb0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x.astype(float), y_oh, epochs = 100, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a4e5eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.8990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2807825803756714, 0.8990384340286255]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x.astype(float), y_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a464270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "483126a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x.astype(float), y_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04cef108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.4808\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5449\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.6282\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.7244\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.7308\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.7564\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.7308\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7564\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7885\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7244\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.8013\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7436\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8077\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8141\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8013\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8141\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8269\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8462\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8526\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8526\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8462\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8654\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8526\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8205\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8718\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8718\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8654\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2958 - accuracy: 0.8590\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.8654\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8910\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2667 - accuracy: 0.9038\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 0.8974\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.8910\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.8974\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.9103\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2403 - accuracy: 0.9103\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9231\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.8782\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.8910\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.8590\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2171 - accuracy: 0.9103\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9231\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9423\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9487\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.9359\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1856 - accuracy: 0.9487\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1848 - accuracy: 0.9551\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1875 - accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9295\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9423\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9423\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9551\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1571 - accuracy: 0.9551\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9744\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1526 - accuracy: 0.9679\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9615\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9615\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9679\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9744\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9615\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9679\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9744\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9744\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1224 - accuracy: 0.9744\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1313 - accuracy: 0.9744\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9744\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9744\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9744\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9679\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9744\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9744\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9744\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 0.9744\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9744\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9744\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9744\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9808\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9744\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9808\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9808\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9808\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9808\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9808\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9808\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9808\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9872\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9936\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9872\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9808\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9936\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9936\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9872\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9872\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9936\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9872\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9872\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa75337c70>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2cba787a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.8269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5240545868873596, 0.8269230723381042]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1eebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d181392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809c3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac1517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1bbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ba72ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  11  12\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   5   1\n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   5   1\n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   5   1\n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   6   1\n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   5   1\n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...  ..  ..\n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   6   0\n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   5   0\n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   6   0\n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   7   0\n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   6   0\n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/wine.csv', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b9289b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, 12].values\n",
    "x = df.iloc[:, :12].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "04863619",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8bac5feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_41 (Dense)            (None, 36)                468       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 18)                666       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 9)                 171       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,315\n",
      "Trainable params: 1,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(36, activation='relu', input_dim=12))\n",
    "model.add(Dense(18, activation='relu'))\n",
    "model.add(Dense(9, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c8451d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "26aab19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.3504 - accuracy: 0.8931\n",
      "Epoch 2/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1915 - accuracy: 0.9366\n",
      "Epoch 3/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1758 - accuracy: 0.9378\n",
      "Epoch 4/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1555 - accuracy: 0.9450\n",
      "Epoch 5/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1412 - accuracy: 0.9501\n",
      "Epoch 6/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1446 - accuracy: 0.9501\n",
      "Epoch 7/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1206 - accuracy: 0.9581\n",
      "Epoch 8/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1171 - accuracy: 0.9589\n",
      "Epoch 9/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0980 - accuracy: 0.9692\n",
      "Epoch 10/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9661\n",
      "Epoch 11/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0855 - accuracy: 0.9725\n",
      "Epoch 12/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0896 - accuracy: 0.9688\n",
      "Epoch 13/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0835 - accuracy: 0.9700\n",
      "Epoch 14/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.9760\n",
      "Epoch 15/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0879 - accuracy: 0.9711\n",
      "Epoch 16/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0796 - accuracy: 0.9752\n",
      "Epoch 17/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0858 - accuracy: 0.9713\n",
      "Epoch 18/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0843 - accuracy: 0.9713\n",
      "Epoch 19/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0785 - accuracy: 0.9754\n",
      "Epoch 20/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0735 - accuracy: 0.9776\n",
      "Epoch 21/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9752\n",
      "Epoch 22/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0688 - accuracy: 0.9766\n",
      "Epoch 23/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0698 - accuracy: 0.9772\n",
      "Epoch 24/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0709 - accuracy: 0.9772\n",
      "Epoch 25/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0708 - accuracy: 0.9756\n",
      "Epoch 26/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0830 - accuracy: 0.9743\n",
      "Epoch 27/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9770\n",
      "Epoch 28/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0728 - accuracy: 0.9758\n",
      "Epoch 29/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9797\n",
      "Epoch 30/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9784\n",
      "Epoch 31/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0687 - accuracy: 0.9793\n",
      "Epoch 32/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0637 - accuracy: 0.9799\n",
      "Epoch 33/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9805\n",
      "Epoch 34/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0647 - accuracy: 0.9793\n",
      "Epoch 35/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0618 - accuracy: 0.9807\n",
      "Epoch 36/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0617 - accuracy: 0.9801\n",
      "Epoch 37/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0612 - accuracy: 0.9807\n",
      "Epoch 38/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.9807\n",
      "Epoch 39/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0597 - accuracy: 0.9809\n",
      "Epoch 40/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9795\n",
      "Epoch 41/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9823\n",
      "Epoch 42/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0576 - accuracy: 0.9821\n",
      "Epoch 43/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0613 - accuracy: 0.9813\n",
      "Epoch 44/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9813\n",
      "Epoch 45/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0634 - accuracy: 0.9805\n",
      "Epoch 46/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9826\n",
      "Epoch 47/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0531 - accuracy: 0.9842\n",
      "Epoch 48/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9807\n",
      "Epoch 49/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.9828\n",
      "Epoch 50/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0601 - accuracy: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa77b4ef40>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.astype(float), y_train, epochs=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3427e772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05264788866043091, 0.9852307438850403]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e259a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "45f44b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oh = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2b30c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "71b694a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_57 (Dense)            (None, 36)                468       \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 18)                666       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 9)                 171       \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 2)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,325\n",
      "Trainable params: 1,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(36, activation='relu', input_dim=12))\n",
    "model.add(Dense(18, activation='relu'))\n",
    "model.add(Dense(9, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7070e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65f0117a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.2696 - accuracy: 0.9113\n",
      "Epoch 2/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1926 - accuracy: 0.9343\n",
      "Epoch 3/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1843 - accuracy: 0.9366\n",
      "Epoch 4/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1741 - accuracy: 0.9401\n",
      "Epoch 5/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1640 - accuracy: 0.9409\n",
      "Epoch 6/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1532 - accuracy: 0.9454\n",
      "Epoch 7/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1455 - accuracy: 0.9489\n",
      "Epoch 8/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1272 - accuracy: 0.9569\n",
      "Epoch 9/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1136 - accuracy: 0.9614\n",
      "Epoch 10/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1137 - accuracy: 0.9608\n",
      "Epoch 11/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9641\n",
      "Epoch 12/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.9741\n",
      "Epoch 13/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9735\n",
      "Epoch 14/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0855 - accuracy: 0.9754\n",
      "Epoch 15/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.9745\n",
      "Epoch 16/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0792 - accuracy: 0.9760\n",
      "Epoch 17/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0761 - accuracy: 0.9760\n",
      "Epoch 18/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.9782\n",
      "Epoch 19/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0744 - accuracy: 0.9750\n",
      "Epoch 20/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0723 - accuracy: 0.9795\n",
      "Epoch 21/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0830 - accuracy: 0.9760\n",
      "Epoch 22/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9799\n",
      "Epoch 23/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0667 - accuracy: 0.9797\n",
      "Epoch 24/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0695 - accuracy: 0.9809\n",
      "Epoch 25/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.9780\n",
      "Epoch 26/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0647 - accuracy: 0.9805\n",
      "Epoch 27/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9811\n",
      "Epoch 28/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.9811\n",
      "Epoch 29/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0701 - accuracy: 0.9789\n",
      "Epoch 30/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0590 - accuracy: 0.9832\n",
      "Epoch 31/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0597 - accuracy: 0.9811\n",
      "Epoch 32/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0596 - accuracy: 0.9823\n",
      "Epoch 33/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9805\n",
      "Epoch 34/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0629 - accuracy: 0.9836\n",
      "Epoch 35/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9813\n",
      "Epoch 36/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0641 - accuracy: 0.9817\n",
      "Epoch 37/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0581 - accuracy: 0.9821\n",
      "Epoch 38/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9778\n",
      "Epoch 39/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0674 - accuracy: 0.9809\n",
      "Epoch 40/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.9817\n",
      "Epoch 41/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0551 - accuracy: 0.9836\n",
      "Epoch 42/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0557 - accuracy: 0.9854\n",
      "Epoch 43/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0517 - accuracy: 0.9854\n",
      "Epoch 44/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9815\n",
      "Epoch 45/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0568 - accuracy: 0.9852\n",
      "Epoch 46/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0577 - accuracy: 0.9842\n",
      "Epoch 47/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9836\n",
      "Epoch 48/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0513 - accuracy: 0.9865\n",
      "Epoch 49/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0521 - accuracy: 0.9842\n",
      "Epoch 50/50\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 0.0507 - accuracy: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa79ea9280>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.astype(float), y_train, epochs=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bf2e1d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.048172179609537125, 0.984000027179718]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cfec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0d2b498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "78/78 [==============================] - 1s 5ms/step - loss: 1.4315 - accuracy: 0.7719 - val_loss: 0.3258 - val_accuracy: 0.9077\n",
      "Epoch 2/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.9276 - val_loss: 0.2670 - val_accuracy: 0.9190\n",
      "Epoch 3/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9315 - val_loss: 0.2567 - val_accuracy: 0.9221\n",
      "Epoch 4/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9343 - val_loss: 0.2232 - val_accuracy: 0.9313\n",
      "Epoch 5/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9330 - val_loss: 0.2174 - val_accuracy: 0.9323\n",
      "Epoch 6/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1905 - accuracy: 0.9389 - val_loss: 0.2072 - val_accuracy: 0.9374\n",
      "Epoch 7/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9418 - val_loss: 0.1990 - val_accuracy: 0.9272\n",
      "Epoch 8/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9441 - val_loss: 0.1950 - val_accuracy: 0.9395\n",
      "Epoch 9/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9456 - val_loss: 0.1771 - val_accuracy: 0.9415\n",
      "Epoch 10/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9474 - val_loss: 0.1688 - val_accuracy: 0.9456\n",
      "Epoch 11/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9502 - val_loss: 0.1598 - val_accuracy: 0.9477\n",
      "Epoch 12/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9497 - val_loss: 0.1594 - val_accuracy: 0.9477\n",
      "Epoch 13/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9538 - val_loss: 0.1446 - val_accuracy: 0.9518\n",
      "Epoch 14/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9577 - val_loss: 0.1487 - val_accuracy: 0.9600\n",
      "Epoch 15/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9582 - val_loss: 0.1481 - val_accuracy: 0.9477\n",
      "Epoch 16/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9589 - val_loss: 0.1415 - val_accuracy: 0.9487\n",
      "Epoch 17/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9600 - val_loss: 0.1221 - val_accuracy: 0.9651\n",
      "Epoch 18/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1145 - accuracy: 0.9613 - val_loss: 0.1444 - val_accuracy: 0.9600\n",
      "Epoch 19/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9643 - val_loss: 0.1406 - val_accuracy: 0.9487\n",
      "Epoch 20/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 0.9666 - val_loss: 0.1068 - val_accuracy: 0.9672\n",
      "Epoch 21/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9682 - val_loss: 0.1067 - val_accuracy: 0.9692\n",
      "Epoch 22/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0904 - accuracy: 0.9690 - val_loss: 0.0992 - val_accuracy: 0.9774\n",
      "Epoch 23/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9728 - val_loss: 0.1144 - val_accuracy: 0.9713\n",
      "Epoch 24/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9713 - val_loss: 0.0975 - val_accuracy: 0.9733\n",
      "Epoch 25/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9707 - val_loss: 0.0992 - val_accuracy: 0.9713\n",
      "Epoch 26/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9710 - val_loss: 0.0924 - val_accuracy: 0.9805\n",
      "Epoch 27/80\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.0817 - accuracy: 0.9728 - val_loss: 0.0909 - val_accuracy: 0.9785\n",
      "Epoch 28/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9736 - val_loss: 0.0910 - val_accuracy: 0.9795\n",
      "Epoch 29/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9769 - val_loss: 0.0885 - val_accuracy: 0.9795\n",
      "Epoch 30/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9751 - val_loss: 0.0906 - val_accuracy: 0.9805\n",
      "Epoch 31/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9756 - val_loss: 0.0850 - val_accuracy: 0.9815\n",
      "Epoch 32/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9749 - val_loss: 0.0824 - val_accuracy: 0.9826\n",
      "Epoch 33/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9779 - val_loss: 0.0867 - val_accuracy: 0.9805\n",
      "Epoch 34/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9774 - val_loss: 0.0821 - val_accuracy: 0.9826\n",
      "Epoch 35/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9749 - val_loss: 0.0804 - val_accuracy: 0.9805\n",
      "Epoch 36/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9779 - val_loss: 0.0821 - val_accuracy: 0.9826\n",
      "Epoch 37/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9779 - val_loss: 0.0826 - val_accuracy: 0.9785\n",
      "Epoch 38/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9784 - val_loss: 0.0910 - val_accuracy: 0.9754\n",
      "Epoch 39/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9774 - val_loss: 0.0866 - val_accuracy: 0.9785\n",
      "Epoch 40/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9774 - val_loss: 0.1138 - val_accuracy: 0.9703\n",
      "Epoch 41/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 0.0878 - val_accuracy: 0.9795\n",
      "Epoch 42/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9802 - val_loss: 0.0790 - val_accuracy: 0.9836\n",
      "Epoch 43/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9779 - val_loss: 0.1071 - val_accuracy: 0.9703\n",
      "Epoch 44/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9761 - val_loss: 0.0755 - val_accuracy: 0.9846\n",
      "Epoch 45/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9792 - val_loss: 0.0751 - val_accuracy: 0.9836\n",
      "Epoch 46/80\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9782 - val_loss: 0.0961 - val_accuracy: 0.9754\n",
      "Epoch 47/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9802 - val_loss: 0.0786 - val_accuracy: 0.9815\n",
      "Epoch 48/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9818 - val_loss: 0.0855 - val_accuracy: 0.9805\n",
      "Epoch 49/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9751 - val_loss: 0.0745 - val_accuracy: 0.9846\n",
      "Epoch 50/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9764 - val_loss: 0.0863 - val_accuracy: 0.9795\n",
      "Epoch 51/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9800 - val_loss: 0.0786 - val_accuracy: 0.9826\n",
      "Epoch 52/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9831 - val_loss: 0.0818 - val_accuracy: 0.9805\n",
      "Epoch 53/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9833 - val_loss: 0.0772 - val_accuracy: 0.9815\n",
      "Epoch 54/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9813 - val_loss: 0.0834 - val_accuracy: 0.9805\n",
      "Epoch 55/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9833 - val_loss: 0.0761 - val_accuracy: 0.9826\n",
      "Epoch 56/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9810 - val_loss: 0.0705 - val_accuracy: 0.9846\n",
      "Epoch 57/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9797 - val_loss: 0.0789 - val_accuracy: 0.9815\n",
      "Epoch 58/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9749 - val_loss: 0.0851 - val_accuracy: 0.9805\n",
      "Epoch 59/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9815 - val_loss: 0.0903 - val_accuracy: 0.9795\n",
      "Epoch 60/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9810 - val_loss: 0.0707 - val_accuracy: 0.9856\n",
      "Epoch 61/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9836 - val_loss: 0.1004 - val_accuracy: 0.9744\n",
      "Epoch 62/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9795 - val_loss: 0.1036 - val_accuracy: 0.9723\n",
      "Epoch 63/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9828 - val_loss: 0.0818 - val_accuracy: 0.9805\n",
      "Epoch 64/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9815 - val_loss: 0.0740 - val_accuracy: 0.9836\n",
      "Epoch 65/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9790 - val_loss: 0.1055 - val_accuracy: 0.9723\n",
      "Epoch 66/80\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9779 - val_loss: 0.0830 - val_accuracy: 0.9774\n",
      "Epoch 67/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9836 - val_loss: 0.0702 - val_accuracy: 0.9856\n",
      "Epoch 68/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9777 - val_loss: 0.0696 - val_accuracy: 0.9856\n",
      "Epoch 69/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9795 - val_loss: 0.0734 - val_accuracy: 0.9836\n",
      "Epoch 70/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9813 - val_loss: 0.0697 - val_accuracy: 0.9846\n",
      "Epoch 71/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9823 - val_loss: 0.1132 - val_accuracy: 0.9621\n",
      "Epoch 72/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9813 - val_loss: 0.1019 - val_accuracy: 0.9723\n",
      "Epoch 73/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9836 - val_loss: 0.0839 - val_accuracy: 0.9805\n",
      "Epoch 74/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9810 - val_loss: 0.0706 - val_accuracy: 0.9856\n",
      "Epoch 75/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9805 - val_loss: 0.0763 - val_accuracy: 0.9826\n",
      "Epoch 76/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9815 - val_loss: 0.0975 - val_accuracy: 0.9774\n",
      "Epoch 77/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9805 - val_loss: 0.0683 - val_accuracy: 0.9856\n",
      "Epoch 78/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 0.0698 - val_accuracy: 0.9867\n",
      "Epoch 79/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9831 - val_loss: 0.0706 - val_accuracy: 0.9846\n",
      "Epoch 80/80\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9820 - val_loss: 0.0914 - val_accuracy: 0.9805\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, validation_split=0.2, batch_size = 50, epochs = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "53621e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1aa7d6d02e0>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "23b36a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1aa7d73fb80>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57eef6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35285380",
   "metadata": {},
   "source": [
    "### boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729836fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2   3      4      5     6       7   8      9     10  \\\n",
       "0    0.00632  18.0   2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1    0.02731   0.0   7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2    0.02729   0.0   7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3    0.03237   0.0   2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4    0.06905   0.0   2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "..       ...   ...    ...  ..    ...    ...   ...     ...  ..    ...   ...   \n",
       "501  0.06263   0.0  11.93   0  0.573  6.593  69.1  2.4786   1  273.0  21.0   \n",
       "502  0.04527   0.0  11.93   0  0.573  6.120  76.7  2.2875   1  273.0  21.0   \n",
       "503  0.06076   0.0  11.93   0  0.573  6.976  91.0  2.1675   1  273.0  21.0   \n",
       "504  0.10959   0.0  11.93   0  0.573  6.794  89.3  2.3889   1  273.0  21.0   \n",
       "505  0.04741   0.0  11.93   0  0.573  6.030  80.8  2.5050   1  273.0  21.0   \n",
       "\n",
       "         11    12    13  \n",
       "0    396.90  4.98  24.0  \n",
       "1    396.90  9.14  21.6  \n",
       "2    392.83  4.03  34.7  \n",
       "3    394.63  2.94  33.4  \n",
       "4    396.90  5.33  36.2  \n",
       "..      ...   ...   ...  \n",
       "501  391.99  9.67  22.4  \n",
       "502  396.90  9.08  20.6  \n",
       "503  396.90  5.64  23.9  \n",
       "504  393.45  6.48  22.0  \n",
       "505  396.90  7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/housing.csv', header = None, delim_whitespace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e1ec711",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.values[:, :13]\n",
    "y = df.values[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843fabc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d415e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78703dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 13, activation = 'relu'))\n",
    "model.add(Dense(20, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13d64d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c88f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 3s 10ms/step - loss: 743.1070 - val_loss: 201.2653\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 125.2207 - val_loss: 101.7251\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 92.8023 - val_loss: 75.1104\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 71.1290 - val_loss: 71.1139\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 65.3470 - val_loss: 69.2474\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 60.3904 - val_loss: 66.6501\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 54.1441 - val_loss: 56.8438\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6097 - val_loss: 55.4096\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7691 - val_loss: 55.5455\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1880 - val_loss: 59.2509\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.8124 - val_loss: 51.8930\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0724 - val_loss: 51.9515\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1241 - val_loss: 50.3826\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.6970 - val_loss: 49.2453\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 45.9384 - val_loss: 49.3006\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 42.9057 - val_loss: 56.1653\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 44.9018 - val_loss: 46.6334\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 42.4384 - val_loss: 48.6655\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 43.3025 - val_loss: 49.6778\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 42.1534 - val_loss: 47.7048\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 42.4374 - val_loss: 45.9722\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.8141 - val_loss: 44.0862\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.9314 - val_loss: 45.4362\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.0548 - val_loss: 43.3719\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.5737 - val_loss: 46.9315\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.2375 - val_loss: 42.3446\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.9340 - val_loss: 42.7004\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.9278 - val_loss: 43.8634\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.4842 - val_loss: 43.1721\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.5417 - val_loss: 40.9724\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.8198 - val_loss: 50.4595\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.5611 - val_loss: 51.9664\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.2900 - val_loss: 39.9902\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.3840 - val_loss: 39.5578\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.3883 - val_loss: 40.3964\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.4370 - val_loss: 41.0951\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 44.2901 - val_loss: 38.9830\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.1075 - val_loss: 62.5884\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.8648 - val_loss: 38.4356\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.5957 - val_loss: 41.7248\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.2371 - val_loss: 38.3665\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.9345 - val_loss: 51.6126\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.4203 - val_loss: 36.7416\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.0785 - val_loss: 39.4863\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.9712 - val_loss: 37.3364\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.1166 - val_loss: 48.8806\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.7995 - val_loss: 35.6240\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.3421 - val_loss: 36.6893\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.5225 - val_loss: 35.7193\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.5243 - val_loss: 39.5608\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.6430 - val_loss: 46.0722\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.8340 - val_loss: 37.0483\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.6914 - val_loss: 47.8234\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.9483 - val_loss: 36.2494\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.7371 - val_loss: 34.6769\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.1591 - val_loss: 39.0657\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.1662 - val_loss: 36.1186\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.8955 - val_loss: 42.8252\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.6353 - val_loss: 36.1022\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 38.5849 - val_loss: 33.6346\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.3919 - val_loss: 34.0823\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.0339 - val_loss: 35.8213\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.8468 - val_loss: 33.4048\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.5305 - val_loss: 32.8103\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.0160 - val_loss: 34.6434\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.1877 - val_loss: 34.0153\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.7638 - val_loss: 42.7032\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.2090 - val_loss: 33.3857\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.0756 - val_loss: 32.8016\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.4711 - val_loss: 34.6075\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.9311 - val_loss: 31.8750\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.8747 - val_loss: 32.1956\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 29.8157 - val_loss: 33.2943\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.7213 - val_loss: 32.3722\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.6817 - val_loss: 35.4750\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.7438 - val_loss: 31.8628\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.0026 - val_loss: 32.6727\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.1369 - val_loss: 32.2870\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.4569 - val_loss: 30.9741\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.9011 - val_loss: 33.9779\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.6049 - val_loss: 30.6721\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.2578 - val_loss: 32.6331\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 26.3066 - val_loss: 31.2865\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.0761 - val_loss: 35.3060\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.4941 - val_loss: 36.3286\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.7200 - val_loss: 39.8474\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.0461 - val_loss: 33.9500\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.2003 - val_loss: 39.1043\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.2393 - val_loss: 31.4870\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.6407 - val_loss: 35.4570\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.1409 - val_loss: 30.2586\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.9918 - val_loss: 34.1607\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 26.9221 - val_loss: 36.1889\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 41.5380 - val_loss: 46.3697\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 44.9393 - val_loss: 31.9172\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 26.3802 - val_loss: 29.6035\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 26.3026 - val_loss: 30.1943\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 25.3572 - val_loss: 32.4862\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 26.8979 - val_loss: 30.3244\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.4307 - val_loss: 30.5413\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, validation_split=0.2, epochs = 100, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e62443a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x216c9be6220>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "029f6ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 36.3628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36.362823486328125"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a4f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "943d722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc10335",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 13, activation = 'relu'))\n",
    "model.add(Dense(20, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1560b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "448b102f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 10ms/step - loss: 539.9809 - val_loss: 573.0895\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 511.8870 - val_loss: 537.0588\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 471.1297 - val_loss: 482.2143\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 408.7495 - val_loss: 398.3605\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 318.9073 - val_loss: 289.6399\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 218.4350 - val_loss: 185.2952\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 145.4368 - val_loss: 137.4498\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 122.6638 - val_loss: 124.8307\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.4060 - val_loss: 116.2028\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 102.5654 - val_loss: 107.5434\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 94.4006 - val_loss: 100.0842\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 86.5743 - val_loss: 93.7467\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 79.2181 - val_loss: 86.7007\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 72.3924 - val_loss: 80.5234\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 66.2540 - val_loss: 74.8050\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 60.5369 - val_loss: 68.9394\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55.6886 - val_loss: 64.9673\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.1346 - val_loss: 60.9227\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5730 - val_loss: 57.4307\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 44.6540 - val_loss: 55.6048\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 43.1143 - val_loss: 53.1727\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.8991 - val_loss: 53.2426\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.8507 - val_loss: 51.4660\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 38.2646 - val_loss: 49.4961\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.3285 - val_loss: 49.2102\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.8392 - val_loss: 47.2819\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.7582 - val_loss: 46.2368\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.2994 - val_loss: 44.7885\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.5525 - val_loss: 44.4853\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.7973 - val_loss: 43.4144\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.3610 - val_loss: 42.3396\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.8808 - val_loss: 42.1589\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.5577 - val_loss: 40.7161\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.8952 - val_loss: 39.8550\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.1330 - val_loss: 39.0646\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 26.3870 - val_loss: 38.2655\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 25.4769 - val_loss: 37.6254\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 24.7674 - val_loss: 37.0469\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 24.2192 - val_loss: 36.5337\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 23.5393 - val_loss: 35.8747\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 23.5145 - val_loss: 35.2809\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 22.4325 - val_loss: 34.6901\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21.6503 - val_loss: 34.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 21.1365 - val_loss: 34.0883\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 20.7691 - val_loss: 33.7372\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 20.3898 - val_loss: 33.3073\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 20.2509 - val_loss: 33.0695\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 19.6296 - val_loss: 32.8075\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 19.2373 - val_loss: 32.4590\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 18.9983 - val_loss: 32.2091\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_sc, y_train, validation_split=0.2, epochs = 50, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83819503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 21.1002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21.10015106201172"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7275b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d3418fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eda8a845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6838074602601538"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed6d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9f875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae54d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2716e1f",
   "metadata": {},
   "source": [
    "### adult_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f7f4c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education_num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital_status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "          50k  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/adult.txt', header=None, names = ['age', 'workclass','fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race'\\\n",
    ", 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', '50k'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86a8c5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " <=50K    24720\n",
       " >50K      7841\n",
       "Name: 50k, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['50k'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d6de6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "      <th>50k_ &lt;=50K</th>\n",
       "      <th>50k_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education_num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0       39   77516             13          2174             0              40   \n",
       "1       50   83311             13             0             0              13   \n",
       "2       38  215646              9             0             0              40   \n",
       "3       53  234721              7             0             0              40   \n",
       "4       28  338409             13             0             0              40   \n",
       "...    ...     ...            ...           ...           ...             ...   \n",
       "32556   27  257302             12             0             0              38   \n",
       "32557   40  154374              9             0             0              40   \n",
       "32558   58  151910              9             0             0              40   \n",
       "32559   22  201490              9             0             0              20   \n",
       "32560   52  287927              9         15024             0              40   \n",
       "\n",
       "       workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0                 0                       0                     0   \n",
       "1                 0                       0                     0   \n",
       "2                 0                       0                     0   \n",
       "3                 0                       0                     0   \n",
       "4                 0                       0                     0   \n",
       "...             ...                     ...                   ...   \n",
       "32556             0                       0                     0   \n",
       "32557             0                       0                     0   \n",
       "32558             0                       0                     0   \n",
       "32559             0                       0                     0   \n",
       "32560             0                       0                     0   \n",
       "\n",
       "       workclass_ Never-worked  ...  native-country_ Scotland  \\\n",
       "0                            0  ...                         0   \n",
       "1                            0  ...                         0   \n",
       "2                            0  ...                         0   \n",
       "3                            0  ...                         0   \n",
       "4                            0  ...                         0   \n",
       "...                        ...  ...                       ...   \n",
       "32556                        0  ...                         0   \n",
       "32557                        0  ...                         0   \n",
       "32558                        0  ...                         0   \n",
       "32559                        0  ...                         0   \n",
       "32560                        0  ...                         0   \n",
       "\n",
       "       native-country_ South  native-country_ Taiwan  \\\n",
       "0                          0                       0   \n",
       "1                          0                       0   \n",
       "2                          0                       0   \n",
       "3                          0                       0   \n",
       "4                          0                       0   \n",
       "...                      ...                     ...   \n",
       "32556                      0                       0   \n",
       "32557                      0                       0   \n",
       "32558                      0                       0   \n",
       "32559                      0                       0   \n",
       "32560                      0                       0   \n",
       "\n",
       "       native-country_ Thailand  native-country_ Trinadad&Tobago  \\\n",
       "0                             0                                0   \n",
       "1                             0                                0   \n",
       "2                             0                                0   \n",
       "3                             0                                0   \n",
       "4                             0                                0   \n",
       "...                         ...                              ...   \n",
       "32556                         0                                0   \n",
       "32557                         0                                0   \n",
       "32558                         0                                0   \n",
       "32559                         0                                0   \n",
       "32560                         0                                0   \n",
       "\n",
       "       native-country_ United-States  native-country_ Vietnam  \\\n",
       "0                                  1                        0   \n",
       "1                                  1                        0   \n",
       "2                                  1                        0   \n",
       "3                                  1                        0   \n",
       "4                                  0                        0   \n",
       "...                              ...                      ...   \n",
       "32556                              1                        0   \n",
       "32557                              1                        0   \n",
       "32558                              1                        0   \n",
       "32559                              1                        0   \n",
       "32560                              1                        0   \n",
       "\n",
       "       native-country_ Yugoslavia  50k_ <=50K  50k_ >50K  \n",
       "0                               0           1          0  \n",
       "1                               0           1          0  \n",
       "2                               0           1          0  \n",
       "3                               0           1          0  \n",
       "4                               0           1          0  \n",
       "...                           ...         ...        ...  \n",
       "32556                           0           1          0  \n",
       "32557                           0           0          1  \n",
       "32558                           0           1          0  \n",
       "32559                           0           1          0  \n",
       "32560                           0           0          1  \n",
       "\n",
       "[32561 rows x 110 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4677e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.values[:, 108:]\n",
    "x = df.values[:, :108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae7760eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 108)\n",
      "(32561, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c52bcf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 100)               10900     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 60)                4860      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,962\n",
      "Trainable params: 23,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim = 108, activation = 'relu'))\n",
    "model.add(Dense(80, activation = 'relu'))\n",
    "model.add(Dense(60, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b1f5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1effae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 329.8449 - accuracy: 0.6717\n",
      "Epoch 2/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 168.3933 - accuracy: 0.6787\n",
      "Epoch 3/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 72.7590 - accuracy: 0.6867\n",
      "Epoch 4/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 57.9866 - accuracy: 0.6868\n",
      "Epoch 5/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 52.5260 - accuracy: 0.6853\n",
      "Epoch 6/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 34.0463 - accuracy: 0.6811\n",
      "Epoch 7/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 22.1593 - accuracy: 0.6821\n",
      "Epoch 8/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 11.9762 - accuracy: 0.6841\n",
      "Epoch 9/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 9.1742 - accuracy: 0.6907\n",
      "Epoch 10/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 5.7205 - accuracy: 0.6889\n",
      "Epoch 11/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 4.2473 - accuracy: 0.6913\n",
      "Epoch 12/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 2.0952 - accuracy: 0.7019\n",
      "Epoch 13/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 2.1687 - accuracy: 0.7011\n",
      "Epoch 14/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.7954 - accuracy: 0.7524\n",
      "Epoch 15/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.7817 - accuracy: 0.7479\n",
      "Epoch 16/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5889 - accuracy: 0.7771\n",
      "Epoch 17/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.6010 - accuracy: 0.7741\n",
      "Epoch 18/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5267 - accuracy: 0.7928\n",
      "Epoch 19/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7988\n",
      "Epoch 20/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 25.8914 - accuracy: 0.6943\n",
      "Epoch 21/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.8675 - accuracy: 0.7616\n",
      "Epoch 22/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5535 - accuracy: 0.7847\n",
      "Epoch 23/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5242 - accuracy: 0.7940\n",
      "Epoch 24/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4906 - accuracy: 0.8016\n",
      "Epoch 25/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5088 - accuracy: 0.7976\n",
      "Epoch 26/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4949 - accuracy: 0.7982\n",
      "Epoch 27/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4890 - accuracy: 0.7989\n",
      "Epoch 28/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5251 - accuracy: 0.7826\n",
      "Epoch 29/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4963 - accuracy: 0.7979\n",
      "Epoch 30/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.8011\n",
      "Epoch 31/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.8040\n",
      "Epoch 32/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4895 - accuracy: 0.8028\n",
      "Epoch 33/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.8029\n",
      "Epoch 34/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4992 - accuracy: 0.8036\n",
      "Epoch 35/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4953 - accuracy: 0.8026\n",
      "Epoch 36/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4933 - accuracy: 0.8007\n",
      "Epoch 37/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5009 - accuracy: 0.7984\n",
      "Epoch 38/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.8017\n",
      "Epoch 39/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.7961\n",
      "Epoch 40/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.4887 - accuracy: 0.8018\n",
      "Epoch 41/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.7920\n",
      "Epoch 42/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5404 - accuracy: 0.7718\n",
      "Epoch 43/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5309 - accuracy: 0.7762\n",
      "Epoch 44/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5146 - accuracy: 0.7893\n",
      "Epoch 45/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.6382 - accuracy: 0.7825\n",
      "Epoch 46/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.9158 - accuracy: 0.7704\n",
      "Epoch 47/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5578 - accuracy: 0.7650\n",
      "Epoch 48/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5505 - accuracy: 0.7634\n",
      "Epoch 49/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5459 - accuracy: 0.7651\n",
      "Epoch 50/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5426 - accuracy: 0.7666\n",
      "Epoch 51/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5466 - accuracy: 0.7693\n",
      "Epoch 52/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5430 - accuracy: 0.7680\n",
      "Epoch 53/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5398 - accuracy: 0.7709\n",
      "Epoch 54/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5411 - accuracy: 0.7723\n",
      "Epoch 55/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5450 - accuracy: 0.7655\n",
      "Epoch 56/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5429 - accuracy: 0.7679\n",
      "Epoch 57/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5426 - accuracy: 0.7663\n",
      "Epoch 58/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.7667\n",
      "Epoch 59/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5484 - accuracy: 0.7651\n",
      "Epoch 60/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5466 - accuracy: 0.7658\n",
      "Epoch 61/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5480 - accuracy: 0.7641\n",
      "Epoch 62/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5445 - accuracy: 0.7655\n",
      "Epoch 63/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5489 - accuracy: 0.7656\n",
      "Epoch 64/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5516 - accuracy: 0.7636\n",
      "Epoch 65/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5474 - accuracy: 0.7635\n",
      "Epoch 66/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5482 - accuracy: 0.7656\n",
      "Epoch 67/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5524 - accuracy: 0.7626\n",
      "Epoch 68/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5499 - accuracy: 0.7610\n",
      "Epoch 69/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 70/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 71/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 72/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 73/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 74/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 75/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 76/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 77/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 78/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 79/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 80/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 82/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 83/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 84/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 85/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 86/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 87/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 88/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 89/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 90/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 91/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 92/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 93/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 94/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 95/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 96/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 97/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7606\n",
      "Epoch 98/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 99/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 100/100\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20770e5c940>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs = 100, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21ca5cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.5502 - accuracy: 0.7606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5502305030822754, 0.7606338858604431]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fea732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7dea473",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efee459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 100)               10900     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 60)                4860      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,962\n",
      "Trainable params: 23,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim = 108, activation = 'relu'))\n",
    "model.add(Dense(80, activation = 'relu'))\n",
    "model.add(Dense(60, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17d0f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f83b1877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 668.8862 - accuracy: 0.6615\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 382.0669 - accuracy: 0.6435\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 173.3647 - accuracy: 0.6769\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 196.8145 - accuracy: 0.6784\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 425.5905 - accuracy: 0.6814\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 432.1721 - accuracy: 0.6679\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 373.8576 - accuracy: 0.6505\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 298.8756 - accuracy: 0.6952\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 324.1301 - accuracy: 0.6494\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 251.8682 - accuracy: 0.6976\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 120.0758 - accuracy: 0.6760\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 123.2737 - accuracy: 0.6961\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 328.8620 - accuracy: 0.6480\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 218.9432 - accuracy: 0.6866\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 251.9981 - accuracy: 0.6781\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 252.1162 - accuracy: 0.7119\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 160.2096 - accuracy: 0.6738\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 107.5550 - accuracy: 0.6906\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 91.7085 - accuracy: 0.6992\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 96.2195 - accuracy: 0.6991\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 236.2294 - accuracy: 0.6597\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 222.9158 - accuracy: 0.6967\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 235.5734 - accuracy: 0.6543\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 232.3977 - accuracy: 0.6987\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 192.4697 - accuracy: 0.6756\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 127.2155 - accuracy: 0.6774\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 156.1899 - accuracy: 0.7029\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 75.8497 - accuracy: 0.7026\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 80.0738 - accuracy: 0.6776\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 84.7684 - accuracy: 0.6989\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 78.2732 - accuracy: 0.6781\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 73.7541 - accuracy: 0.6957\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 202.1735 - accuracy: 0.6652\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 84.4993 - accuracy: 0.6663\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 203.8449 - accuracy: 0.6941\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 180.0480 - accuracy: 0.6566\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 161.2983 - accuracy: 0.7036\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 160.8603 - accuracy: 0.6539\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 159.6625 - accuracy: 0.7021\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 156.7964 - accuracy: 0.6711\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 148.7868 - accuracy: 0.6981\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 142.9511 - accuracy: 0.7007\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 138.7937 - accuracy: 0.6574\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 69.8738 - accuracy: 0.7149\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 49.9291 - accuracy: 0.7114\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 45.4816 - accuracy: 0.7002\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 46.4813 - accuracy: 0.6988\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 47.2405 - accuracy: 0.6870\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 90.1443 - accuracy: 0.6688\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 58.1594 - accuracy: 0.7002\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 45.1094 - accuracy: 0.7008\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 42.0050 - accuracy: 0.6990\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 43.3824 - accuracy: 0.6912\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 96.7915 - accuracy: 0.6671\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 112.3261 - accuracy: 0.6860\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 113.3056 - accuracy: 0.6719\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 104.3419 - accuracy: 0.6906\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 95.7205 - accuracy: 0.6838\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 77.3115 - accuracy: 0.6998\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 89.8442 - accuracy: 0.6783\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 87.0088 - accuracy: 0.6785\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 87.9660 - accuracy: 0.6876\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 68.5665 - accuracy: 0.6768\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 66.5678 - accuracy: 0.7054\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 62.0331 - accuracy: 0.6860\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 59.0590 - accuracy: 0.6688\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 58.0300 - accuracy: 0.7149\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 48.4444 - accuracy: 0.6898\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 45.5005 - accuracy: 0.6715\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 21.2312 - accuracy: 0.7014\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 23.5465 - accuracy: 0.6931\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 20.3923 - accuracy: 0.6939\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 44.6398 - accuracy: 0.6600\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 58.2431 - accuracy: 0.6985\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 28.5422 - accuracy: 0.7001\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 21.4513 - accuracy: 0.6982\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 19.0333 - accuracy: 0.6952\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 20.2600 - accuracy: 0.7061\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 18.3521 - accuracy: 0.6960\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 20.6174 - accuracy: 0.6901\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 39.5580 - accuracy: 0.6586\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 26.1975 - accuracy: 0.7059\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 21.9670 - accuracy: 0.7136\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 17.8118 - accuracy: 0.7011\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 36.1466 - accuracy: 0.6693\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 35.4066 - accuracy: 0.6931\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 31.3445 - accuracy: 0.6957\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 44.1714 - accuracy: 0.6559\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 47.0836 - accuracy: 0.6935\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 39.8686 - accuracy: 0.6571\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 48.7123 - accuracy: 0.6952\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 31.3456 - accuracy: 0.6790\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 24.3006 - accuracy: 0.7110\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 60.3849 - accuracy: 0.6505\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 42.9010 - accuracy: 0.6880\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 34.1679 - accuracy: 0.6778\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 24.2771 - accuracy: 0.6944\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 11.6560 - accuracy: 0.6996\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 11.3671 - accuracy: 0.6948\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 9.1138 - accuracy: 0.6929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20771da3520>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2595aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255/255 [==============================] - 1s 2ms/step - loss: 5.0634 - accuracy: 0.7904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.06342887878418, 0.7904434204101562]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e6716a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc2b00ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bcbfc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 100)               10900     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 60)                4860      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,962\n",
      "Trainable params: 23,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim = 108, activation = 'relu'))\n",
    "model.add(Dense(80, activation = 'relu'))\n",
    "model.add(Dense(60, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e91f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "348591d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7779\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8385\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8469\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8511\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.8552\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3049 - accuracy: 0.8583\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8610\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8626\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8624\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.8658\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.8678\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.8690\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8705\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.8737\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.8746\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8742\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.8776\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2610 - accuracy: 0.8776\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.8794\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.8810\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.8830\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.8836\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.8835\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.8853\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.8876\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2428 - accuracy: 0.8864\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.8877\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.8883\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2366 - accuracy: 0.8894\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.8916\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.8918\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.8929\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.8952\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2238 - accuracy: 0.8968\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.8966\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.8975\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.8980\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.8978\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9006\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9024\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9023\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9036\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9054\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9060\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2029 - accuracy: 0.9083\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2042 - accuracy: 0.9062\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9089\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1991 - accuracy: 0.9088\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9095\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1999 - accuracy: 0.9069\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9095\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9108\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1929 - accuracy: 0.9116\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1930 - accuracy: 0.9094\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1899 - accuracy: 0.9131\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.9115\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1871 - accuracy: 0.9143\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1857 - accuracy: 0.9135\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9151\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1822 - accuracy: 0.9170\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9163\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9176\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.9179\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9170\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9166\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1816 - accuracy: 0.9166\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1772 - accuracy: 0.9179\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9194\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1718 - accuracy: 0.9204\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9215\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9219\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9223\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9231\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9224\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9230\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9229\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9238\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9251\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9209\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9257\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9239\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9251\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9254\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9277\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9273\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9267\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1570 - accuracy: 0.9269\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9276\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9291\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9288\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9292\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9280\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9303\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9278\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1531 - accuracy: 0.9285\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9321\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9313\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9308\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20778835bb0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_sc, y_train, epochs = 100, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "923d30a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255/255 [==============================] - 1s 2ms/step - loss: 0.6943 - accuracy: 0.8317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6942933201789856, 0.831716001033783]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6672b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['50k'].apply(lambda x : 1 if x == ' >50K' else 0)\n",
    "x = df.loc[:, :'native-country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f81e9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90aa5a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b75c0e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oh = tf.keras.utils.to_categorical(y)\n",
    "y_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ea1b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_oh, test_size=0.3, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "edbe9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52d935af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 128)               13952     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 56)                7224      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 56)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 26)                1482      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 26)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 54        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,712\n",
      "Trainable params: 22,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim = 108, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(56, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(26, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad195529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = 'accuracy', optimizer = 'adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3de741c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "912/912 [==============================] - 4s 4ms/step - loss: 0.6411 - accuracy: 0.6813 - val_loss: 0.4706 - val_accuracy: 0.7769\n",
      "Epoch 2/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.5358 - accuracy: 0.7448 - val_loss: 0.4285 - val_accuracy: 0.8024\n",
      "Epoch 3/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.5020 - accuracy: 0.7610 - val_loss: 0.4059 - val_accuracy: 0.8186\n",
      "Epoch 4/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4793 - accuracy: 0.7758 - val_loss: 0.3919 - val_accuracy: 0.8298\n",
      "Epoch 5/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4677 - accuracy: 0.7817 - val_loss: 0.3817 - val_accuracy: 0.8344\n",
      "Epoch 6/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4554 - accuracy: 0.7866 - val_loss: 0.3750 - val_accuracy: 0.8348\n",
      "Epoch 7/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4457 - accuracy: 0.7897 - val_loss: 0.3699 - val_accuracy: 0.8368\n",
      "Epoch 8/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4364 - accuracy: 0.7928 - val_loss: 0.3657 - val_accuracy: 0.8392\n",
      "Epoch 9/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4295 - accuracy: 0.7984 - val_loss: 0.3622 - val_accuracy: 0.8410\n",
      "Epoch 10/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4214 - accuracy: 0.8026 - val_loss: 0.3596 - val_accuracy: 0.8425\n",
      "Epoch 11/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4202 - accuracy: 0.7997 - val_loss: 0.3571 - val_accuracy: 0.8429\n",
      "Epoch 12/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4122 - accuracy: 0.8045 - val_loss: 0.3550 - val_accuracy: 0.8432\n",
      "Epoch 13/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4177 - accuracy: 0.8037 - val_loss: 0.3532 - val_accuracy: 0.8434\n",
      "Epoch 14/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4157 - accuracy: 0.8092 - val_loss: 0.3518 - val_accuracy: 0.8434\n",
      "Epoch 15/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4127 - accuracy: 0.8024 - val_loss: 0.3507 - val_accuracy: 0.8438\n",
      "Epoch 16/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4099 - accuracy: 0.8090 - val_loss: 0.3497 - val_accuracy: 0.8440\n",
      "Epoch 17/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4098 - accuracy: 0.8107 - val_loss: 0.3488 - val_accuracy: 0.8445\n",
      "Epoch 18/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4048 - accuracy: 0.8090 - val_loss: 0.3479 - val_accuracy: 0.8458\n",
      "Epoch 19/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4017 - accuracy: 0.8096 - val_loss: 0.3470 - val_accuracy: 0.8458\n",
      "Epoch 20/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4060 - accuracy: 0.8085 - val_loss: 0.3461 - val_accuracy: 0.8456\n",
      "Epoch 21/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3972 - accuracy: 0.8131 - val_loss: 0.3453 - val_accuracy: 0.8458\n",
      "Epoch 22/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4019 - accuracy: 0.8096 - val_loss: 0.3448 - val_accuracy: 0.8467\n",
      "Epoch 23/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3951 - accuracy: 0.8149 - val_loss: 0.3442 - val_accuracy: 0.8473\n",
      "Epoch 24/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3931 - accuracy: 0.8149 - val_loss: 0.3435 - val_accuracy: 0.8462\n",
      "Epoch 25/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3944 - accuracy: 0.8127 - val_loss: 0.3431 - val_accuracy: 0.8462\n",
      "Epoch 26/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3930 - accuracy: 0.8166 - val_loss: 0.3425 - val_accuracy: 0.8456\n",
      "Epoch 27/100\n",
      "912/912 [==============================] - 3s 3ms/step - loss: 0.3918 - accuracy: 0.8181 - val_loss: 0.3421 - val_accuracy: 0.8460\n",
      "Epoch 28/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3931 - accuracy: 0.8155 - val_loss: 0.3416 - val_accuracy: 0.8458\n",
      "Epoch 29/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3886 - accuracy: 0.8170 - val_loss: 0.3412 - val_accuracy: 0.8465\n",
      "Epoch 30/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3876 - accuracy: 0.8208 - val_loss: 0.3407 - val_accuracy: 0.8460\n",
      "Epoch 31/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3904 - accuracy: 0.8187 - val_loss: 0.3403 - val_accuracy: 0.8462\n",
      "Epoch 32/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3881 - accuracy: 0.8177 - val_loss: 0.3399 - val_accuracy: 0.8465\n",
      "Epoch 33/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3912 - accuracy: 0.8162 - val_loss: 0.3396 - val_accuracy: 0.8456\n",
      "Epoch 34/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3872 - accuracy: 0.8163 - val_loss: 0.3394 - val_accuracy: 0.8456\n",
      "Epoch 35/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3851 - accuracy: 0.8197 - val_loss: 0.3391 - val_accuracy: 0.8456\n",
      "Epoch 36/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3822 - accuracy: 0.8214 - val_loss: 0.3387 - val_accuracy: 0.8449\n",
      "Epoch 37/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3855 - accuracy: 0.8213 - val_loss: 0.3384 - val_accuracy: 0.8462\n",
      "Epoch 38/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3822 - accuracy: 0.8221 - val_loss: 0.3381 - val_accuracy: 0.8460\n",
      "Epoch 39/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3837 - accuracy: 0.8208 - val_loss: 0.3378 - val_accuracy: 0.8465\n",
      "Epoch 40/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3803 - accuracy: 0.8211 - val_loss: 0.3375 - val_accuracy: 0.8462\n",
      "Epoch 41/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3823 - accuracy: 0.8194 - val_loss: 0.3373 - val_accuracy: 0.8469\n",
      "Epoch 42/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3775 - accuracy: 0.8212 - val_loss: 0.3369 - val_accuracy: 0.8473\n",
      "Epoch 43/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3792 - accuracy: 0.8225 - val_loss: 0.3367 - val_accuracy: 0.8471\n",
      "Epoch 44/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3802 - accuracy: 0.8227 - val_loss: 0.3365 - val_accuracy: 0.8467\n",
      "Epoch 45/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3783 - accuracy: 0.8193 - val_loss: 0.3363 - val_accuracy: 0.8469\n",
      "Epoch 46/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3801 - accuracy: 0.8222 - val_loss: 0.3361 - val_accuracy: 0.8469\n",
      "Epoch 47/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3774 - accuracy: 0.8232 - val_loss: 0.3359 - val_accuracy: 0.8462\n",
      "Epoch 48/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3800 - accuracy: 0.8206 - val_loss: 0.3357 - val_accuracy: 0.8462\n",
      "Epoch 49/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3798 - accuracy: 0.8238 - val_loss: 0.3355 - val_accuracy: 0.8471\n",
      "Epoch 50/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3776 - accuracy: 0.8245 - val_loss: 0.3353 - val_accuracy: 0.8465\n",
      "Epoch 51/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3794 - accuracy: 0.8186 - val_loss: 0.3351 - val_accuracy: 0.8467\n",
      "Epoch 52/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3781 - accuracy: 0.8201 - val_loss: 0.3349 - val_accuracy: 0.8471\n",
      "Epoch 53/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3773 - accuracy: 0.8231 - val_loss: 0.3347 - val_accuracy: 0.8476\n",
      "Epoch 54/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3761 - accuracy: 0.8233 - val_loss: 0.3345 - val_accuracy: 0.8482\n",
      "Epoch 55/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3777 - accuracy: 0.8204 - val_loss: 0.3344 - val_accuracy: 0.8482\n",
      "Epoch 56/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3765 - accuracy: 0.8230 - val_loss: 0.3342 - val_accuracy: 0.8482\n",
      "Epoch 57/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3786 - accuracy: 0.8232 - val_loss: 0.3341 - val_accuracy: 0.8478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3773 - accuracy: 0.8200 - val_loss: 0.3339 - val_accuracy: 0.8476\n",
      "Epoch 59/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3756 - accuracy: 0.8252 - val_loss: 0.3337 - val_accuracy: 0.8480\n",
      "Epoch 60/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3720 - accuracy: 0.8250 - val_loss: 0.3335 - val_accuracy: 0.8484\n",
      "Epoch 61/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3751 - accuracy: 0.8235 - val_loss: 0.3334 - val_accuracy: 0.8480\n",
      "Epoch 62/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3697 - accuracy: 0.8261 - val_loss: 0.3332 - val_accuracy: 0.8482\n",
      "Epoch 63/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3763 - accuracy: 0.8227 - val_loss: 0.3330 - val_accuracy: 0.8487\n",
      "Epoch 64/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3734 - accuracy: 0.8256 - val_loss: 0.3329 - val_accuracy: 0.8487\n",
      "Epoch 65/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3732 - accuracy: 0.8249 - val_loss: 0.3328 - val_accuracy: 0.8487\n",
      "Epoch 66/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3695 - accuracy: 0.8273 - val_loss: 0.3325 - val_accuracy: 0.8487\n",
      "Epoch 67/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3738 - accuracy: 0.8235 - val_loss: 0.3324 - val_accuracy: 0.8495\n",
      "Epoch 68/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3701 - accuracy: 0.8268 - val_loss: 0.3323 - val_accuracy: 0.8493\n",
      "Epoch 69/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3670 - accuracy: 0.8268 - val_loss: 0.3321 - val_accuracy: 0.8495\n",
      "Epoch 70/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3681 - accuracy: 0.8256 - val_loss: 0.3319 - val_accuracy: 0.8493\n",
      "Epoch 71/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3693 - accuracy: 0.8261 - val_loss: 0.3318 - val_accuracy: 0.8493\n",
      "Epoch 72/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3712 - accuracy: 0.8247 - val_loss: 0.3317 - val_accuracy: 0.8489\n",
      "Epoch 73/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3729 - accuracy: 0.8253 - val_loss: 0.3315 - val_accuracy: 0.8489\n",
      "Epoch 74/100\n",
      "912/912 [==============================] - 3s 3ms/step - loss: 0.3679 - accuracy: 0.8266 - val_loss: 0.3314 - val_accuracy: 0.8497\n",
      "Epoch 75/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3727 - accuracy: 0.8280 - val_loss: 0.3313 - val_accuracy: 0.8497\n",
      "Epoch 76/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3684 - accuracy: 0.8263 - val_loss: 0.3312 - val_accuracy: 0.8497\n",
      "Epoch 77/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3648 - accuracy: 0.8300 - val_loss: 0.3310 - val_accuracy: 0.8500\n",
      "Epoch 78/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3697 - accuracy: 0.8271 - val_loss: 0.3310 - val_accuracy: 0.8500\n",
      "Epoch 79/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3701 - accuracy: 0.8277 - val_loss: 0.3309 - val_accuracy: 0.8500\n",
      "Epoch 80/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3690 - accuracy: 0.8244 - val_loss: 0.3308 - val_accuracy: 0.8502\n",
      "Epoch 81/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3637 - accuracy: 0.8274 - val_loss: 0.3306 - val_accuracy: 0.8502\n",
      "Epoch 82/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3677 - accuracy: 0.8293 - val_loss: 0.3305 - val_accuracy: 0.8502\n",
      "Epoch 83/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3656 - accuracy: 0.8301 - val_loss: 0.3303 - val_accuracy: 0.8502\n",
      "Epoch 84/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3676 - accuracy: 0.8258 - val_loss: 0.3302 - val_accuracy: 0.8500\n",
      "Epoch 85/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3655 - accuracy: 0.8267 - val_loss: 0.3301 - val_accuracy: 0.8504\n",
      "Epoch 86/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3673 - accuracy: 0.8289 - val_loss: 0.3299 - val_accuracy: 0.8506\n",
      "Epoch 87/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3679 - accuracy: 0.8282 - val_loss: 0.3299 - val_accuracy: 0.8502\n",
      "Epoch 88/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3643 - accuracy: 0.8267 - val_loss: 0.3298 - val_accuracy: 0.8506\n",
      "Epoch 89/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3645 - accuracy: 0.8292 - val_loss: 0.3297 - val_accuracy: 0.8506\n",
      "Epoch 90/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3656 - accuracy: 0.8275 - val_loss: 0.3296 - val_accuracy: 0.8504\n",
      "Epoch 91/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3651 - accuracy: 0.8308 - val_loss: 0.3294 - val_accuracy: 0.8500\n",
      "Epoch 92/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3660 - accuracy: 0.8288 - val_loss: 0.3294 - val_accuracy: 0.8506\n",
      "Epoch 93/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3627 - accuracy: 0.8283 - val_loss: 0.3293 - val_accuracy: 0.8504\n",
      "Epoch 94/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3659 - accuracy: 0.8288 - val_loss: 0.3291 - val_accuracy: 0.8506\n",
      "Epoch 95/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3639 - accuracy: 0.8283 - val_loss: 0.3290 - val_accuracy: 0.8508\n",
      "Epoch 96/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3637 - accuracy: 0.8282 - val_loss: 0.3289 - val_accuracy: 0.8508\n",
      "Epoch 97/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3604 - accuracy: 0.8307 - val_loss: 0.3288 - val_accuracy: 0.8513\n",
      "Epoch 98/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3643 - accuracy: 0.8275 - val_loss: 0.3287 - val_accuracy: 0.8508\n",
      "Epoch 99/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3669 - accuracy: 0.8270 - val_loss: 0.3286 - val_accuracy: 0.8511\n",
      "Epoch 100/100\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.3636 - accuracy: 0.8276 - val_loss: 0.3286 - val_accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_sc, y_train, validation_split = 0.2, epochs = 100, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc40e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20771f451f0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], c = 'r')\n",
    "plt.plot(hist.history['val_loss'], c = 'b')\n",
    "plt.plot(hist.history['accuracy'], c = 'g')\n",
    "plt.plot(hist.history['val_accuracy'], c = 'y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c28e3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 1s 2ms/step - loss: 6756.4580 - accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6756.4580078125, 0.7655850052833557]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e69bbf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8517760262053434"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093b8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0367757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d6e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cb8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41c523ca",
   "metadata": {},
   "source": [
    "### concrete_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "817a3e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.887366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.269535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.052780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.296075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                      540.0   \n",
       "1                                      540.0   \n",
       "2                                      332.5   \n",
       "3                                      332.5   \n",
       "4                                      198.6   \n",
       "\n",
       "   Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                0.0       \n",
       "1                                                0.0       \n",
       "2                                              142.5       \n",
       "3                                              142.5       \n",
       "4                                              132.4       \n",
       "\n",
       "   Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         0.0   \n",
       "\n",
       "   Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                      162.0   \n",
       "1                                      162.0   \n",
       "2                                      228.0   \n",
       "3                                      228.0   \n",
       "4                                      192.0   \n",
       "\n",
       "   Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                2.5     \n",
       "1                                                2.5     \n",
       "2                                                0.0     \n",
       "3                                                0.0     \n",
       "4                                                0.0     \n",
       "\n",
       "   Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                             1040.0      \n",
       "1                                             1055.0      \n",
       "2                                              932.0      \n",
       "3                                              932.0      \n",
       "4                                              978.4      \n",
       "\n",
       "   Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \\\n",
       "0                                              676.0         28   \n",
       "1                                              676.0         28   \n",
       "2                                              594.0        270   \n",
       "3                                              594.0        365   \n",
       "4                                              825.5        360   \n",
       "\n",
       "   Concrete compressive strength(MPa, megapascals)   \n",
       "0                                         79.986111  \n",
       "1                                         61.887366  \n",
       "2                                         40.269535  \n",
       "3                                         41.052780  \n",
       "4                                         44.296075  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../Data/Concrete_Data.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e938fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['cement', 'furnace', 'ash', 'water', 'superplacsticizer', 'coarse', 'fine', 'age', 'strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eafc75a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>furnace</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplacsticizer</th>\n",
       "      <th>coarse</th>\n",
       "      <th>fine</th>\n",
       "      <th>age</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.887366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.269535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.052780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.296075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.284354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.178794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.696601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.768036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.401235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cement  furnace    ash  water  superplacsticizer  coarse   fine  age  \\\n",
       "0      540.0      0.0    0.0  162.0                2.5  1040.0  676.0   28   \n",
       "1      540.0      0.0    0.0  162.0                2.5  1055.0  676.0   28   \n",
       "2      332.5    142.5    0.0  228.0                0.0   932.0  594.0  270   \n",
       "3      332.5    142.5    0.0  228.0                0.0   932.0  594.0  365   \n",
       "4      198.6    132.4    0.0  192.0                0.0   978.4  825.5  360   \n",
       "...      ...      ...    ...    ...                ...     ...    ...  ...   \n",
       "1025   276.4    116.0   90.3  179.6                8.9   870.1  768.3   28   \n",
       "1026   322.2      0.0  115.6  196.0               10.4   817.9  813.4   28   \n",
       "1027   148.5    139.4  108.6  192.7                6.1   892.4  780.0   28   \n",
       "1028   159.1    186.7    0.0  175.6               11.3   989.6  788.9   28   \n",
       "1029   260.9    100.5   78.3  200.6                8.6   864.5  761.5   28   \n",
       "\n",
       "       strength  \n",
       "0     79.986111  \n",
       "1     61.887366  \n",
       "2     40.269535  \n",
       "3     41.052780  \n",
       "4     44.296075  \n",
       "...         ...  \n",
       "1025  44.284354  \n",
       "1026  31.178794  \n",
       "1027  23.696601  \n",
       "1028  32.768036  \n",
       "1029  32.401235  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5992c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.values[:, 8]\n",
    "x = df.values[:, :8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9660ddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 8)\n",
      "(1030,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "20cb1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1b2b36ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 256)               2304      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 56)                7224      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 28)                1596      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 29        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,049\n",
      "Trainable params: 44,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(56, activation = 'relu'))\n",
    "model.add(Dense(28, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8311cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "07c21a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 501.4102 - val_loss: 175.8043\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 152.4738 - val_loss: 151.0908\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 135.9854 - val_loss: 116.2812\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 105.5603 - val_loss: 108.7857\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 100.1491 - val_loss: 87.9327\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 82.4049 - val_loss: 87.1462\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 72.3704 - val_loss: 72.0997\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 76.5247 - val_loss: 97.3916\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 63.2491 - val_loss: 62.0103\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 67.0343 - val_loss: 113.1576\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 71.1056 - val_loss: 67.5389\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56.3680 - val_loss: 84.0723\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59.2709 - val_loss: 71.8334\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 72.1555 - val_loss: 113.0746\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 95.0922 - val_loss: 81.9447\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 66.1650 - val_loss: 80.2539\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59.4825 - val_loss: 57.9620\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 63.4327 - val_loss: 54.6561\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48.2299 - val_loss: 73.9098\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 62.0219 - val_loss: 44.3758\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47.9582 - val_loss: 42.0579\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.6175 - val_loss: 41.6161\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47.5319 - val_loss: 52.1613\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50.4181 - val_loss: 42.0438\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.5041 - val_loss: 41.5645\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45.3278 - val_loss: 46.8681\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46.1030 - val_loss: 50.8645\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56.0601 - val_loss: 59.8519\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53.2464 - val_loss: 39.9740\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50.6498 - val_loss: 47.7796\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40.2144 - val_loss: 49.8632\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 52.3073 - val_loss: 48.9455\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47.7948 - val_loss: 48.3835\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45.1244 - val_loss: 34.9518\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45.7304 - val_loss: 58.8075\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 52.6478 - val_loss: 45.7117\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49.0669 - val_loss: 70.4284\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.7529 - val_loss: 62.2557\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 66.0295 - val_loss: 81.8385\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47.8843 - val_loss: 56.8721\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.3269 - val_loss: 38.3196\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.5192 - val_loss: 42.4847\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45.6563 - val_loss: 40.4350\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41.4574 - val_loss: 34.9451\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 36.8274 - val_loss: 33.7651\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 36.8020 - val_loss: 37.8472\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 37.1799 - val_loss: 37.2403\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.6287 - val_loss: 32.4744\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 37.5348 - val_loss: 57.9447\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.5359 - val_loss: 33.8904\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, validation_split=0.2, epochs = 50, batch_size = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "00202ba4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.935722 ],\n",
       "       [22.497997 ],\n",
       "       [28.418144 ],\n",
       "       [28.470167 ],\n",
       "       [56.553402 ],\n",
       "       [30.743904 ],\n",
       "       [16.838654 ],\n",
       "       [ 9.249533 ],\n",
       "       [23.904554 ],\n",
       "       [22.897812 ],\n",
       "       [35.073116 ],\n",
       "       [37.120544 ],\n",
       "       [36.975143 ],\n",
       "       [51.549236 ],\n",
       "       [36.067257 ],\n",
       "       [54.340378 ],\n",
       "       [29.52114  ],\n",
       "       [17.824457 ],\n",
       "       [35.651875 ],\n",
       "       [16.966461 ],\n",
       "       [15.729113 ],\n",
       "       [25.826702 ],\n",
       "       [26.171642 ],\n",
       "       [22.700356 ],\n",
       "       [45.25382  ],\n",
       "       [36.734005 ],\n",
       "       [29.779709 ],\n",
       "       [17.00037  ],\n",
       "       [61.07806  ],\n",
       "       [50.316128 ],\n",
       "       [59.81831  ],\n",
       "       [34.378414 ],\n",
       "       [48.2242   ],\n",
       "       [41.91669  ],\n",
       "       [26.564104 ],\n",
       "       [37.22643  ],\n",
       "       [33.85163  ],\n",
       "       [37.931644 ],\n",
       "       [35.959652 ],\n",
       "       [30.175224 ],\n",
       "       [70.26261  ],\n",
       "       [49.953518 ],\n",
       "       [27.876919 ],\n",
       "       [29.438515 ],\n",
       "       [38.973644 ],\n",
       "       [28.430384 ],\n",
       "       [45.08903  ],\n",
       "       [12.426098 ],\n",
       "       [29.281204 ],\n",
       "       [21.032785 ],\n",
       "       [39.425144 ],\n",
       "       [60.019306 ],\n",
       "       [33.381596 ],\n",
       "       [38.94001  ],\n",
       "       [44.16734  ],\n",
       "       [52.034252 ],\n",
       "       [38.103672 ],\n",
       "       [38.09072  ],\n",
       "       [34.41705  ],\n",
       "       [26.089077 ],\n",
       "       [28.640285 ],\n",
       "       [10.695426 ],\n",
       "       [51.104492 ],\n",
       "       [36.590466 ],\n",
       "       [59.42992  ],\n",
       "       [21.717167 ],\n",
       "       [16.847652 ],\n",
       "       [48.332623 ],\n",
       "       [47.24432  ],\n",
       "       [62.219517 ],\n",
       "       [36.900574 ],\n",
       "       [40.06696  ],\n",
       "       [40.243843 ],\n",
       "       [31.945406 ],\n",
       "       [41.859837 ],\n",
       "       [23.53518  ],\n",
       "       [10.8246155],\n",
       "       [57.13229  ],\n",
       "       [50.666042 ],\n",
       "       [52.276424 ],\n",
       "       [55.827297 ],\n",
       "       [36.350853 ],\n",
       "       [33.661793 ],\n",
       "       [46.11791  ],\n",
       "       [41.4948   ],\n",
       "       [71.34366  ],\n",
       "       [ 7.528045 ],\n",
       "       [32.01121  ],\n",
       "       [40.372375 ],\n",
       "       [37.789753 ],\n",
       "       [22.568338 ],\n",
       "       [16.277561 ],\n",
       "       [24.063173 ],\n",
       "       [44.44794  ],\n",
       "       [ 9.280038 ],\n",
       "       [23.026958 ],\n",
       "       [55.94325  ],\n",
       "       [18.403168 ],\n",
       "       [32.321762 ],\n",
       "       [30.41285  ],\n",
       "       [39.47804  ],\n",
       "       [42.182415 ],\n",
       "       [24.51665  ],\n",
       "       [ 9.749713 ],\n",
       "       [18.51833  ],\n",
       "       [11.858288 ],\n",
       "       [15.872472 ],\n",
       "       [57.633587 ],\n",
       "       [28.4935   ],\n",
       "       [28.072706 ],\n",
       "       [43.641808 ],\n",
       "       [36.697598 ],\n",
       "       [21.379526 ],\n",
       "       [32.85291  ],\n",
       "       [28.515621 ],\n",
       "       [16.845533 ],\n",
       "       [49.941933 ],\n",
       "       [57.725986 ],\n",
       "       [12.300914 ],\n",
       "       [ 6.726068 ],\n",
       "       [71.34366  ],\n",
       "       [26.24733  ],\n",
       "       [20.183306 ],\n",
       "       [39.425667 ],\n",
       "       [66.51917  ],\n",
       "       [26.554176 ],\n",
       "       [18.441797 ],\n",
       "       [57.345707 ],\n",
       "       [30.635612 ],\n",
       "       [35.134514 ],\n",
       "       [44.946243 ],\n",
       "       [23.81755  ],\n",
       "       [32.123737 ],\n",
       "       [41.20963  ],\n",
       "       [39.90062  ],\n",
       "       [63.086243 ],\n",
       "       [21.343761 ],\n",
       "       [ 9.284563 ],\n",
       "       [42.510735 ],\n",
       "       [45.211525 ],\n",
       "       [22.578632 ],\n",
       "       [47.56609  ],\n",
       "       [17.411018 ],\n",
       "       [60.958477 ],\n",
       "       [28.17247  ],\n",
       "       [37.541035 ],\n",
       "       [47.826683 ],\n",
       "       [39.33086  ],\n",
       "       [60.948936 ],\n",
       "       [25.954235 ],\n",
       "       [38.01813  ],\n",
       "       [26.155806 ],\n",
       "       [55.474304 ],\n",
       "       [44.49382  ],\n",
       "       [32.384327 ],\n",
       "       [26.347692 ],\n",
       "       [ 9.475914 ],\n",
       "       [25.94822  ],\n",
       "       [36.021347 ],\n",
       "       [34.313343 ],\n",
       "       [34.617096 ],\n",
       "       [66.43906  ],\n",
       "       [59.553654 ],\n",
       "       [23.358486 ],\n",
       "       [25.837944 ],\n",
       "       [28.34959  ],\n",
       "       [45.19131  ],\n",
       "       [30.078207 ],\n",
       "       [35.143734 ],\n",
       "       [42.29385  ],\n",
       "       [18.929047 ],\n",
       "       [33.884396 ],\n",
       "       [22.311241 ],\n",
       "       [46.12974  ],\n",
       "       [ 6.9451346],\n",
       "       [15.334429 ],\n",
       "       [41.385303 ],\n",
       "       [34.168808 ],\n",
       "       [44.115208 ],\n",
       "       [54.738148 ],\n",
       "       [16.67573  ],\n",
       "       [13.637264 ],\n",
       "       [47.982212 ],\n",
       "       [20.862959 ],\n",
       "       [33.28781  ],\n",
       "       [39.22002  ],\n",
       "       [31.201002 ],\n",
       "       [20.431137 ],\n",
       "       [53.85845  ],\n",
       "       [32.690594 ],\n",
       "       [15.653907 ],\n",
       "       [51.866882 ],\n",
       "       [41.956284 ],\n",
       "       [60.28604  ],\n",
       "       [14.685767 ],\n",
       "       [29.813122 ],\n",
       "       [37.644863 ],\n",
       "       [42.81663  ],\n",
       "       [69.636116 ],\n",
       "       [ 2.5763013],\n",
       "       [53.20877  ],\n",
       "       [ 4.4510436],\n",
       "       [36.868145 ],\n",
       "       [39.581425 ],\n",
       "       [57.09927  ],\n",
       "       [62.651226 ],\n",
       "       [31.170454 ],\n",
       "       [55.0417   ],\n",
       "       [16.91191  ],\n",
       "       [27.406845 ],\n",
       "       [46.771725 ],\n",
       "       [49.769268 ],\n",
       "       [46.493877 ],\n",
       "       [10.633088 ],\n",
       "       [39.296604 ],\n",
       "       [53.0704   ],\n",
       "       [13.410325 ],\n",
       "       [ 7.40785  ],\n",
       "       [37.066036 ],\n",
       "       [23.862074 ],\n",
       "       [23.390808 ],\n",
       "       [60.76153  ],\n",
       "       [28.660795 ],\n",
       "       [58.108562 ],\n",
       "       [32.723454 ],\n",
       "       [16.808203 ],\n",
       "       [49.23643  ],\n",
       "       [39.506516 ],\n",
       "       [36.908703 ],\n",
       "       [26.819946 ],\n",
       "       [10.042414 ],\n",
       "       [20.499537 ],\n",
       "       [56.895153 ],\n",
       "       [27.104525 ],\n",
       "       [41.83211  ],\n",
       "       [37.736122 ],\n",
       "       [47.92962  ],\n",
       "       [41.449017 ],\n",
       "       [46.852886 ],\n",
       "       [19.297714 ],\n",
       "       [28.102016 ],\n",
       "       [37.421066 ],\n",
       "       [39.748306 ],\n",
       "       [14.477023 ],\n",
       "       [42.958553 ],\n",
       "       [23.845678 ],\n",
       "       [59.03465  ],\n",
       "       [38.424664 ],\n",
       "       [19.673887 ],\n",
       "       [60.254406 ],\n",
       "       [45.12696  ],\n",
       "       [50.555305 ],\n",
       "       [22.697294 ],\n",
       "       [38.435497 ],\n",
       "       [69.95917  ],\n",
       "       [23.395412 ],\n",
       "       [17.791077 ],\n",
       "       [19.163237 ]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e88f9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [v[0] for v in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a7278164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177593409506916"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab66eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "47ae3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "88136cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_31 (Dense)            (None, 256)               2304      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 56)                7224      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 28)                1596      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 29        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,049\n",
      "Trainable params: 44,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(56, activation = 'relu'))\n",
    "model.add(Dense(28, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bf1415fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "08346bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1273.5836 - val_loss: 552.6298\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 300.1810 - val_loss: 207.4318\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 203.7651 - val_loss: 186.4465\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 180.6677 - val_loss: 171.0029\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 164.0490 - val_loss: 157.2915\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 152.2194 - val_loss: 151.2934\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 141.9742 - val_loss: 141.0518\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 128.9922 - val_loss: 134.7174\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 117.6607 - val_loss: 119.6291\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 103.3704 - val_loss: 105.8491\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 90.4304 - val_loss: 121.1415\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 79.6105 - val_loss: 87.3149\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 66.7927 - val_loss: 74.4066\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 56.4809 - val_loss: 68.9509\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 51.3093 - val_loss: 67.5280\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 45.7257 - val_loss: 53.5646\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 43.5839 - val_loss: 49.0421\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 38.3717 - val_loss: 54.9981\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 35.3642 - val_loss: 44.7536\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 33.9164 - val_loss: 42.5897\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.4751 - val_loss: 50.0663\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 32.6368 - val_loss: 39.4720\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.7058 - val_loss: 39.2513\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.9918 - val_loss: 37.2075\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.3490 - val_loss: 36.1872\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.8928 - val_loss: 36.3034\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.9201 - val_loss: 38.8132\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.3261 - val_loss: 33.0378\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.4022 - val_loss: 36.1985\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.9378 - val_loss: 31.3003\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.6545 - val_loss: 30.6276\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9742 - val_loss: 34.0088\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.7392 - val_loss: 36.1161\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.1780 - val_loss: 32.4826\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.7815 - val_loss: 29.7600\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.1649 - val_loss: 30.1256\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.2321 - val_loss: 31.7982\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.6561 - val_loss: 27.8283\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.9220 - val_loss: 30.4640\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7319 - val_loss: 32.2868\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.7314 - val_loss: 33.3618\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7178 - val_loss: 33.7357\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.3705 - val_loss: 28.8706\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.1532 - val_loss: 31.6475\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.8003 - val_loss: 32.7284\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7399 - val_loss: 26.0888\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0045 - val_loss: 31.2145\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6150 - val_loss: 26.7161\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7288 - val_loss: 27.6185\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4089 - val_loss: 29.1995\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.8572 - val_loss: 29.2107\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1942 - val_loss: 29.6749\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.1671 - val_loss: 36.0413\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.5397 - val_loss: 28.9007\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1865 - val_loss: 29.2806\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1424 - val_loss: 26.2208\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2272 - val_loss: 27.7743\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3530 - val_loss: 28.1813\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5054 - val_loss: 25.3337\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6555 - val_loss: 25.8738\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1004 - val_loss: 29.3014\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0505 - val_loss: 29.8658\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4954 - val_loss: 28.8710\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4023 - val_loss: 27.5586\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 13.0049 - val_loss: 28.0254\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 13.9978 - val_loss: 26.9035\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 13.6386 - val_loss: 30.4919\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 13.4942 - val_loss: 25.0655\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.2071 - val_loss: 25.4745\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 13.4417 - val_loss: 28.3893\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 12.6235 - val_loss: 27.5770\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.0580 - val_loss: 27.7244\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.0432 - val_loss: 26.9698\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8701 - val_loss: 31.5805\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6147 - val_loss: 25.0925\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 12.0338 - val_loss: 25.8067\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.9817 - val_loss: 25.5053\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.6159 - val_loss: 27.2342\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.8433 - val_loss: 24.3253\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 12.3046 - val_loss: 27.6531\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 4ms/step - loss: 11.0674 - val_loss: 25.7349\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.6970 - val_loss: 26.6266\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.5829 - val_loss: 25.1162\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.6260 - val_loss: 24.6907\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.5744 - val_loss: 26.4623\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.8092 - val_loss: 29.7568\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.2651 - val_loss: 25.6327\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.1075 - val_loss: 26.6830\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 10.4990 - val_loss: 23.8634\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 10.2254 - val_loss: 25.6625\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.4845 - val_loss: 25.3425\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.5489 - val_loss: 24.7250\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9342 - val_loss: 45.0874\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5256 - val_loss: 26.1886\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 12.4003 - val_loss: 27.9473\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 12.3478 - val_loss: 30.1091\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 10.2994 - val_loss: 24.0929\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.4208 - val_loss: 24.7566\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.7317 - val_loss: 28.5900\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 10.4688 - val_loss: 32.7239\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_sc, y_train, validation_split=0.2, epochs = 100, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ab974632",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8079309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8659677096753343"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e4c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c50c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c690b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005fe20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2eeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693dd39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a45c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ce463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03fc9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ad014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df353f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826db41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae7b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68076cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbade368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe177882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a1017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11262616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32889f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e954a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaeba4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79c463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0126d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0540bcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e098b325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf32a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6aca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d6095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de0aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0dfba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938e202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a7657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb7290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33281ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db8731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f72472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f7457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a2037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388f685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084cd037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e3f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6345d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f48af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af9632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e222d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71809633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be726ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e44a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2998b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162435ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626893ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af0ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e5687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4612d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb4ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e17deea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12118f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdc43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853dd50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b5694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8aa17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e629f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26145272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7772160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6287b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b807d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a937763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b8d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35f329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbd8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d21c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623bbf64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e6cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5870b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d12131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734dd537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7179a4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e011106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f75b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
